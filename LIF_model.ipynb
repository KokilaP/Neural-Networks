{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Simplified LIF model to experiment w/ NetworkX and Brian2\n",
    "\n",
    "Current status on runtime:\n",
    "~75 seconds for n=200, m=300 at 200 ms initially\n",
    "On consecutive runs, time reduces to ~1 second under same conditions == hysteresis effect? \n",
    "Want to collect times once reach steady-state, so have to keep running until runtime difference is not significant\n",
    "    and that's what you would record and compare with FPGA (would need to keep testing CPU and specs constant)\n",
    "\n",
    "For FPGA testing:\n",
    "1. Change any random values to specific values (rand_temp,W,G.v,PoissonInput)\n",
    "2. Figure out what variables need to be saved and sent to FPGA (c_rows,c_cols)\n",
    "\n",
    "Manipulatable variables:\n",
    "S3.connect\n",
    "S3.w\n",
    "PoissonInputs\n",
    "G_.v\n",
    "tau_m1\n",
    "tau_m2\n",
    "p_couple\n",
    "w_couple\n",
    "\n",
    "Variables of interest:\n",
    "rows = source neuron numbers (numpy.ndarray)\n",
    "cols = target neuron numbers (numpy.ndarray)\n",
    "connect_W = weight array (numpy.ndarray)\n",
    "A_temp5 = adjacency matrix (numpy.ndarray)\n",
    "myW = weight adjacency matrix (numpy.ndarray)\n",
    "c_rows = manually defined source neurons from coupling\n",
    "c_cols = manually defined target neurons from coupling\n",
    "coup_mat = coupling matrix (source x target)\n",
    "spikemon1.t = spike trains for source network\n",
    "spikemon2.t = spike trains for target network\n",
    "rand_seed = seed to initiate randomization\n",
    "\n",
    "Final output variables for Synapses group: \n",
    "ADJ matrix = rows (source), cols (target), A_temp5 (matrix form), c_rows (coupled), c_cols (coupled)\n",
    "WT matrix = connect_W (weights between source-target in order of (rows,cols))\n",
    "WT-ADJ matrix = myW (shows entire n*n matrix w/ E/I/non-connections) \n",
    "\n",
    "Work in progress for computer simulation:\n",
    "0) Is there a workable threshold for number of neurons and connections?\n",
    "    - Try establishing a maximum number of n and m before kernel crashes\n",
    "    - Why does it appear that the top 80% of neurons are behaving differently (if n=250, n_weird=200->250)?\n",
    "        - Yup, it's because excit_num\n",
    "        - Inhibitory neurons have significantly decreased firing rate, but it shouldn't be that?\n",
    "1) By changing coupling weight (S3.w), how does synchronicity change (see HH paper when they changed conductance & Fred \n",
    "        email 2/20)\n",
    "    - One run function to go through different values of coupling weight and output many graphs\n",
    "        OR individually go through different run functions that have specified coupling weight values and output 1 graph at a time\n",
    "2) Once we have correct parameters, we can start manipulating different network parameters/topology\n",
    "    - Would want different topology/parameters for each source/target network because they wouldn't be homogeneous \n",
    "3) Cleaner user interface where you only have to change the function instead of the source code\n",
    "\n",
    "Work in progress for FPGA simulation:\n",
    "1) Change values to match FPGA, e.g. 16-bit precision (dtype=int16) (?)\n",
    "\n",
    "Example of synchronicity:\n",
    "https://www.youtube.com/watch?v=yVkdfJ9PkRQ\n",
    "''' and None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pyspike",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bda420eb1dfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbrian2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyspike\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m#%matplotlib inline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named pyspike"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import time\n",
    "from brian2 import *\n",
    "import pyspike as spk\n",
    "#%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdjacencyMatrix:  \n",
    "    '''\n",
    "    Function 1: Weighted adjacency matrix\n",
    "    Call to initiate adjacency matrix\n",
    "    Call to choose which neural network topology with given parameters\n",
    "    \n",
    "    Description:\n",
    "    Given parameters, constructs network with adjacency matrix and applies random weights.\n",
    "    \n",
    "    Returns:\n",
    "        G: NetworkX Graph\n",
    "        A: Adjacency matrix. Sparse matrix\n",
    "        rows: Presynaptic neurons\n",
    "        cols: Postsynaptic neurons\n",
    "        connect_W: Weights for each E/I connection (in order of rows,cols)\n",
    "    \n",
    "    Parameters:\n",
    "        n: nodes\n",
    "        m: edges\n",
    "        k: neighbor connections\n",
    "        p: probability \n",
    "        d: degrees\n",
    "    '''\n",
    "    def __init__(self,n): \n",
    "        plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "        \n",
    "    def all_to_all(self,n):\n",
    "        G = nx.complete_graph(n) \n",
    "        #nx.draw(G, with_labels=True) # Draws plot with node labels\n",
    "        #plt.savefig(\"All to all.png\") # If want to save topology image\n",
    "        A = nx.adjacency_matrix(G) # Outputs unit adjacency matrix\n",
    "        return A, G\n",
    "\n",
    "    def random(self,n,m): \n",
    "        # Interchangeable based on UI for different types of topography\n",
    "        G = nx.dense_gnm_random_graph(n,m) # Uses NetX to generate random topography\n",
    "        #nx.draw(G, with_labels=True) # Draws connectivity figure\n",
    "        #plt.savefig(\"Random.png\") # Saves connectivity figure as Random.png\n",
    "\n",
    "        # Extracts ADJACENCY MATRIX from topography and rearranges to manageable array of (n*n) elements\n",
    "        A = nx.adjacency_matrix(G) # Assigns A as adjacency matrix (which nodes are connected)\n",
    "        return A, G \n",
    "    \n",
    "    def small_world(self,n,k,p): \n",
    "        G = nx.newman_watts_strogatz_graph(n,k,p) \n",
    "        #nx.draw(G, with_labels=True)\n",
    "        #plt.savefig(\"Small-world.png\")\n",
    "        A = nx.adjacency_matrix(G)\n",
    "        return A, G\n",
    "    \n",
    "    def regular(self,d,n): \n",
    "        G = nx.random_regular_graph(d,n)\n",
    "        #nx.draw(G, with_labels=True)\n",
    "        #plt.savefig(\"Regular.png\")\n",
    "        A = nx.adjacency_matrix(G)\n",
    "        return A, G\n",
    "    \n",
    "    def scale_free(self,n): \n",
    "        G = nx.scale_free_graph(n) \n",
    "        #nx.draw(G, with_labels=True)\n",
    "        #plt.savefig(\"Scale free.png\")\n",
    "        A = nx.adjacency_matrix(G)\n",
    "        return A, G\n",
    "\n",
    "    def Weighted(self,A,n):\n",
    "        A_temp1 = A.todense() # Converts A to manageable matrix\n",
    "        A_temp2 = np.reshape(A_temp1,(1,n**2)) # Reshapes adjacency matrix to array for calculation\n",
    "        A_temp3 = np.array(A_temp2) # Changes matrix element to type:array for calculation\n",
    "        A_temp4 = A_temp3[0] # Selects the first and only cell in array for manipulation\n",
    "\n",
    "        # Generates random values for n neurons to decide whether E/I\n",
    "        rand_temp=np.random.rand(1,n) \n",
    "        rand_temp=rand_temp[0]\n",
    "\n",
    "        # Changes positive to negative weights based on probability (***not necessary if define E/I in Synapses and subG)\n",
    "        if 0:\n",
    "            newlist = [] \n",
    "            for item in rand_temp:\n",
    "                if item > 0.8: # Random numbers to negative according to uniform probability\n",
    "                    item = -item \n",
    "                newlist.append(item) \n",
    "\n",
    "        # Reshapes adjacency matrix to workable matrix of n*n neurons\n",
    "        A_temp5 = np.reshape(A_temp4,(n,n)) \n",
    "\n",
    "        # Generates random weights for each connection (assuming all-all) w/o self-feedback\n",
    "        #W = np.random.rand(n,n) \n",
    "        W = np.random.randint(100, size=[n,n])\n",
    "        W_n = W\n",
    "        np.fill_diagonal(W,0) # Neurons are not self-connected\n",
    "        myW = W\n",
    "\n",
    "        # Prep for calculation of final weight matrix (basically just replacing all '1' in ADJ mat w/ corresponding WT mat)\n",
    "        A_temp=np.reshape(A_temp5,(n**2,1)) # Reshapes A for multiplication\n",
    "        W_temp=np.reshape(W,(1,n**2)) # Reshapes W for multiplication\n",
    "        W=A_temp * W_temp # Makes (n**2)x(n**2) matrix\n",
    "        W=W.diagonal() \n",
    "        W=np.reshape(W,(n,n)) \n",
    "        \n",
    "        # Gets the index values for source(rows)/target(cols) neurons \n",
    "        rows, cols = np.nonzero(A_temp5)\n",
    "\n",
    "        # Gets rid of duplicate connections (bidirectional --> unidirectional)\n",
    "        new_coord = zip(rows,cols)\n",
    "        #print new_coord\n",
    "        new_rows = set(tuple(sorted(l)) for l in new_coord)\n",
    "        g = np.array(list(new_rows))\n",
    "        rows = g[:,0] #neurons i\n",
    "        cols = g[:,1] #neurons j\n",
    "        new_coord = zip(rows,cols)\n",
    "\n",
    "        # To duplicate values above diagonal onto spots below diagonal\n",
    "        for x in range(len(myW)):\n",
    "            for y in range(len(myW)):\n",
    "                myW[y,x] = myW[x,y]\n",
    "\n",
    "        # Generates weight matrix in array that's necessary for Synapses in Brian2\n",
    "        # Values are in order of new_coord array\n",
    "        connect_W = []\n",
    "        for i in range(len(new_coord)):\n",
    "            connect_W.append(W[new_coord[i]])\n",
    "        connect_W = np.array(connect_W) # Weights for each connection in ndarray\n",
    "\n",
    "        # Changes weights (in array) to inhibitory if coming from an inhibitory neuron (upper 20% of n)\n",
    "        excit_num = int(0.8*n) # Index for 0:excitatory neurons\n",
    "        for x in range(len(new_coord)):\n",
    "            for y in (0,1):\n",
    "                if new_coord[x][y] >= excit_num: # Any neuron index greater than excit_num is inhibitory\n",
    "                    connect_W[x] = -connect_W[x]\n",
    "                    #final_W.append(connect_W(x))\n",
    "                    \n",
    "        # Changes weights (in matrix) to inhibitory if coming from an inhibitory neuron (upper 20% of n)\n",
    "        for x in range(len(myW)):\n",
    "            for y in range(len(myW)):\n",
    "                if x >= excit_num:\n",
    "                    myW[x,y] = -myW[x,y]\n",
    "                if y >= excit_num:\n",
    "                    myW[x,y] = -myW[x,y]\n",
    "        \n",
    "        return W, rows, cols, connect_W, new_coord, A_temp5, myW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualization:\n",
    "    '''\n",
    "    Function 2: Visualize neural network\n",
    "    Inputs graph G \n",
    "    Returns cluster coefficient & characteristic path length\n",
    "        & plot of connections between neurons (color-coded)\n",
    "    For more info: see collective dynamics paper\n",
    "    \n",
    "    Description:\n",
    "    From network model, determines cluster coefficient and characteristic path length for each\n",
    "        node. For each network, will take average of those values, respectively and yield \n",
    "        single integer value.\n",
    "    From network model, will output plot of connections, color-coded for excitatory and\n",
    "        inhibitory.\n",
    "    \n",
    "    Returns:\n",
    "        cc_avg: Cluster coefficient averaged over all nodes\n",
    "        ex_in_plot: Plot of colored excitatory/inhibitory connections\n",
    "        cpl_avg: Number of edges at shortest path over all nodes \n",
    "        \n",
    "    Parameters:\n",
    "        G: NetworkX Graph from Function 1\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        #plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "\n",
    "    def cluster_coeff(self,G):        \n",
    "        cc = nx.clustering(G)\n",
    "\n",
    "        cc_y=[]\n",
    "        for idx in cc:\n",
    "            cc_y=np.append(cc_y,cc[idx])\n",
    "        \n",
    "        cc_avg = np.ndarray.mean(cc_y, dtype=np.float64)\n",
    "        return cc_avg\n",
    "    \n",
    "    def ex_in_connec(self,G,connect_W):\n",
    "        plt.figure()\n",
    "        red_patch = mpatches.Patch(color='red', label='Excitatory')\n",
    "        blue_patch = mpatches.Patch(color='blue', label='Inhibitory')\n",
    "        plt.legend(handles=[red_patch,blue_patch])\n",
    "        suptitle('Structural Connections', fontsize=14, fontweight='bold')\n",
    "\n",
    "        edges = G.edges()\n",
    "        nodes = G.nodes()\n",
    "\n",
    "        custom_color={}\n",
    "        for idx in range(len(connect_W)):\n",
    "            if connect_W[idx] < 0:\n",
    "                inhib_edge = new_coord[idx]\n",
    "                G.add_edge(*inhib_edge)\n",
    "                custom_color[inhib_edge]='b'\n",
    "            else:\n",
    "                excit_edge = new_coord[idx]\n",
    "                G.add_edge(*excit_edge)\n",
    "                custom_color[excit_edge]='r'\n",
    "        if 0:\n",
    "            for idx,idy in enumerate(edges):\n",
    "                x1,y1 = edges[idx]\n",
    "                if connect_W < 0:\n",
    "                    inhib_edge = (x1,y1)\n",
    "                    G.add_edge(x1,y1)\n",
    "                    custom_color[x1,y1]='b' # Stores color of edges in dict\n",
    "                else:\n",
    "                    excit_edge = (x1,y1)\n",
    "                    G.add_edge(x1,y1)\n",
    "                    custom_color[x1,y1]='r'\n",
    "        \n",
    "        ex_in_plot=nx.draw_networkx(G,node_color='w',\n",
    "                         with_labels=True,\n",
    "                         node_list=nodes,\n",
    "                         #node_size=50,\n",
    "                         node_size=200,\n",
    "                         edge_list=custom_color.keys(),\n",
    "                         edge_color=custom_color.values(),\n",
    "                         label='Blue=Inhibitory, Red=Excitatory')\n",
    "        #plt.savefig(\"Structural Connections.png\")\n",
    "        \n",
    "    def char_path_len(self,G):\n",
    "        cpl = nx.all_pairs_shortest_path_length(G)\n",
    "        my_array = []\n",
    "        my_key = []\n",
    "        cpl_count = []\n",
    "        for idx in cpl:\n",
    "            myarray = cpl[idx]\n",
    "            min_val = min(ii for ii in myarray if ii > 0) # Find min length\n",
    "            for key,length in myarray.iteritems():\n",
    "                if length == min_val:\n",
    "                    my_key = np.append(my_key,key)\n",
    "            my_count = len(my_key) # Find number of edges of that length\n",
    "            cpl_count = np.append(cpl_count,my_count)\n",
    "            my_key = []\n",
    "            cpl_avg = np.mean(cpl_count) # Find average of those edges\n",
    "        return cpl_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrianVisualization:\n",
    "    '''\n",
    "    Function 4: Visualization of Brian \n",
    "    Define LIF neural population in Brian\n",
    "    Call to save spike times\n",
    "    Call to plot voltage monitor\n",
    "    Call to plot raster plot\n",
    "    Call to plot histogram\n",
    "    \n",
    "    Description:\n",
    "    Will plot the voltage monitor, raster plot, and histogram of neural network\n",
    "    \n",
    "    Returns:\n",
    "        G: NeuronGroup\n",
    "        spike_times: Spike times for neuron 0\n",
    "        all_spikes: Spike times for all neurons\n",
    "        \n",
    "    \n",
    "    Parameters:\n",
    "        statemon: StateMonitor\n",
    "        spikemon: SpikeMonitor\n",
    "        run_time: Simulation run time\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "        \n",
    "        start_scope()\n",
    "    \n",
    "    def network1(self,rows,cols,connect_W,N):\n",
    "        '''\n",
    "        For full synch: G1.v = fixed\n",
    "                        PI = off\n",
    "        '''\n",
    "        eqs = '''\n",
    "        dv/dt = (I-v)/tau : 1 (unless refractory)\n",
    "        I : 1\n",
    "        tau : second\n",
    "        '''\n",
    "                \n",
    "        G1 = NeuronGroup(N, eqs, threshold='v>v_th', reset='v=v_r', refractory=10*ms, method='linear')\n",
    "        #G1.v = 'rand()' #random so changes dynamics for each neuron --> causes difference in raster\n",
    "        G1.v = '0.967188882214'\n",
    "        '''\n",
    "        Injection current is constant but with slight perturbations from PoissonInput, if that function is active\n",
    "        To get rid of highly synchronized, G1.v='rand()' and turn on P1\n",
    "        '''\n",
    "        G1.I = I_c # Constant current \n",
    "        G1.tau = tau_m1 * ms\n",
    "        \n",
    "        # PoissonInput injection current -- changes each neuron's firing rate\n",
    "        # Each neuron has different input current depending on Poisson distribution\n",
    "        PI_num = 0.8*N \n",
    "        #subG1 = G1[int(PI_num):] # Top 20% of total neurons stimulated\n",
    "        subG1 = G1[:] # All neurons stimulated via Poisson \n",
    "        '''\n",
    "        PoissonInput(target,target_var,N,rate,weight)\n",
    "        target: which neurons to send PoissonInput\n",
    "        target_var: which variable that is being changed from input\n",
    "        N: number of inputs (more input = higher firing rate)\n",
    "        rate: rate of input (100Hz = 10ms per spike)\n",
    "        weight: amount added to voltage\n",
    "        '''\n",
    "        #P1 = PoissonInput(subG1, 'v', 5, 100*Hz, weight=0.1) # PoissonInput on\n",
    "        P1 = PoissonInput(subG1, 'v', 5, 100*Hz, weight=0) # PoissonInput off\n",
    "\n",
    "        \n",
    "        S1 = Synapses(G1, G1, 'w : 1', on_pre='v_post += w')\n",
    "        S1.connect(i=rows, j=cols) # Adjacency matrix from Adj.weighted\n",
    "        S1.w = connect_W/float(100) # Weighted matrix \n",
    "                \n",
    "        return G1,S1,P1\n",
    "    \n",
    "    def network2(self,rows,cols,connect_W,N):\n",
    "        '''\n",
    "        Start off w/ identical network parameters as network 1, but need to eventually change connect_W (its interconnections)\n",
    "        If P2 turned on, may need to increase S3.w so network 1 influence is higher than PoissonInput\n",
    "        '''\n",
    "        eqs = '''\n",
    "        dv/dt = (I-v)/tau : 1 (unless refractory)\n",
    "        I : 1\n",
    "        tau : second\n",
    "        '''\n",
    "\n",
    "        G2 = NeuronGroup(N, eqs, threshold='v>v_th', reset='v=v_r', refractory=10*ms, method='linear')\n",
    "        #G2.v = '0.967188882214' # For debugging of coupling so that all nodes in G2 will fire at same rate\n",
    "        G2.v = 'rand()'\n",
    "        G2.I = I_c\n",
    "        G2.tau = tau_m2 * ms\n",
    "        \n",
    "        subG2 = G2[:]\n",
    "        P2 = PoissonInput(subG2, 'v', 5, 100*Hz, weight=0.1)\n",
    "        \n",
    "        S2 = Synapses(G2, G2, 'w:1', on_pre='v_post += w')\n",
    "        S2.connect(i=rows, j=cols) # Network 2 has same inter-network connections as Network 1\n",
    "        S2.w = connect_W/float(100)\n",
    "        \n",
    "        return G2,S2,P2\n",
    "\n",
    "    def network_coupling(self,N,p_couple,w_couple,G1,G2):\n",
    "        '''\n",
    "        Should see how coupling between different subpopulation has global effects (raster plot)\n",
    "            - Could see difference if neurons have same firing rate (non-PoissonInput) vs. different firing rate (all-PoissonInput)\n",
    "            - May only want to record (Statemon, Spikemon) from this last coupling (G2) to save resources\n",
    "                - See Monitoring Synaptic Variables from http://brian2.readthedocs.io/en/2.0.1/user/synapses.html\n",
    "            = Can introduce multiple output synapses (multisynaptic_index from http://brian2.readthedocs.io/en/2.0.1/user/synapses.html)\n",
    "                - Or more simply \"S.connect(i=numpy.arange(10), j=1)\"\n",
    "        '''\n",
    "        S3 = Synapses(G1,G2, 'w:1', on_pre='v_post += w')#, delay=5*ms) # G1 drives G2\n",
    "        \n",
    "        ### Manually defining coupling ###\n",
    "        p_couple2 = p_couple*N\n",
    "        i_couple = 0.8*N\n",
    "        \n",
    "        # If want 1:1 for only first p_couple% neurons (excitatory --> excitatory)\n",
    "        c_rows = list(arange(0,p_couple2,dtype=int)) # Source neurons\n",
    "        c_cols = list(arange(0,p_couple2,dtype=int)) # Target neurons\n",
    "        \n",
    "        # If want 1:1 for only last p_couple% neurons \n",
    "        #c_rows = list(arange(N-p_couple2,N,dtype=int))\n",
    "        #c_cols = list(arange(N-p_couple2,N,dtype=int))\n",
    "        \n",
    "        # If want 1:1 for inhibitory onto inhibitory neurons\n",
    "        #c_rows = list(arange(N-i_couple,N,dtype=int))\n",
    "        #c_cols = list(arange(N-i_couple,N,dtype=int))        \n",
    "        \n",
    "        # If want 1:1 for projection of excitatory onto inhibitory neurons\n",
    "        #c_rows = list(arange(0,p_couple2,dtype=int))\n",
    "        #c_cols = list(arange(N-i_couple,N,dtype=int))\n",
    "        \n",
    "        # If want 1:! for projection of inhibitory onto excitatory neurons\n",
    "        #c_rows = list(arange(N-p_couple2,N,dtype=int))\n",
    "        #c_cols = list(arange(0,p_couple2,dtype=int))\n",
    "        \n",
    "        S3.connect(i=c_rows, j=c_cols) # Manually defined coupling\n",
    "        S3.w = w_couple\n",
    "        ###################################\n",
    "        \n",
    "        ##### Probabilistic coupling #####\n",
    "        #S3.connect(p=0.05) # Probabilistic connection - Chance that G2 will connect with and spike from G1\n",
    "        #S3.w = 0.02\n",
    "        #S3.connect(p=p_couple)\n",
    "        ###################################\n",
    "                \n",
    "        # Coupling matrix\n",
    "        coup_mat = [[0 for x in range(N)] for y in range(N)]\n",
    "\n",
    "        for ii in range(len(c_rows)):\n",
    "            for jj in range(len(c_cols)):\n",
    "                coup_mat[ii][ii] = 1\n",
    "\n",
    "        statemon1 = StateMonitor(G1, 'v', record=0) # Records just neuron 0 to save resources\n",
    "        spikemon1 = SpikeMonitor(G1, variables='v')\n",
    "        statemon2 = StateMonitor(G2, 'v', record=0) # Records just neuron 0 to save resources\n",
    "        spikemon2 = SpikeMonitor(G2, variables='v')\n",
    "                \n",
    "        run(run_time*ms, 'text')\n",
    "\n",
    "        return statemon1,spikemon1,statemon2,spikemon2,c_rows,c_cols,coup_mat\n",
    "        \n",
    "    def spike_time(self,spikemon):\n",
    "        all_values = spikemon.all_values()\n",
    "        spike_times = all_values['t'][0] # Spike times for just neuron 0\n",
    "        all_spikes = spikemon.t/ms # Spike times for all neurons\n",
    "        \n",
    "        return spike_times,all_spikes\n",
    "        \n",
    "    def voltage_monitor(self,statemon):\n",
    "        plot(statemon.t/ms, statemon.v[0])\n",
    "        #plot(statemon.t/ms, statemon.v[1])  # Plots second neuron      \n",
    "        ylabel('Voltage (V)')\n",
    "        xlabel('Time (ms)')\n",
    "        \n",
    "    def raster_plot(self,spikemon,spikemon_other):\n",
    "        #ion()\n",
    "        plot(spikemon.t/ms, spikemon.i, '.r')\n",
    "        plot(spikemon_other.t/ms, spikemon_other.i, '.k') # Plots overlay of each network\n",
    "        xlabel('Time (ms)')\n",
    "        ylabel('Neuron index');\n",
    "        #plt.show(block=True)\n",
    "        \n",
    "    def spike_hist(self,run_time,all_spikes):\n",
    "        my_bins = arange(0,run_time+2,2)\n",
    "        plt.hist(all_spikes, bins=my_bins)\n",
    "        xlabel('Time (ms)')\n",
    "        ylabel('Total number of spikes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynchronicityCalculation:\n",
    "    '''\n",
    "    To calculate different metrics of synchronicity\n",
    "    \n",
    "    For more information:\n",
    "        See Synch Metrics bookmarks folder\n",
    "        http://wwwold.fi.isc.cnr.it/users/thomas.kreuz/sourcecode.html\n",
    "        https://arxiv.org/pdf/1603.03293.pdf\n",
    "        http://mariomulansky.github.io/PySpike/pyspike.html#pyspike.SpikeTrain.SpikeTrain\n",
    "        http://mariomulansky.github.io/PySpike/index.html\n",
    "        http://www.scholarpedia.org/article/Measures_of_spike_train_synchrony#ISI-distance\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "\n",
    "    def Initialize(self,spikemon1,spikemon2):\n",
    "        st1 = spk.SpikeTrain(list(spikemon1.t/ms), edges=[0,run_time])\n",
    "        st2 = spk.SpikeTrain(list(spikemon2.t/ms), edges=[0,run_time])\n",
    "\n",
    "        return st1,st2\n",
    "\n",
    "    def SPIKEsynch(self,spikemon1,spikemon2):\n",
    "        '''\n",
    "        SPIKE-synchronization measures similarity where 0 means absence of synchrony and bounded to 1\n",
    "        indicating absolute synchrony\n",
    "        '''\n",
    "        spike_sync = spk.spike_sync([st1,st2])\n",
    "        #print spike_sync\n",
    "\n",
    "        # Plotting SPIKE-synchronicity\n",
    "        spike_profile = spk.spike_sync_profile([st1,st2])\n",
    "        x,y = spike_profile.get_plottable_data()\n",
    "        plot(x,y,'-k')\n",
    "        ylabel('SPIKE-sync')\n",
    "\n",
    "    def ISIdistance(self,spikemon1,spikemon2):\n",
    "        '''\n",
    "        ISI-distance quantifies dissimilarity based on differences of interspike intervals from two\n",
    "        different spike trains. Becomes 0 for identical spike trains and approaches -1 and 1 when\n",
    "        first or second spike train is faster than the other, respectively.\n",
    "        '''\n",
    "        isi_prof = spk.isi_profile(st1,st2)\n",
    "        isi_dist = isi_prof.avrg()\n",
    "        #print isi_dist # Outputs nan if spike train has same time values\n",
    "\n",
    "        # Plotting ISI profile\n",
    "        x,y = isi_prof.get_plottable_data()\n",
    "        plot(x,y,'-k')\n",
    "        ylabel('ISI')\n",
    "\n",
    "    def SPIKEdistance(self,spikemon1,spikemon2):\n",
    "        '''\n",
    "        SPIKE-distance quantifies dissimilarity based on exact spike timings. In other words,\n",
    "        dissimilarity in terms of deviations from exact coincidences of spikes\n",
    "        Becomes 0 for identical spike trains, and bounded by 1 for highly dissimilar\n",
    "        '''\n",
    "        spike_dist = spk.spike_distance([st1,st2])\n",
    "        #print spike_dist\n",
    "\n",
    "        spike_profile = spk.spike_profile([st1,st2])\n",
    "        x,y = spike_profile.get_plottable_data()\n",
    "        plot(x,y,'-k')\n",
    "        xlabel('Time (ms)')\n",
    "        ylabel('SPIKE-dist')\n",
    "\n",
    "    def CrossCorrelation(self,spikemon1,spikemon2):\n",
    "        # Normalize spike times\n",
    "        norm1 = spikemon1.t / np.linalg.norm(spikemon1.t)\n",
    "        norm2 = spikemon2.t / np.linalg.norm(spikemon2.t)\n",
    "        test1 = norm1\n",
    "        test2 = norm2\n",
    "        y = np.correlate(test1,test2,\"full\") \n",
    "        z = np.correlate(test1,test1,\"full\") \n",
    "\n",
    "        # Plotting correlation\n",
    "        x_valy = range(len(y))\n",
    "        x_valz = range(len(z))\n",
    "        plot(x_valy-np.argmax(z/ms),y,'b')\n",
    "        plot(x_valz-np.argmax(z/ms),z,'g')\n",
    "        blue_patch = mpatches.Patch(color='blue', label='Test Correlation')\n",
    "        green_patch = mpatches.Patch(color='green', label='Autocorrelation')\n",
    "        suptitle('Comparing network 2 to network 1', fontsize=14, fontweight='bold')\n",
    "        plt.legend(handles=[blue_patch,green_patch])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average characteristic path length:\n",
      "2.99\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Sample function 1 calling\n",
    "Change parameters to fit neural model\n",
    "Computes weighted adjacency matrix\n",
    "\n",
    "Parameters to be user-defined:\n",
    "    n: nodes\n",
    "    m: edges\n",
    "    k: each node is connected to k nearest neightbors\n",
    "    p: probability of adding new edge for each edge\n",
    "    d: degree of each node\n",
    "'''\n",
    "# Sample call function\n",
    "n = 200 # Kills kernel at n = 250, m=375 possibly b/c cpu limitations\n",
    "m = 300\n",
    "k = 2\n",
    "p = 0.2\n",
    "d = 2\n",
    "rand_seed = np.random.seed(int(time.time())) # To seed random number generator based on time\n",
    "\n",
    "Adj = AdjacencyMatrix(n) # Initiates \n",
    "\n",
    "#[A,G] = Adj.all_to_all(n) # Defines all-to-all topology\n",
    "[A,G] = Adj.random(n,m) # Defines random topology\n",
    "#[A,G] = Adj.small_world(n,k,p) # Defines small-world topology\n",
    "#[A,G] = Adj.regular(d,n) # Defines regular topology\n",
    "#[A,G] = Adj.scale_free(n) # Defines scale-free topology\n",
    "\n",
    "W,rows,cols,connect_W,new_coord,A_temp5,myW = Adj.Weighted(A,n) # Output\n",
    "\n",
    "'''\n",
    "Sample function 2 calling\n",
    "First plot: cluster coefficient for each neuron\n",
    "Second plot: excitatory (r) and inhibitory (b) connections\n",
    "'''\n",
    "vis = Visualization() # Initiates \n",
    "cc_avg = vis.cluster_coeff(G) # Calculates average cluster coefficient\n",
    "\n",
    "vis.ex_in_connec(G,connect_W) # Plots excitatory/inhibitory connections\n",
    "cpl_avg = vis.char_path_len(G) # Calculates average characteristic path length\n",
    "print \"Average characteristic path length:\"\n",
    "print cpl_avg\n",
    "\n",
    "#show(block=True) # Show Network connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation at t=0. s for a duration of 1. s\n",
      "100. us (0%) simulated in 34s, estimated 3d 22h 34m 54s remaining.\n",
      "1. s (100%) simulated in 36s\n",
      "Total runtime:\n",
      "48.3402359486\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Sample function 4 calling\n",
    "Change parameters to fit neural model\n",
    "Simulates leaky integrate-and-fire neuron model\n",
    "\n",
    "Parameters:\n",
    "    N: number of neurons\n",
    "    tau_m: time constant (ms)\n",
    "    v_r = reset membrane potential (mv)\n",
    "    v_th = threshold membrane potential (mv)\n",
    "    I_c = constant input current\n",
    "    run_time = simulation time (ms)\n",
    "    p_couple = probability that neuron i in first net will couple with neuron i in second net\n",
    "    w_couple = coupling weight (influence from net1 to net2)\n",
    "'''\n",
    "N = n \n",
    "tau_m1 = 20.4 #37\n",
    "tau_m2 = 32.4 #43\n",
    "v_r = 0 \n",
    "v_th = 1 \n",
    "I_c = 2 \n",
    "run_time = 1000\n",
    "p_couple = 0.1 #0.99 \n",
    "w_couple = 0.5 #1 \n",
    "'''\n",
    "Coupling weight seems to influence how long two nets will stay coupled together\n",
    "But it doesn't seem to look like there's a big difference between w=5 and w=5000\n",
    "The difference is only clearly visible if network 1 has fixed voltage and PoissonInput off\n",
    "'''\n",
    "BrianVis = BrianVisualization() # Initiates\n",
    "\n",
    "run_t = time.time() # Records initial runtime\n",
    "\n",
    "[G1,S1,P1] = BrianVis.network1(rows,cols,connect_W,N) # Runs LIF model for first network\n",
    "[G2,S2,P2] = BrianVis.network2(rows,cols,connect_W,N) # Runs LIF model for second network\n",
    "[statemon1,spikemon1,statemon2,spikemon2,c_rows,c_cols,coup_mat] = BrianVis.network_coupling(N,p_couple,w_couple,G1,G2) # Couples first and second networks\n",
    "\n",
    "elapsed = time.time() - run_t # Calculates elapsed runtime\n",
    "print 'Total runtime:'\n",
    "print elapsed # Prints elpased runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculating synchronicity metrics (SPIKE-synchronicity,ISI-distance,SPIKE-distance)\n",
    "'''\n",
    "Sync = SynchronicityCalculation() # Initiates\n",
    "[st1,st2] = Sync.Initialize(spikemon1,spikemon2)\n",
    "\n",
    "fig1 = plt.subplot(411)\n",
    "suptitle('Synchronicity Metrics', fontsize=14, fontweight='bold')\n",
    "BrianVis.raster_plot(spikemon2,spikemon1)\n",
    "    # Red == Network2 (target network)\n",
    "    # Black == Network1 (source network)\n",
    "\n",
    "fig2 = plt.subplot(412,sharex=fig1)\n",
    "Sync.SPIKEsynch(st1,st2) # Plots SPIKE-synchronization\n",
    "\n",
    "fig3 = plt.subplot(413,sharex=fig1)\n",
    "Sync.ISIdistance(st1,st2) # Plots ISI-distance\n",
    "\n",
    "fig4 = plt.subplot(414,sharex=fig1)\n",
    "Sync.SPIKEdistance(st1,st2) # Plots SPIKE-distance\n",
    "\n",
    "figManager = plt.get_current_fig_manager()\n",
    "figManager.window.showMaximized()\n",
    "\n",
    "show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plotting cross-correlation\n",
    "'''\n",
    "Sync = SynchronicityCalculation() # Initiates\n",
    "\n",
    "Sync.CrossCorrelation(spikemon1,spikemon2)\n",
    "\n",
    "figManager = plt.get_current_fig_manager()\n",
    "figManager.window.showMaximized()\n",
    "\n",
    "show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Plotting network dynamics (raster and PSTH)\n",
    "'''\n",
    "\n",
    "# Network 1 voltage monitor\n",
    "#suptitle('Network 1 voltage monitor', fontsize=14, fontweight='bold')\n",
    "#BrianVis.voltage_monitor(statemon1) # Plots voltage monitor\n",
    "\n",
    "# Network 2 voltage monitor\n",
    "#suptitle('Network 2 voltage monitor', fontsize=14, fontweight='bold')\n",
    "#BrianVis.voltage_monitor(statemon2) # Plots voltage monitor\n",
    "\n",
    "# Gather data for network 1\n",
    "[spike_times,all_spikes] = BrianVis.spike_time(spikemon1)\n",
    "\n",
    "# Network 1 raster\n",
    "fig1 = plt.subplot(221)\n",
    "suptitle('Two network raster and PSTH', fontsize=14, fontweight='bold')\n",
    "BrianVis.raster_plot(spikemon1,spikemon1) \n",
    "    # Network 1 in black (second input)\n",
    "\n",
    "# Network 1 PSTH\n",
    "fig2 = plt.subplot(222, sharex=fig1)\n",
    "BrianVis.spike_hist(run_time,all_spikes) \n",
    "\n",
    "# Gather data for network 2\n",
    "[spike_times,all_spikes] = BrianVis.spike_time(spikemon2)\n",
    "\n",
    "# Network 2 raster\n",
    "fig3 = plt.subplot(223, sharex=fig1, sharey=fig1)\n",
    "BrianVis.raster_plot(spikemon2,spikemon1) \n",
    "    # Network 2 in red (first input)\n",
    "    # Network 1 in black (second input)\n",
    "\n",
    "# Network 2 PSTH\n",
    "fig4 = plt.subplot(224, sharex=fig1)\n",
    "BrianVis.spike_hist(run_time,all_spikes)\n",
    "\n",
    "# Qt4Agg backend for full screen window display\n",
    "figManager = plt.get_current_fig_manager()\n",
    "figManager.window.showMaximized()\n",
    "\n",
    "show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspike.SpikeTrain.SpikeTrain object at 0x11cf68ad0>\n",
      "<pyspike.SpikeTrain.SpikeTrain object at 0x11cf804d0>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Attempt to reconfigure spike trains for better quantitation of synchronicity\n",
    "'''\n",
    "\n",
    "if 0:\n",
    "    # Attempt to separate into n rows\n",
    "\n",
    "    x1 = spikemon1.t/ms\n",
    "    tot_col = len(x1)/N\n",
    "\n",
    "    y1 = np.reshape(x,(N,tot_col),order='f') \n",
    "    #print y1[0]\n",
    "\n",
    "    # Are there 42 spikes over the course of 1 sec? Yes\n",
    "\n",
    "    x2 = spikemon2.t/ms\n",
    "    tot_col = len(x1)/N\n",
    "\n",
    "    #print len(x2)\n",
    "    #print N\n",
    "\n",
    "# Can't do spikemon2 like spikemon1 because the length is different and a neuron might have fired more often than another\n",
    "    # Now we have to compare list_spike_train1 to list(spikemon1.t/ms) to figure out why won't load right into SpikeTrain\n",
    "\n",
    "# Get spike train data from SpikeMonitor that is ordered by neuron index\n",
    "spike_trains1 = spikemon1.spike_trains()\n",
    "spike_trains2 = spikemon2.spike_trains()\n",
    "\n",
    "# Convert spike trains for each population to list\n",
    "list_spike_train1 = [ v for v in spike_trains1.values() ]\n",
    "list_spike_train2 = [ v for v in spike_trains2.values() ] # Further differentiate into spike trains for indiv. neuron?\n",
    "\n",
    "# Convert list of spike trains to list for each individual neuron\n",
    "    # Would this corrupt the synchronicty bc not just comparing population to population, but comparing inter-population and intra-population variation\n",
    "\n",
    "#convert to txt file where each line has spike times for each neuron\n",
    "spike_train1_txt = open('Spikes1.txt','w')\n",
    "for item in list_spike_train1:\n",
    "    spike_train1_txt.write(\"%s\\n\" % item)\n",
    "\n",
    "# Load spikes from saved txt file\n",
    "my_st1 = spk.load_spike_trains_from_txt(\"Spikes1.txt\",edges=[0,run_time])\n",
    "\n",
    "test_st1 = spk.load_spike_trains_from_txt(\"PySpike_testdata.txt\",edges=[0,4000])\n",
    "\n",
    "# NxM matrix where N is number of neurons and M is number of spikes for each neuron\n",
    "#isi_prof = spk.isi_profile(test_st1) # works for comparing 1 entire population (NxM matrix)\n",
    "isi_prof = spk.isi_profile(test_st1[0],test_st1[1]) # works for intra-population (1xM array)\n",
    "#isi_prof = spk.isi_profile(test,st1,test_st1) # doesn't work for comparing inter-population (2 NxM matrices)\n",
    "#isi_prof = spk.isi_profile(my_st1) # seems to be take a long time and yields 0\n",
    "isi_dist = isi_prof.avrg()\n",
    "x,y = isi_prof.get_plottable_data()\n",
    "plot(x,y,'-k')\n",
    "ylabel('ISI')\n",
    "#axes = plt.gca()\n",
    "#axes.set_ylim([0,0.6]) # set axes\n",
    "\n",
    "figManager = plt.get_current_fig_manager()\n",
    "figManager.window.showMaximized()\n",
    "\n",
    "show(block=True)\n",
    "\n",
    "if 0:\n",
    "    # Second attempt - doesn't work\n",
    "    outarr = np.vstack(list_spike_train1)\n",
    "    np.savetxt(\"Spikes2.txt\",outarr.T)\n",
    "\n",
    "    # Third attempt - doesn't work\n",
    "    import json\n",
    "    with open('Spikes3.txt','w') as myfile:\n",
    "        json.dump(list_spike_train1,myfile)\n",
    "\n",
    "#my_st1 = spk.SpikeTrain(list(spikemon1.t/ms), edges=[0,run_time])\n",
    "\n",
    "if 0:\n",
    "    '''\n",
    "    Calculating synchronicity metrics (SPIKE-synchronicity,ISI-distance,SPIKE-distance) with reshaped spikemon\n",
    "    '''\n",
    "    Sync = SynchronicityCalculation() # Initiates\n",
    "    [st1,st2] = Sync.Initialize(spikemon1,spikemon2)\n",
    "\n",
    "    fig1 = plt.subplot(411)\n",
    "    suptitle('Synchronicity Metrics', fontsize=14, fontweight='bold')\n",
    "    BrianVis.raster_plot(spikemon2,spikemon1)\n",
    "        # Red == Network2 (target network)\n",
    "        # Black == Network1 (source network)\n",
    "\n",
    "    fig2 = plt.subplot(412,sharex=fig1)\n",
    "    Sync.SPIKEsynch(st1,st2) # Plots SPIKE-synchronization\n",
    "\n",
    "    fig3 = plt.subplot(413,sharex=fig1)\n",
    "    Sync.ISIdistance(st1,st2) # Plots ISI-distance\n",
    "\n",
    "    fig4 = plt.subplot(414,sharex=fig1)\n",
    "    Sync.SPIKEdistance(st1,st2) # Plots SPIKE-distance\n",
    "\n",
    "    figManager = plt.get_current_fig_manager()\n",
    "    figManager.window.showMaximized()\n",
    "\n",
    "    show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pyspike",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1f14d99de4c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyspike\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named pyspike"
     ]
    }
   ],
   "source": [
    "import pyspike as spk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
