{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Simplified LIF model to experiment w/ NetworkX and Brian2\n",
    "\n",
    "Current status on runtime:\n",
    "~75 seconds for n=200, m=300 at 200 ms initially\n",
    "On consecutive runs, time reduces to ~1 second under same conditions == hysteresis effect? \n",
    "Want to collect times once reach steady-state, so have to keep running until runtime difference is not significant\n",
    "    and that's what you would record and compare with FPGA (would need to keep testing CPU and specs constant)\n",
    "\n",
    "For FPGA testing:\n",
    "1. Change any random values to specific values (rand_temp,W,G.v,PoissonInput)\n",
    "2. Figure out what variables need to be saved and sent to FPGA (c_rows,c_cols)\n",
    "\n",
    "Manipulatable variables:\n",
    "S3.connect\n",
    "S3.w\n",
    "PoissonInputs\n",
    "G_.v\n",
    "tau_m1\n",
    "tau_m2\n",
    "p_couple\n",
    "w_couple\n",
    "\n",
    "Variables of interest:\n",
    "rows = source neuron numbers (numpy.ndarray)\n",
    "cols = target neuron numbers (numpy.ndarray)\n",
    "connect_W = weight array (numpy.ndarray)\n",
    "A_temp5 = adjacency matrix (numpy.ndarray)\n",
    "myW = weight adjacency matrix (numpy.ndarray)\n",
    "c_rows = manually defined source neurons from coupling\n",
    "c_cols = manually defined target neurons from coupling\n",
    "coup_mat = coupling matrix (source x target)\n",
    "spikemon1.t = spike trains for source network\n",
    "spikemon2.t = spike trains for target network\n",
    "rand_seed = seed to initiate randomization\n",
    "\n",
    "Final output variables for Synapses group: \n",
    "ADJ matrix = rows (source), cols (target), A_temp5 (matrix form), c_rows (coupled), c_cols (coupled)\n",
    "WT matrix = connect_W (weights between source-target in order of (rows,cols))\n",
    "WT-ADJ matrix = myW (shows entire n*n matrix w/ E/I/non-connections) \n",
    "\n",
    "Work in progress for computer simulation:\n",
    "0) Is there a workable threshold for number of neurons and connections?\n",
    "    - Try establishing a maximum number of n and m before kernel crashes\n",
    "    - Why does it appear that the top 80% of neurons are behaving differently (if n=250, n_weird=200->250)?\n",
    "        - Yup, it's because excit_num\n",
    "        - Inhibitory neurons have significantly decreased firing rate, but it shouldn't be that?\n",
    "1) By changing coupling weight (S3.w), how does synchronicity change (see HH paper when they changed conductance & Fred \n",
    "        email 2/20)\n",
    "    - One run function to go through different values of coupling weight and output many graphs\n",
    "        OR individually go through different run functions that have specified coupling weight values and output 1 graph at a time\n",
    "2) Once we have correct parameters, we can start manipulating different network parameters/topology\n",
    "    - Would want different topology/parameters for each source/target network because they wouldn't be homogeneous \n",
    "3) Cleaner user interface where you only have to change the function instead of the source code\n",
    "\n",
    "Work in progress for FPGA simulation:\n",
    "1) Change values to match FPGA, e.g. 16-bit precision (dtype=int16) (?)\n",
    "\n",
    "Example of synchronicity:\n",
    "https://www.youtube.com/watch?v=yVkdfJ9PkRQ\n",
    "''' and None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import time\n",
    "from brian2 import *\n",
    "#%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### NOTE\n",
    "pyspike: Python library for the numerical analysis of spike train similarity.\n",
    "http://mariomulansky.github.io/PySpike/\n",
    "n:nodes, m:edges\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyMatrix:  \n",
    "    '''\n",
    "    Function 1: Weighted adjacency matrix\n",
    "    Call to initiate adjacency matrix\n",
    "    Call to choose which neural network topology with given parameters\n",
    "    \n",
    "    Description:\n",
    "    Given parameters, constructs network with adjacency matrix and applies random weights.\n",
    "    \n",
    "    Returns:\n",
    "        G: NetworkX Graph\n",
    "        A: Adjacency matrix. Sparse matrix\n",
    "        rows: Presynaptic neurons\n",
    "        cols: Postsynaptic neurons\n",
    "        connect_W: Weights for each E/I connection (in order of rows,cols)\n",
    "    \n",
    "    Parameters:\n",
    "        n: nodes\n",
    "        m: edges\n",
    "        k: neighbor connections\n",
    "        p: probability \n",
    "        d: degrees\n",
    "    '''\n",
    "    def __init__(self,n): \n",
    "        plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "        \n",
    "    def all_to_all(self,n):\n",
    "        G = nx.complete_graph(n) #returns a graph with 0 to n-1 nodes, all nodes are connected to each other\n",
    "        #nx.draw(G, with_labels=True) # Draws plot with node labels\n",
    "        #plt.show(G) #To display graph in a figure window\n",
    "        #plt.savefig(\"All to all.png\") # If want to save topology image\n",
    "        A = nx.adjacency_matrix(G) # Outputs unit adjacency matrix\n",
    "        #print(A) #To see adjacency matrix, A...it's all ones as every node is connected to each other besides themselves\n",
    "        return A, G\n",
    "\n",
    "    def random(self,n,m): \n",
    "        # Interchangeable based on UI for different types of topography\n",
    "        G = nx.dense_gnm_random_graph(n,m) # Uses NetX to generate random topography\n",
    "        #nx.draw(G, with_labels=True) # Draws connectivity figure\n",
    "        #plt.savefig(\"Random.png\") # Saves connectivity figure as Random.png\n",
    "\n",
    "        # Extracts ADJACENCY MATRIX from topography and rearranges to manageable array of (n*n) elements\n",
    "        A = nx.adjacency_matrix(G) # Assigns A as adjacency matrix (which nodes are connected)\n",
    "        return A, G \n",
    "    \n",
    "    def small_world(self,n,k,p): \n",
    "        G = nx.newman_watts_strogatz_graph(n,k,p) #n nodes in a ring, k nearest neighbours to connect \n",
    "                                                  #a node with... \n",
    "                                                  #add edge with a probability p for each edge\n",
    "        #nx.draw(G, with_labels=True)\n",
    "        #plt.savefig(\"Small-world.png\")\n",
    "        A = nx.adjacency_matrix(G)\n",
    "        return A, G\n",
    "    \n",
    "    def regular(self,d,n): \n",
    "        G = nx.random_regular_graph(d,n) #d, degree(number of edges adjacent to that node) of node\n",
    "        #nx.draw(G, with_labels=True)\n",
    "        #plt.savefig(\"Regular.png\")\n",
    "        A = nx.adjacency_matrix(G)\n",
    "        return A, G\n",
    "    \n",
    "    def scale_free(self,n): \n",
    "        G = nx.scale_free_graph(n) \n",
    "        #nx.draw(G, with_labels=True)\n",
    "        #plt.savefig(\"Scale free.png\")\n",
    "        A = nx.adjacency_matrix(G)\n",
    "        return A, G\n",
    "\n",
    "    def Weighted(self,A,n):\n",
    "        A_temp1 = A.todense() # Converts A to manageable matrix\n",
    "        A_temp2 = np.reshape(A_temp1,(1,n**2)) # Reshapes adjacency matrix to array for calculation\n",
    "        A_temp3 = np.array(A_temp2) # Changes matrix element to type:array for calculation\n",
    "        A_temp4 = A_temp3[0] # Selects the first and only cell in array for manipulation, still array of 1 by n**2\n",
    "\n",
    "        # Generates random values for n neurons to decide whether E/I\n",
    "        rand_temp=np.random.rand(1,n) \n",
    "        rand_temp=rand_temp[0] #array of 1 by n random numbers between 0 and 1\n",
    "\n",
    "        # Changes positive to negative weights based on probability (***not necessary if define E/I in Synapses and subG)\n",
    "        if 0:\n",
    "            newlist = [] \n",
    "            for item in rand_temp:\n",
    "                if item > 0.8: # Random numbers to negative according to uniform probability\n",
    "                    item = -item \n",
    "                newlist.append(item) \n",
    "\n",
    "        # Reshapes adjacency matrix to workable matrix of n*n neurons\n",
    "        A_temp5 = np.reshape(A_temp4,(n,n)) # An n by n matrix of 1s and 0s\n",
    "\n",
    "        # Generates random weights for each connection (assuming all-all) w/o self-feedback\n",
    "        #W = np.random.rand(n,n) \n",
    "        W = np.random.randint(100, size=[n,n])\n",
    "        W_n = W\n",
    "        np.fill_diagonal(W,0) # Neurons are not self-connected\n",
    "        myW = W # n by n array of random ints upto 100 with zeros on diagonal\n",
    "\n",
    "        # Prep for calculation of final weight matrix (basically just replacing all '1' in ADJ mat w/ corresponding WT mat)\n",
    "        A_temp=np.reshape(A_temp5,(n**2,1)) # Reshapes A for multiplication\n",
    "        W_temp=np.reshape(W,(1,n**2)) # Reshapes W for multiplication\n",
    "        W=A_temp * W_temp # Makes (n**2)x(n**2) matrix of adjacency matrix times weights\n",
    "        W=W.diagonal() \n",
    "        W=np.reshape(W,(n,n)) # n by n, adjacency * random weight matrix. 0s for no connections\n",
    "        \n",
    "        # Gets the index values for source(rows)/target(cols) neurons \n",
    "        rows, cols = np.nonzero(A_temp5)\n",
    "\n",
    "        # Gets rid of duplicate connections (bidirectional --> unidirectional)\n",
    "        new_coord = zip(rows,cols) # To get an array of coordinate pair tuples, to define node pairs or edges \n",
    "        #print new_coord\n",
    "        new_rows = set(tuple(sorted(l)) for l in new_coord) # set removes duplicate tuples that are now ordered pairs\n",
    "        # set(array of tuples)\n",
    "        g = np.array(list(new_rows)) #array of 1 by 2 neuron pair vectors that are connected to each other\n",
    "        # In each 1 by 2 vector: column 0 is source neuron and column 1 is target neuron\n",
    "        rows = g[:,0] #1-D array of all source neurons i\n",
    "        cols = g[:,1] #1-D array of all target neurons j\n",
    "        new_coord = zip(rows,cols) # list of tuples, source and target ordered pairs with no duplicates\n",
    "\n",
    "        # To duplicate values above diagonal onto spots below diagonal\n",
    "        for x in range(len(myW)): # creates array from 0 to n-1 to iterate through\n",
    "            for y in range(len(myW)):\n",
    "                myW[y,x] = myW[x,y] # symmetrical array of random weights with 0s on diagonal\n",
    "\n",
    "        # Generates weight matrix in array that's necessary for Synapses in Brian2\n",
    "        # Values are in order of new_coord array\n",
    "        connect_W = []\n",
    "        for i in range(len(new_coord)): # iterate for number of neuron pairs or edges\n",
    "            connect_W.append(W[new_coord[i]])\n",
    "        connect_W = np.array(connect_W) # a 1-D array defining strength of each unique connection \n",
    "\n",
    "        # Changes weights (in array) to inhibitory if coming from an inhibitory neuron (upper 20% of n)\n",
    "        excit_num = int(0.8*n) # Index for 0:excitatory neurons\n",
    "        for x in range(len(new_coord)):\n",
    "            for y in (0,1):\n",
    "                if new_coord[x][y] >= excit_num: # Any neuron index greater than excit_num is inhibitory\n",
    "                    connect_W[x] = -connect_W[x] # weight array with random ints and upper portion -ve\n",
    "                    #final_W.append(connect_W(x))\n",
    "                    \n",
    "        # Changes weights (in matrix) to inhibitory if coming from an inhibitory neuron (upper 20% of n)\n",
    "        for x in range(len(myW)):\n",
    "            for y in range(len(myW)):\n",
    "                if x >= excit_num:\n",
    "                    myW[x,y] = -myW[x,y]\n",
    "                if y >= excit_num:\n",
    "                    myW[x,y] = -myW[x,y] # n by n weight matrix with random ints and upper portion -ve\n",
    "        \n",
    "        return W, rows, cols, connect_W, new_coord, A_temp5, myW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualization:\n",
    "    '''\n",
    "    Function 2: Visualize neural network\n",
    "    Inputs graph G \n",
    "    Returns cluster coefficient & characteristic path length\n",
    "        & plot of connections between neurons (color-coded)\n",
    "    For more info: see collective dynamics paper\n",
    "    \n",
    "    Description:\n",
    "    From network model, determines cluster coefficient and characteristic path length for each\n",
    "        node. For each network, will take average of those values, respectively and yield \n",
    "        single integer value.\n",
    "    From network model, will output plot of connections, color-coded for excitatory and\n",
    "        inhibitory.\n",
    "    \n",
    "    Returns:\n",
    "        cc_avg: Cluster coefficient averaged over all nodes\n",
    "        ex_in_plot: Plot of colored excitatory/inhibitory connections\n",
    "        cpl_avg: Number of edges at shortest path over all nodes \n",
    "        \n",
    "    Parameters:\n",
    "        G: NetworkX Graph from Function 1\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        #plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "\n",
    "    def cluster_coeff(self,G):        \n",
    "        cc = nx.clustering(G) # calculate clustering co-eff according to different rules eg. no of triangles going through node\n",
    "        # outputs co-eff for all or specified nodes in dict form\n",
    "        cc_y=[]\n",
    "        for idx in cc:\n",
    "            cc_y=np.append(cc_y,cc[idx]) # access and append dict values (co-effs in this case) to array\n",
    "        \n",
    "        cc_avg = np.ndarray.mean(cc_y, dtype=np.float64)\n",
    "        return cc_avg\n",
    "    \n",
    "    def ex_in_connec(self,G,connect_W):\n",
    "        plt.figure()\n",
    "        red_patch = mpatches.Patch(color='red', label='Excitatory')\n",
    "        blue_patch = mpatches.Patch(color='blue', label='Inhibitory')\n",
    "        plt.legend(handles=[red_patch,blue_patch])\n",
    "        suptitle('Structural Connections', fontsize=14, fontweight='bold')\n",
    "\n",
    "        edges = G.edges() # list of tuple pairs\n",
    "        nodes = G.nodes() # array of nodes\n",
    "\n",
    "        custom_color={}\n",
    "        for idx in range(len(connect_W)):\n",
    "            if connect_W[idx] < 0:\n",
    "                inhib_edge = new_coord[idx]\n",
    "                G.add_edge(*inhib_edge)\n",
    "                custom_color[inhib_edge]='b'\n",
    "            else:\n",
    "                excit_edge = new_coord[idx]\n",
    "                G.add_edge(*excit_edge)\n",
    "                custom_color[excit_edge]='r'\n",
    "        if 0:\n",
    "            for idx,idy in enumerate(edges):\n",
    "                x1,y1 = edges[idx]\n",
    "                if connect_W < 0:\n",
    "                    inhib_edge = (x1,y1)\n",
    "                    G.add_edge(x1,y1)\n",
    "                    custom_color[x1,y1]='b' # Stores color of edges in dict\n",
    "                else:\n",
    "                    excit_edge = (x1,y1)\n",
    "                    G.add_edge(x1,y1)\n",
    "                    custom_color[x1,y1]='r'\n",
    "        \n",
    "        ex_in_plot=nx.draw_networkx(G,node_color='w',\n",
    "                         with_labels=True,\n",
    "                         node_list=nodes,\n",
    "                         #node_size=50,\n",
    "                         node_size=200,\n",
    "                         edge_list=custom_color.keys(),\n",
    "                         edge_color=custom_color.values(),\n",
    "                         label='Blue=Inhibitory, Red=Excitatory')\n",
    "        #plt.savefig(\"Structural Connections.png\")\n",
    "        \n",
    "    def char_path_len(self,G):\n",
    "        cpl = nx.all_pairs_shortest_path_length(G) # shortest path lengths. Gen. returns tuple with source and target dict\n",
    "        my_array = []\n",
    "        my_key = []\n",
    "        cpl_count = []\n",
    "        for idx in cpl: # looping through each source node and looking at no of targets and length to target nodes\n",
    "#            myarray = cpl[idx] # cpl is a generator object. idx is a tuple (source, target dict). Should be idx[1].\n",
    "            myarray = idx[1]\n",
    "            min_val = min(ii for ii in myarray if ii > 0) # Find min length\n",
    "            for key,length in myarray.iteritems():\n",
    "                if length == min_val:\n",
    "                    my_key = np.append(my_key,key) # array of target nodes with min length for specific source node\n",
    "            my_count = len(my_key) # Find number of edges of that length\n",
    "            cpl_count = np.append(cpl_count,my_count)\n",
    "            my_key = []\n",
    "            cpl_avg = np.mean(cpl_count) # Find average of those edges\n",
    "        return cpl_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A python generator object cannot be iterated through. It is similar to a function which returns an object(iterator) that can be iterated through. eg. cpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrianVisualization:\n",
    "    '''\n",
    "    Function 4: Visualization of Brian \n",
    "    Define LIF neural population in Brian\n",
    "    Call to save spike times\n",
    "    Call to plot voltage monitor\n",
    "    Call to plot raster plot\n",
    "    Call to plot histogram\n",
    "    \n",
    "    Description:\n",
    "    Will plot the voltage monitor, raster plot, and histogram of neural network\n",
    "    \n",
    "    Returns:\n",
    "        G: NeuronGroup\n",
    "        spike_times: Spike times for neuron 0\n",
    "        all_spikes: Spike times for all neurons\n",
    "        \n",
    "    \n",
    "    Parameters:\n",
    "        statemon: StateMonitor\n",
    "        spikemon: SpikeMonitor\n",
    "        run_time: Simulation run time\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "        \n",
    "        start_scope()\n",
    "    \n",
    "    def network1(self,rows,cols,connect_W,N):\n",
    "        # rows and cols 1-D arrays of source and target neurons that are connected as defined in graph from networkx\n",
    "        # connect_W: 1-D array of strength of connections corresponding to source and target neuron pairs \n",
    "        '''\n",
    "        For full synch: G1.v = fixed\n",
    "                        PI = off\n",
    "        '''\n",
    "        eqs = '''                \n",
    "        dv/dt = (I-v)/tau : 1 (unless refractory)\n",
    "        I : 1\n",
    "        tau : second\n",
    "        '''   # Leaky integrate and fire neuron\n",
    "                \n",
    "        G1 = NeuronGroup(N, eqs, threshold='v>v_th', reset='v=v_r', refractory=10*ms, method='linear')\n",
    "        #G1.v = 'rand()' #random so changes dynamics for each neuron --> causes difference in raster\n",
    "        G1.v = '0.967188882214'\n",
    "        '''\n",
    "        Injection current is constant but with slight perturbations from PoissonInput, if that function is active\n",
    "        To get rid of highly synchronized, G1.v='rand()' and turn on P1\n",
    "        '''\n",
    "        G1.I = I_c # Constant current \n",
    "        G1.tau = tau_m1 * ms\n",
    "        \n",
    "        # PoissonInput injection current -- changes each neuron's firing rate\n",
    "        # Each neuron has different input current depending on Poisson distribution\n",
    "        PI_num = 0.8*N \n",
    "        #subG1 = G1[int(PI_num):] # Top 20% of total neurons stimulated\n",
    "        subG1 = G1[:] # All neurons stimulated via Poisson \n",
    "        '''\n",
    "        PoissonInput(target,target_var,N,rate,weight)\n",
    "        target: which neurons to send PoissonInput\n",
    "        target_var: which variable that is being changed from input\n",
    "        N: number of inputs (more input = higher firing rate)\n",
    "        rate: rate of input (100Hz = 10ms per spike)\n",
    "        weight: amount added to voltage\n",
    "        '''\n",
    "        #P1 = PoissonInput(subG1, 'v', 5, 100*Hz, weight=0.1) # PoissonInput on\n",
    "        P1 = PoissonInput(subG1, 'v', 5, 100*Hz, weight=0) # PoissonInput off\n",
    "\n",
    "        \n",
    "        S1 = Synapses(G1, G1, 'w : 1', on_pre='v_post += w') # w is the synapse weight added to the signal\n",
    "        S1.connect(i=rows, j=cols) # Adjacency matrix from Adj.weighted, this uses network structure defined on networkx\n",
    "        S1.w = connect_W/float(100) # Weighted matrix defined from networkx graph \n",
    "                \n",
    "        return G1,S1,P1\n",
    "    \n",
    "    def network2(self,rows,cols,connect_W,N):\n",
    "        '''\n",
    "        Start off w/ identical network parameters as network 1, but need to eventually change connect_W (its interconnections)\n",
    "        If P2 turned on, may need to increase S3.w so network 1 influence is higher than PoissonInput\n",
    "        '''\n",
    "        eqs = '''\n",
    "        dv/dt = (I-v)/tau : 1 (unless refractory)\n",
    "        I : 1\n",
    "        tau : second\n",
    "        '''\n",
    "\n",
    "        G2 = NeuronGroup(N, eqs, threshold='v>v_th', reset='v=v_r', refractory=10*ms, method='linear')\n",
    "        #G2.v = '0.967188882214' # For debugging of coupling so that all nodes in G2 will fire at same rate\n",
    "        G2.v = 'rand()'\n",
    "        G2.I = I_c\n",
    "        G2.tau = tau_m2 * ms\n",
    "        \n",
    "        subG2 = G2[:]\n",
    "        P2 = PoissonInput(subG2, 'v', 5, 100*Hz, weight=0.1)\n",
    "        \n",
    "        S2 = Synapses(G2, G2, 'w:1', on_pre='v_post += w')\n",
    "        S2.connect(i=rows, j=cols) # Network 2 has same inter-network connections as Network 1\n",
    "        S2.w = connect_W/float(100)\n",
    "        \n",
    "        return G2,S2,P2\n",
    "\n",
    "    def network_coupling(self,N,p_couple,w_couple,G1,G2):\n",
    "        '''\n",
    "        Should see how coupling between different subpopulation has global effects (raster plot)\n",
    "            - Could see difference if neurons have same firing rate (non-PoissonInput) vs. different firing rate (all-PoissonInput)\n",
    "            - May only want to record (Statemon, Spikemon) from this last coupling (G2) to save resources\n",
    "                - See Monitoring Synaptic Variables from http://brian2.readthedocs.io/en/2.0.1/user/synapses.html\n",
    "            = Can introduce multiple output synapses (multisynaptic_index from http://brian2.readthedocs.io/en/2.0.1/user/synapses.html)\n",
    "                - Or more simply \"S.connect(i=numpy.arange(10), j=1)\"\n",
    "        '''\n",
    "        S3 = Synapses(G1,G2, 'w:1', on_pre='v_post += w')#, delay=5*ms) # G1 drives G2\n",
    "        \n",
    "        ### Manually defining coupling ###\n",
    "        p_couple2 = p_couple*N\n",
    "        i_couple = 0.8*N\n",
    "        \n",
    "        # If want 1:1 for only first p_couple% neurons (excitatory --> excitatory)\n",
    "        c_rows = list(arange(0,p_couple2,dtype=int)) # Source neurons\n",
    "        c_cols = list(arange(0,p_couple2,dtype=int)) # Target neurons\n",
    "        \n",
    "        # If want 1:1 for only last p_couple% neurons \n",
    "        #c_rows = list(arange(N-p_couple2,N,dtype=int))\n",
    "        #c_cols = list(arange(N-p_couple2,N,dtype=int))\n",
    "        \n",
    "        # If want 1:1 for inhibitory onto inhibitory neurons\n",
    "        #c_rows = list(arange(N-i_couple,N,dtype=int))\n",
    "        #c_cols = list(arange(N-i_couple,N,dtype=int))        \n",
    "        \n",
    "        # If want 1:1 for projection of excitatory onto inhibitory neurons\n",
    "        #c_rows = list(arange(0,p_couple2,dtype=int))\n",
    "        #c_cols = list(arange(N-i_couple,N,dtype=int))\n",
    "        \n",
    "        # If want 1:! for projection of inhibitory onto excitatory neurons\n",
    "        #c_rows = list(arange(N-p_couple2,N,dtype=int))\n",
    "        #c_cols = list(arange(0,p_couple2,dtype=int))\n",
    "        \n",
    "        S3.connect(i=c_rows, j=c_cols) # Manually defined coupling\n",
    "        S3.w = w_couple\n",
    "        ###################################\n",
    "        \n",
    "        ##### Probabilistic coupling #####\n",
    "        #S3.connect(p=0.05) # Probabilistic connection - Chance that G2 will connect with and spike from G1\n",
    "        #S3.w = 0.02\n",
    "        #S3.connect(p=p_couple)\n",
    "        ###################################\n",
    "                \n",
    "        # Coupling matrix\n",
    "        coup_mat = [[0 for x in range(N)] for y in range(N)]\n",
    "\n",
    "        for ii in range(len(c_rows)):\n",
    "            for jj in range(len(c_cols)):\n",
    "                coup_mat[ii][ii] = 1      # Matrix has 1s for connections and 0s for none\n",
    "\n",
    "        statemon1 = StateMonitor(G1, 'v', record=0) # Records just neuron 0 to save resources\n",
    "        spikemon1 = SpikeMonitor(G1, variables='v')\n",
    "        statemon2 = StateMonitor(G2, 'v', record=0) # Records just neuron 0 to save resources\n",
    "        spikemon2 = SpikeMonitor(G2, variables='v')\n",
    "                \n",
    "        run(run_time*ms, 'text')\n",
    "\n",
    "        return statemon1,spikemon1,statemon2,spikemon2,c_rows,c_cols,coup_mat\n",
    "        \n",
    "    def spike_time(self,spikemon):\n",
    "        all_values = spikemon.all_values()\n",
    "        spike_times = all_values['t'][0] # Spike times for just neuron 0\n",
    "        all_spikes = spikemon.t/ms # Spike times for all neurons\n",
    "        \n",
    "        return spike_times,all_spikes\n",
    "        \n",
    "    def voltage_monitor(self,statemon):\n",
    "        plot(statemon.t/ms, statemon.v[0])\n",
    "        #plot(statemon.t/ms, statemon.v[1])  # Plots second neuron      \n",
    "        ylabel('Voltage (V)')\n",
    "        xlabel('Time (ms)')\n",
    "        \n",
    "    def raster_plot(self,spikemon,spikemon_other):\n",
    "        #ion()\n",
    "        plot(spikemon.t/ms, spikemon.i, '.r')\n",
    "        plot(spikemon_other.t/ms, spikemon_other.i, '.k') # Plots overlay of each network\n",
    "        xlabel('Time (ms)')\n",
    "        ylabel('Neuron index');\n",
    "        #plt.show(block=True)\n",
    "        \n",
    "    def spike_hist(self,run_time,all_spikes):\n",
    "        my_bins = arange(0,run_time+2,2)\n",
    "        plt.hist(all_spikes, bins=my_bins)\n",
    "        xlabel('Time (ms)')\n",
    "        ylabel('Total number of spikes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynchronicityCalculation:\n",
    "    '''\n",
    "    To calculate different metrics of synchronicity\n",
    "    \n",
    "    For more information:\n",
    "        See Synch Metrics bookmarks folder\n",
    "        http://wwwold.fi.isc.cnr.it/users/thomas.kreuz/sourcecode.html\n",
    "        https://arxiv.org/pdf/1603.03293.pdf\n",
    "        http://mariomulansky.github.io/PySpike/pyspike.html#pyspike.SpikeTrain.SpikeTrain\n",
    "        http://mariomulansky.github.io/PySpike/index.html\n",
    "        http://www.scholarpedia.org/article/Measures_of_spike_train_synchrony#ISI-distance\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "\n",
    "    def Initialize(self,spikemon1,spikemon2):\n",
    "        st1 = spk.SpikeTrain(list(spikemon1.t/ms), edges=[0,run_time])\n",
    "        st2 = spk.SpikeTrain(list(spikemon2.t/ms), edges=[0,run_time])\n",
    "\n",
    "        return st1,st2\n",
    "\n",
    "    def SPIKEsynch(self,spikemon1,spikemon2):\n",
    "        '''\n",
    "        SPIKE-synchronization measures similarity where 0 means absence of synchrony and bounded to 1\n",
    "        indicating absolute synchrony\n",
    "        '''\n",
    "        spike_sync = spk.spike_sync([st1,st2])\n",
    "        #print spike_sync\n",
    "\n",
    "        # Plotting SPIKE-synchronicity\n",
    "        spike_profile = spk.spike_sync_profile([st1,st2])\n",
    "        x,y = spike_profile.get_plottable_data()\n",
    "        plot(x,y,'-k')\n",
    "        ylabel('SPIKE-sync')\n",
    "\n",
    "    def ISIdistance(self,spikemon1,spikemon2):\n",
    "        '''\n",
    "        ISI-distance quantifies dissimilarity based on differences of interspike intervals from two\n",
    "        different spike trains. Becomes 0 for identical spike trains and approaches -1 and 1 when\n",
    "        first or second spike train is faster than the other, respectively.\n",
    "        '''\n",
    "        isi_prof = spk.isi_profile(st1,st2)\n",
    "        isi_dist = isi_prof.avrg()\n",
    "        #print isi_dist # Outputs nan if spike train has same time values\n",
    "\n",
    "        # Plotting ISI profile\n",
    "        x,y = isi_prof.get_plottable_data()\n",
    "        plot(x,y,'-k')\n",
    "        ylabel('ISI')\n",
    "\n",
    "    def SPIKEdistance(self,spikemon1,spikemon2):\n",
    "        '''\n",
    "        SPIKE-distance quantifies dissimilarity based on exact spike timings. In other words,\n",
    "        dissimilarity in terms of deviations from exact coincidences of spikes\n",
    "        Becomes 0 for identical spike trains, and bounded by 1 for highly dissimilar\n",
    "        '''\n",
    "        spike_dist = spk.spike_distance([st1,st2])\n",
    "        #print spike_dist\n",
    "\n",
    "        spike_profile = spk.spike_profile([st1,st2])\n",
    "        x,y = spike_profile.get_plottable_data()\n",
    "        plot(x,y,'-k')\n",
    "        xlabel('Time (ms)')\n",
    "        ylabel('SPIKE-dist')\n",
    "\n",
    "    def CrossCorrelation(self,spikemon1,spikemon2):\n",
    "        # Normalize spike times\n",
    "        norm1 = spikemon1.t / np.linalg.norm(spikemon1.t)\n",
    "        norm2 = spikemon2.t / np.linalg.norm(spikemon2.t)\n",
    "        test1 = norm1\n",
    "        test2 = norm2\n",
    "        y = np.correlate(test1,test2,\"full\") \n",
    "        z = np.correlate(test1,test1,\"full\") \n",
    "\n",
    "        # Plotting correlation\n",
    "        x_valy = range(len(y))\n",
    "        x_valz = range(len(z))\n",
    "        plot(x_valy-np.argmax(z/ms),y,'b')\n",
    "        plot(x_valz-np.argmax(z/ms),z,'g')\n",
    "        blue_patch = mpatches.Patch(color='blue', label='Test Correlation')\n",
    "        green_patch = mpatches.Patch(color='green', label='Autocorrelation')\n",
    "        suptitle('Comparing network 2 to network 1', fontsize=14, fontweight='bold')\n",
    "        plt.legend(handles=[blue_patch,green_patch])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array is too big; `arr.size * arr.dtype.itemsize` is larger than the maximum possible size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-25f740b43249>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#[A,G] = Adj.scale_free(n) # Defines scale-free topology\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconnect_W\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_coord\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA_temp5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmyW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWeighted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m '''\n",
      "\u001b[1;32m<ipython-input-4-e31c12ff24b1>\u001b[0m in \u001b[0;36mWeighted\u001b[1;34m(self, A, n)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mA_temp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_temp5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Reshapes A for multiplication\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mW_temp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Reshapes W for multiplication\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mA_temp\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mW_temp\u001b[0m \u001b[1;31m# Makes (n**2)x(n**2) matrix of adjacency matrix times weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# n by n, adjacency * random weight matrix. 0s for no connections\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: array is too big; `arr.size * arr.dtype.itemsize` is larger than the maximum possible size."
     ]
    }
   ],
   "source": [
    "'''\n",
    "Sample function 1 calling\n",
    "Change parameters to fit neural model\n",
    "Computes weighted adjacency matrix\n",
    "\n",
    "Parameters to be user-defined:\n",
    "    n: nodes\n",
    "    m: edges\n",
    "    k: each node is connected to k nearest neightbors\n",
    "    p: probability of adding new edge for each edge\n",
    "    d: degree of each node\n",
    "'''\n",
    "# Sample call function\n",
    "n = 200 # Kills kernel at n = 250, m=375 possibly b/c cpu limitations\n",
    "m = 300\n",
    "k = 2\n",
    "p = 0.2\n",
    "d = 2\n",
    "rand_seed = np.random.seed(int(time.time())) # To seed random number generator based on time\n",
    "\n",
    "Adj = AdjacencyMatrix(n) # Initiates...only runs the '__ini__' function at this point\n",
    "\n",
    "#[A,G] = Adj.all_to_all(n) # Defines all-to-all topology\n",
    "[A,G] = Adj.random(n,m) # Defines random topology\n",
    "#[A,G] = Adj.small_world(n,k,p) # Defines small-world topology\n",
    "#[A,G] = Adj.regular(d,n) # Defines regular topology\n",
    "#[A,G] = Adj.scale_free(n) # Defines scale-free topology\n",
    "\n",
    "W,rows,cols,connect_W,new_coord,A_temp5,myW = Adj.Weighted(A,n) # Output\n",
    "\n",
    "'''\n",
    "Sample function 2 calling\n",
    "First plot: cluster coefficient for each neuron\n",
    "Second plot: excitatory (r) and inhibitory (b) connections\n",
    "'''\n",
    "vis = Visualization() # Initiates \n",
    "cc_avg = vis.cluster_coeff(G) # Calculates average cluster coefficient\n",
    "\n",
    "vis.ex_in_connec(G,connect_W) # Plots excitatory/inhibitory connections\n",
    "cpl_avg = vis.char_path_len(G) # Calculates average characteristic path length\n",
    "print (\"Average characteristic path length:\")\n",
    "print (cpl_avg)\n",
    "\n",
    "#show(block=True) # Show Network connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f5d2cfba584a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mrun_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Records initial runtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mG1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mS1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mP1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBrianVis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconnect_W\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Runs LIF model for first network\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mG2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mS2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mP2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBrianVis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconnect_W\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Runs LIF model for second network\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstatemon1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mspikemon1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstatemon2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mspikemon2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc_rows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc_cols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcoup_mat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBrianVis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork_coupling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_couple\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_couple\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mG1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mG2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Couples first and second networks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rows' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Sample function 4 calling\n",
    "Change parameters to fit neural model\n",
    "Simulates leaky integrate-and-fire neuron model\n",
    "\n",
    "Parameters:\n",
    "    N: number of neurons\n",
    "    tau_m: time constant (ms)\n",
    "    v_r = reset membrane potential (mv)\n",
    "    v_th = threshold membrane potential (mv)\n",
    "    I_c = constant input current\n",
    "    run_time = simulation time (ms)\n",
    "    p_couple = probability that neuron i in first net will couple with neuron i in second net\n",
    "    w_couple = coupling weight (influence from net1 to net2)\n",
    "'''\n",
    "N = n \n",
    "tau_m1 = 20.4 #37\n",
    "tau_m2 = 32.4 #43\n",
    "v_r = 0 \n",
    "v_th = 1 \n",
    "I_c = 2 \n",
    "run_time = 1000\n",
    "p_couple = 0.1 #0.99 \n",
    "w_couple = 0.5 #1 \n",
    "'''\n",
    "Coupling weight seems to influence how long two nets will stay coupled together\n",
    "But it doesn't seem to look like there's a big difference between w=5 and w=5000\n",
    "The difference is only clearly visible if network 1 has fixed voltage and PoissonInput off\n",
    "'''\n",
    "BrianVis = BrianVisualization() # Initiates\n",
    "\n",
    "run_t = time.time() # Records initial runtime\n",
    "\n",
    "[G1,S1,P1] = BrianVis.network1(rows,cols,connect_W,N) # Runs LIF model for first network\n",
    "[G2,S2,P2] = BrianVis.network2(rows,cols,connect_W,N) # Runs LIF model for second network\n",
    "[statemon1,spikemon1,statemon2,spikemon2,c_rows,c_cols,coup_mat] = BrianVis.network_coupling(N,p_couple,w_couple,G1,G2) # Couples first and second networks\n",
    "\n",
    "elapsed = time.time() - run_t # Calculates elapsed runtime\n",
    "print ('Total runtime:')\n",
    "print (elapsed) # Prints elpased runtime\n",
    "\n",
    "print('variables')\n",
    "print(connect_W.shape)\n",
    "print(rows.shape)\n",
    "print(cols.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculating synchronicity metrics (SPIKE-synchronicity,ISI-distance,SPIKE-distance)\n",
    "'''\n",
    "Sync = SynchronicityCalculation() # Initiates\n",
    "[st1,st2] = Sync.Initialize(spikemon1,spikemon2)\n",
    "\n",
    "fig1 = plt.subplot(411)\n",
    "suptitle('Synchronicity Metrics', fontsize=14, fontweight='bold')\n",
    "BrianVis.raster_plot(spikemon2,spikemon1)\n",
    "    # Red == Network2 (target network)\n",
    "    # Black == Network1 (source network)\n",
    "\n",
    "fig2 = plt.subplot(412,sharex=fig1)\n",
    "Sync.SPIKEsynch(st1,st2) # Plots SPIKE-synchronization\n",
    "\n",
    "fig3 = plt.subplot(413,sharex=fig1)\n",
    "Sync.ISIdistance(st1,st2) # Plots ISI-distance\n",
    "\n",
    "fig4 = plt.subplot(414,sharex=fig1)\n",
    "Sync.SPIKEdistance(st1,st2) # Plots SPIKE-distance\n",
    "\n",
    "figManager = plt.get_current_fig_manager()\n",
    "figManager.window.showMaximized()\n",
    "\n",
    "show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plotting cross-correlation\n",
    "'''\n",
    "Sync = SynchronicityCalculation() # Initiates\n",
    "\n",
    "Sync.CrossCorrelation(spikemon1,spikemon2)\n",
    "\n",
    "figManager = plt.get_current_fig_manager()\n",
    "figManager.window.showMaximized()\n",
    "\n",
    "show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plotting network dynamics (raster and PSTH)\n",
    "'''\n",
    "\n",
    "# Network 1 voltage monitor\n",
    "#suptitle('Network 1 voltage monitor', fontsize=14, fontweight='bold')\n",
    "#BrianVis.voltage_monitor(statemon1) # Plots voltage monitor\n",
    "\n",
    "# Network 2 voltage monitor\n",
    "#suptitle('Network 2 voltage monitor', fontsize=14, fontweight='bold')\n",
    "#BrianVis.voltage_monitor(statemon2) # Plots voltage monitor\n",
    "\n",
    "# Gather data for network 1\n",
    "[spike_times,all_spikes] = BrianVis.spike_time(spikemon1)\n",
    "\n",
    "# Network 1 raster\n",
    "fig1 = plt.subplot(221)\n",
    "suptitle('Two network raster and PSTH', fontsize=14, fontweight='bold')\n",
    "BrianVis.raster_plot(spikemon1,spikemon1) \n",
    "    # Network 1 in black (second input)\n",
    "\n",
    "# Network 1 PSTH\n",
    "fig2 = plt.subplot(222, sharex=fig1)\n",
    "BrianVis.spike_hist(run_time,all_spikes) \n",
    "\n",
    "# Gather data for network 2\n",
    "[spike_times,all_spikes] = BrianVis.spike_time(spikemon2)\n",
    "\n",
    "# Network 2 raster\n",
    "fig3 = plt.subplot(223, sharex=fig1, sharey=fig1)\n",
    "BrianVis.raster_plot(spikemon2,spikemon1) \n",
    "    # Network 2 in red (first input)\n",
    "    # Network 1 in black (second input)\n",
    "\n",
    "# Network 2 PSTH\n",
    "fig4 = plt.subplot(224, sharex=fig1)\n",
    "BrianVis.spike_hist(run_time,all_spikes)\n",
    "\n",
    "# Qt4Agg backend for full screen window display\n",
    "figManager = plt.get_current_fig_manager()\n",
    "figManager.window.showMaximized()\n",
    "\n",
    "show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Attempt to reconfigure spike trains for better quantitation of synchronicity\n",
    "'''\n",
    "\n",
    "if 0:\n",
    "    # Attempt to separate into n rows\n",
    "\n",
    "    x1 = spikemon1.t/ms\n",
    "    tot_col = len(x1)/N\n",
    "\n",
    "    y1 = np.reshape(x,(N,tot_col),order='f') \n",
    "    #print y1[0]\n",
    "\n",
    "    # Are there 42 spikes over the course of 1 sec? Yes\n",
    "\n",
    "    x2 = spikemon2.t/ms\n",
    "    tot_col = len(x1)/N\n",
    "\n",
    "    #print len(x2)\n",
    "    #print N\n",
    "\n",
    "# Can't do spikemon2 like spikemon1 because the length is different and a neuron might have fired more often than another\n",
    "    # Now we have to compare list_spike_train1 to list(spikemon1.t/ms) to figure out why won't load right into SpikeTrain\n",
    "\n",
    "# Get spike train data from SpikeMonitor that is ordered by neuron index\n",
    "spike_trains1 = spikemon1.spike_trains()\n",
    "spike_trains2 = spikemon2.spike_trains()\n",
    "\n",
    "# Convert spike trains for each population to list\n",
    "list_spike_train1 = [ v for v in spike_trains1.values() ]\n",
    "list_spike_train2 = [ v for v in spike_trains2.values() ] # Further differentiate into spike trains for indiv. neuron?\n",
    "\n",
    "# Convert list of spike trains to list for each individual neuron\n",
    "    # Would this corrupt the synchronicty bc not just comparing population to population, but comparing inter-population and intra-population variation\n",
    "\n",
    "#convert to txt file where each line has spike times for each neuron\n",
    "spike_train1_txt = open('Spikes1.txt','w')\n",
    "for item in list_spike_train1:\n",
    "    spike_train1_txt.write(\"%s\\n\" % item)\n",
    "\n",
    "# Load spikes from saved txt file\n",
    "my_st1 = spk.load_spike_trains_from_txt(\"Spikes1.txt\",edges=[0,run_time])\n",
    "\n",
    "test_st1 = spk.load_spike_trains_from_txt(\"PySpike_testdata.txt\",edges=[0,4000])\n",
    "\n",
    "# NxM matrix where N is number of neurons and M is number of spikes for each neuron\n",
    "#isi_prof = spk.isi_profile(test_st1) # works for comparing 1 entire population (NxM matrix)\n",
    "isi_prof = spk.isi_profile(test_st1[0],test_st1[1]) # works for intra-population (1xM array)\n",
    "#isi_prof = spk.isi_profile(test,st1,test_st1) # doesn't work for comparing inter-population (2 NxM matrices)\n",
    "#isi_prof = spk.isi_profile(my_st1) # seems to be take a long time and yields 0\n",
    "isi_dist = isi_prof.avrg()\n",
    "x,y = isi_prof.get_plottable_data()\n",
    "plot(x,y,'-k')\n",
    "ylabel('ISI')\n",
    "#axes = plt.gca()\n",
    "#axes.set_ylim([0,0.6]) # set axes\n",
    "\n",
    "figManager = plt.get_current_fig_manager()\n",
    "figManager.window.showMaximized()\n",
    "\n",
    "show(block=True)\n",
    "\n",
    "if 0:\n",
    "    # Second attempt - doesn't work\n",
    "    outarr = np.vstack(list_spike_train1)\n",
    "    np.savetxt(\"Spikes2.txt\",outarr.T)\n",
    "\n",
    "    # Third attempt - doesn't work\n",
    "    import json\n",
    "    with open('Spikes3.txt','w') as myfile:\n",
    "        json.dump(list_spike_train1,myfile)\n",
    "\n",
    "#my_st1 = spk.SpikeTrain(list(spikemon1.t/ms), edges=[0,run_time])\n",
    "\n",
    "if 0:\n",
    "    '''\n",
    "    Calculating synchronicity metrics (SPIKE-synchronicity,ISI-distance,SPIKE-distance) with reshaped spikemon\n",
    "    '''\n",
    "    Sync = SynchronicityCalculation() # Initiates\n",
    "    [st1,st2] = Sync.Initialize(spikemon1,spikemon2)\n",
    "\n",
    "    fig1 = plt.subplot(411)\n",
    "    suptitle('Synchronicity Metrics', fontsize=14, fontweight='bold')\n",
    "    BrianVis.raster_plot(spikemon2,spikemon1)\n",
    "        # Red == Network2 (target network)\n",
    "        # Black == Network1 (source network)\n",
    "\n",
    "    fig2 = plt.subplot(412,sharex=fig1)\n",
    "    Sync.SPIKEsynch(st1,st2) # Plots SPIKE-synchronization\n",
    "\n",
    "    fig3 = plt.subplot(413,sharex=fig1)\n",
    "    Sync.ISIdistance(st1,st2) # Plots ISI-distance\n",
    "\n",
    "    fig4 = plt.subplot(414,sharex=fig1)\n",
    "    Sync.SPIKEdistance(st1,st2) # Plots SPIKE-distance\n",
    "\n",
    "    figManager = plt.get_current_fig_manager()\n",
    "    figManager.window.showMaximized()\n",
    "\n",
    "    show(block=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
