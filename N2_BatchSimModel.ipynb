{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "This is a model which can create coupled networks of a desired type and change their parameters to observe which of them affect synchronization. \n",
    "\n",
    "It carries out the following functions:\n",
    "    1. Create individual network groups with their synapses --> uses BrianVis.network_indv(...)\n",
    "    2. Create synapse group of coupled networks with monitors to record each network --> BrianVis.network_coupling(..)\n",
    "    3. Make changes to individual parameters of network groups, synapses and run times\n",
    "    4. Run the coupled networks in the following pattern:\n",
    "               a. Disconnected networks for a time t1*s: coupled synaptic weights will be zero\n",
    "               b. Connected(coupled) networks for a time t2*s: coupled synaptic weights reset to values obtained in step 2\n",
    "               c. Disconnected networks for a time t1*s: coupled synaptic weights set to zero again\n",
    "    5. Output spikemonitor voltages and times so they can be graphed\n",
    "\n",
    "# Goals:\n",
    "- To simulate coupled networks while varying their parameters\n",
    "- To observe network behavior in coupled vs uncoupled states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Python Modules and Initializing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Please make sure kernel is Python 2 and not Python 3. \n",
    "# Currently Brian 2 does not work correctly on Python3 even if the package is installed\n",
    "# Refer to README file on GitHub for how to change the Jupyter notebook environment to Python2\n",
    "# Refer to README file on GitHub for how to setup PySpike\n",
    "\n",
    "import networkx as nx\n",
    "from brian2 import *\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pyspike as spk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Classes\n",
    "\n",
    "### Types: \n",
    "* Visualization\n",
    "* Brian Visualization\n",
    "* Adjacency Matrix\n",
    "* Spike Stats\n",
    "* Synchronicity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Visualization:\n",
    "    '''\n",
    "    Function 2: Visualize neural network\n",
    "    Inputs graph G \n",
    "    Returns cluster coefficient & characteristic path length\n",
    "        & plot of connections between neurons (color-coded)\n",
    "    For more info: see collective dynamics paper\n",
    "    \n",
    "    Description:\n",
    "    From network model, determines cluster coefficient and characteristic path length for each\n",
    "        node. For each network, will take average of those values, respectively and yield \n",
    "        single integer value.\n",
    "    From network model, will output plot of connections, color-coded for excitatory and\n",
    "        inhibitory.\n",
    "    \n",
    "    Returns:\n",
    "        cc_avg: Cluster coefficient averaged over all nodes\n",
    "        ex_in_plot: Plot of colored excitatory/inhibitory connections\n",
    "        cpl_avg: Number of edges at shortest path over all nodes \n",
    "        \n",
    "    Parameters:\n",
    "        G: NetworkX Graph from Function 1\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        #plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "\n",
    "    def cluster_coeff(self,G):        \n",
    "        cc = nx.clustering(G) # calculate clustering co-eff according to different rules eg. no of triangles going through node\n",
    "        # outputs co-eff for all or specified nodes in dict form\n",
    "        cc_y=[]\n",
    "        for idx in cc:\n",
    "            cc_y=np.append(cc_y,cc[idx]) # access and append dict values (co-effs in this case) to array\n",
    "        \n",
    "        cc_avg = np.ndarray.mean(cc_y, dtype=np.float64)\n",
    "        return cc_avg\n",
    "    \n",
    "    def ex_in_connec(self,G,connect_W,new_coord):\n",
    "        plt.figure()\n",
    "        red_patch = mpatches.Patch(color='red', label='Excitatory')\n",
    "        blue_patch = mpatches.Patch(color='blue', label='Inhibitory')\n",
    "        plt.legend(handles=[red_patch,blue_patch])\n",
    "        suptitle('Structural Connections', fontsize=14, fontweight='bold')\n",
    "\n",
    "        edges = G.edges() # list of tuple pairs\n",
    "        nodes = G.nodes() # array of nodes\n",
    "\n",
    "        custom_color={}\n",
    "        for idx in range(len(connect_W)):\n",
    "            if connect_W[idx] < 0:\n",
    "                inhib_edge = new_coord[idx]\n",
    "                G.add_edge(*inhib_edge)     # adds an inhibitory edge connection to graph if it's not already there\n",
    "                custom_color[inhib_edge]='b'\n",
    "            else:\n",
    "                excit_edge = new_coord[idx]\n",
    "                G.add_edge(*excit_edge)\n",
    "                custom_color[excit_edge]='r'\n",
    "        if 0:\n",
    "            for idx,idy in enumerate(edges):\n",
    "                x1,y1 = edges[idx]\n",
    "                if connect_W < 0:\n",
    "                    inhib_edge = (x1,y1)\n",
    "                    G.add_edge(x1,y1)\n",
    "                    custom_color[x1,y1]='b' # Stores color of edges in dict\n",
    "                else:\n",
    "                    excit_edge = (x1,y1)\n",
    "                    G.add_edge(x1,y1)\n",
    "                    custom_color[x1,y1]='r'\n",
    "        \n",
    "        ex_in_plot=nx.draw_networkx(G,node_color='w',\n",
    "                         with_labels=True,\n",
    "                         node_list=nodes,\n",
    "                         #node_size=50,\n",
    "                         node_size=200,\n",
    "                         edge_list=custom_color.keys(),\n",
    "                         edge_color=custom_color.values(),\n",
    "                         label='Blue=Inhibitory, Red=Excitatory')\n",
    "        #plt.savefig(\"Structural Connections.png\")\n",
    "        \n",
    "    def char_path_len(self,G):\n",
    "        cpl = nx.all_pairs_shortest_path_length(G) # shortest path lengths. Gen. returns tuple with source and target dict\n",
    "        my_array = []\n",
    "        my_key = []\n",
    "        cpl_count = []\n",
    "        for idx in cpl: # looping through each source node and looking at no of targets and length to target nodes\n",
    "            myarray = cpl[idx[1]] # cpl is a generator object. idx is a tuple (source, target dict). Should be idx[1].\n",
    "            min_val = min(ii for ii in myarray if ii > 0) # Find min length\n",
    "            for key,length in myarray.iteritems():\n",
    "                if length == min_val:\n",
    "                    my_key = np.append(my_key,key) # array of target nodes with min length for specific source node\n",
    "            my_count = len(my_key) # Find number of edges of that length\n",
    "            cpl_count = np.append(cpl_count,my_count)\n",
    "            my_key = []\n",
    "            cpl_avg = np.mean(cpl_count) # Find average of those edges\n",
    "        return cpl_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class BrianVisualization:\n",
    "    '''\n",
    "    Function 4: Visualization of Brian \n",
    "    Define LIF neural population in Brian\n",
    "    Call to save spike times\n",
    "    Call to plot voltage monitor\n",
    "    Call to plot raster plot\n",
    "    Call to plot histogram\n",
    "    \n",
    "    Description:\n",
    "    Will plot the voltage monitor, raster plot, and histogram of neural network\n",
    "    \n",
    "    Returns:\n",
    "        G: NeuronGroup\n",
    "        spike_times: Spike times for neuron 0\n",
    "        all_spikes: Spike times for all neurons\n",
    "        \n",
    "    \n",
    "    Parameters:\n",
    "        statemon: StateMonitor\n",
    "        spikemon: SpikeMonitor\n",
    "        run_time: Simulation run time\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "        \n",
    "        start_scope()\n",
    "    \n",
    "    def network_indv(self,rows,cols,connect_W,N,PInput):\n",
    "        # rows and cols 1-D arrays of source and target neurons that are connected as defined in graph from networkx\n",
    "        # connect_W: 1-D array of strength of connections corresponding to source and target neuron pairs \n",
    "        '''\n",
    "        For full synch: G1.v = fixed\n",
    "                        PI = off\n",
    "        '''\n",
    "        eqs = neuron_diffeqns # Defined in the input parameter block \n",
    "                \n",
    "        G1 = NeuronGroup(N, eqs, threshold='v>v_th', reset='v=v_r', refractory=10*ms, method=integ_method) #integ_method defined in input parameter block\n",
    "        G1.v = v_c # initial voltage value defined in input block\n",
    "        '''\n",
    "        Injection current is constant but with slight perturbations from PoissonInput, if that function is active\n",
    "        To get rid of highly synchronized, G1.v='rand()' and turn on P1\n",
    "        '''\n",
    "        \n",
    "        # PoissonInput injection current -- changes each neuron's firing rate\n",
    "        # Each neuron has different input current depending on Poisson distribution\n",
    "        PI_num = 0.8*N \n",
    "        #subG1 = G1[int(PI_num):] # Top 20% of total neurons stimulated\n",
    "        subG1 = G1[:] # All neurons stimulated via Poisson \n",
    "        '''\n",
    "        PoissonInput(target,target_var,N,rate,weight)\n",
    "        target: which neurons to send PoissonInput\n",
    "        target_var: which variable that is being changed from input\n",
    "        N: number of inputs (more input = higher firing rate)\n",
    "        rate: rate of input (100Hz = 10ms per spike)\n",
    "        weight: amount added to voltage\n",
    "        '''\n",
    "        P1 = PoissonInput(subG1, 'v', 5, 100*Hz, weight=PInput) # PoissonInput off if PInput = 0\n",
    "        S1 = Synapses(G1, G1, 'w : volt', on_pre='v_post += w') # w is the synapse weight added to the signal\n",
    "        S1.connect(i=rows, j=cols) # Adjacency matrix from Adj.weighted, this uses network structure defined on networkx\n",
    "        S1.w = connect_W/float(100) # Weighted matrix defined from networkx graph \n",
    "               \n",
    "        return G1,S1,P1\n",
    "\n",
    "    def network_coupling(self,N,p_couple,w_couple,G1,G2,SG_name):\n",
    "        '''\n",
    "        Should see how coupling between different subpopulation has global effects (raster plot)\n",
    "            - Could see difference if neurons have same firing rate (non-PoissonInput) vs. different firing rate (all-PoissonInput)\n",
    "            - May only want to record (Statemon, Spikemon) from this last coupling (G2) to save resources\n",
    "                - See Monitoring Synaptic Variables from http://brian2.readthedocs.io/en/2.0.1/user/synapses.html\n",
    "            = Can introduce multiple output synapses (multisynaptic_index from http://brian2.readthedocs.io/en/2.0.1/user/synapses.html)\n",
    "                - Or more simply \"S.connect(i=numpy.arange(10), j=1)\"\n",
    "        '''\n",
    "        S3 = Synapses(G1,G2, 'w: volt', on_pre='v_post += w',name=SG_name)#, delay=5*ms) # G1 drives G2\n",
    "        \n",
    "        ### Manually defining coupling ###\n",
    "        p_couple2 = p_couple*N\n",
    "        i_couple2 = 0.8*N\n",
    "        \n",
    "        # If want 1:1 for only first p_couple% neurons (excitatory --> excitatory)\n",
    "        if connect_type == 'ee':\n",
    "            c_rows = list(arange(0,p_couple2,dtype=int)) # Source neurons\n",
    "            c_cols = list(arange(0,p_couple2,dtype=int)) # Target neurons\n",
    "        elif connect_type == 'ii':\n",
    "            c_rows = list(arange(N-i_couple2,N,dtype=int))\n",
    "            c_cols = list(arange(N-i_couple2,N,dtype=int))\n",
    "        elif connect_type == 'ie':\n",
    "            c_rows = list(arange(N-i_couple2,N,dtype=int))\n",
    "            c_cols = list(arange(0,p_couple2,dtype=int))\n",
    "        elif connect_type == 'ei':\n",
    "            c_rows = list(arange(0,p_couple2,dtype=int))\n",
    "            c_cols = list(arange(N-i_couple2,N,dtype=int))\n",
    "        \n",
    "        S3.connect(i=c_rows, j=c_cols) # Manually defined coupling\n",
    "        S3.w = w_couple\n",
    "        ###################################\n",
    "        \n",
    "        ##### Probabilistic coupling #####\n",
    "        #S3.connect(p=0.05) # Probabilistic connection - Chance that G2 will connect with and spike from G1\n",
    "        #S3.w = 0.02\n",
    "        #S3.connect(p=p_couple)\n",
    "        ###################################\n",
    "                \n",
    "        # Coupling matrix\n",
    "        coup_mat = [[0 for x in range(N)] for y in range(N)]\n",
    "\n",
    "        for ii in range(len(c_rows)):\n",
    "            for jj in range(len(c_cols)):\n",
    "                coup_mat[ii][ii] = 1      # Matrix has 1s for connections and 0s for none\n",
    "\n",
    "        statemon1 = StateMonitor(G1, 'v', record=0,name='statemon1_'+ G1.name) # Records just neuron 0 to save resources\n",
    "        spikemon1 = SpikeMonitor(G1, variables='v',)\n",
    "        statemon2 = StateMonitor(G2, 'v', record=0,name='statemon2_'+ G2.name) # Records just neuron 0 to save resources\n",
    "        spikemon2 = SpikeMonitor(G2, variables='v')\n",
    "\n",
    "        return statemon1,spikemon1,statemon2,spikemon2,c_rows,c_cols,coup_mat,S3\n",
    "        \n",
    "    def spike_time(self,spikemon):\n",
    "        all_values = spikemon.all_values()\n",
    "        spike_times = all_values['t'][0] # Spike times for just neuron 0\n",
    "        all_spikes = spikemon.t/ms # Spike times for all neurons\n",
    "        \n",
    "        return spike_times,all_spikes\n",
    "        \n",
    "    def voltage_monitor(self,statemon):\n",
    "        plot(statemon.t/ms, statemon.v[0])\n",
    "        #plot(statemon.t/ms, statemon.v[1])  # Plots second neuron      \n",
    "        ylabel('Voltage (V)')\n",
    "        xlabel('Time (ms)')\n",
    "        \n",
    "    def raster_plot(self,spikemon,spikemon_other):\n",
    "        #ion()\n",
    "        plot(spikemon.t/ms, spikemon.i, '.r')\n",
    "        plot(spikemon_other.t/ms, spikemon_other.i, '.k') # Plots overlay of each network\n",
    "        #plt.xlim([0,105])\n",
    "        #plt.xticks(np.arange(0, 1200, step=20))\n",
    "        xlabel('Time (ms)')\n",
    "        ylabel('Neuron index');\n",
    "        #plt.show(block=True)\n",
    "        \n",
    "    def spike_hist(self,run_time,all_spikes):\n",
    "        my_bins = arange(0,run_time+2,2)\n",
    "        plt.hist(all_spikes, bins=my_bins)\n",
    "        plt.xlim([0,105])\n",
    "        plt.yticks(np.arange(0, 30, step=2))\n",
    "        plt.margins()\n",
    "        xlabel('Time (ms)')\n",
    "        ylabel('Total number of spikes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class AdjacencyMatrix:  \n",
    "    '''\n",
    "    Function 1: Weighted adjacency matrix\n",
    "    Call to initiate adjacency matrix\n",
    "    Call to choose which neural network topology with given parameters\n",
    "    \n",
    "    Description:\n",
    "    Given parameters, constructs network with adjacency matrix and applies random weights.\n",
    "    \n",
    "    Returns:\n",
    "        Graph: NetworkX Graph\n",
    "        A: Adjacency matrix. Sparse matrix\n",
    "        rows: Presynaptic neurons\n",
    "        cols: Postsynaptic neurons\n",
    "        connect_W: Weights for each E/I connection (in order of rows,cols)\n",
    "    \n",
    "    Parameters:\n",
    "        n: nodes\n",
    "        m: edges\n",
    "        k: neighbor connections\n",
    "        p: probability \n",
    "        d: degrees\n",
    "    '''\n",
    "    def __init__(self,n): \n",
    "        plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "        \n",
    "    def random(self,n,p): \n",
    "        # Interchangeable based on UI for different types of topography\n",
    "        #G = nx.dense_gnm_random_graph(n,m) # Uses NetX to generate random topography, need to add input param m\n",
    "        Graph = nx.gnp_random_graph(n,p)\n",
    "        #nx.draw(G, with_labels=True) # Draws connectivity figure\n",
    "        #plt.savefig(\"Random.png\") # Saves connectivity figure as Random.png\n",
    "\n",
    "        # Extracts ADJACENCY MATRIX from topography and rearranges to manageable array of (n*n) elements\n",
    "        A = nx.adjacency_matrix(Graph) # Assigns A as adjacency matrix (which nodes are connected)\n",
    "        return A, Graph \n",
    "    \n",
    "    def small_world(self,n,k,p): \n",
    "        Graph = nx.newman_watts_strogatz_graph(n,k,p) \n",
    "        #nx.draw(G, with_labels=True)\n",
    "        #plt.savefig(\"Small-world.png\")\n",
    "        A = nx.adjacency_matrix(Graph)\n",
    "        return A, Graph\n",
    "    \n",
    "    def unidir_coord(self,rows, cols):\n",
    "        # function to remove duplicate connections like (0,3) and (3,0) so that all connections are uni- and not bi-directional\n",
    "        coord = zip(rows,cols) # To get an array of coordinate pair tuples, to define node pairs or edges \n",
    "        new_pairs = set(tuple(sorted(l)) for l in coord) # set removes duplicate tuples that are now ordered pairs\n",
    "                                                            # set(array of tuples)\n",
    "        g = np.array(list(new_pairs)) #array of 1 by 2 neuron pair vectors that are connected to each other\n",
    "                                      # In each 1 by 2 vector: column 0 is source neuron and column 1 is target neuron\n",
    "        new_rows = g[:,0] #1-D array of all source neurons i\n",
    "        new_cols = g[:,1] #1-D array of all target neurons j\n",
    "        new_coord = zip(new_rows,new_cols) # list of tuples, source and target ordered pairs with no duplicates\n",
    "        return new_coord, new_rows, new_cols\n",
    "    \n",
    "    def adj_synapse_type(self,A):\n",
    "        ### Define connections as inhibitory or excitatory in the adjacency matrix\n",
    "        A_mat = A.todense() # Converts adjacency matrix from 'scipy.sparse.csr.csr_matrix' to numpy matrix                              \n",
    "        rows, cols = np.nonzero(A_mat) # Two arrays of index positions for connections\n",
    "        [new_coord, new_rows, new_cols] = self.unidir_coord(rows,cols) # Removes duplicate connections\n",
    "        connect = len(new_rows) # number of connections or 1s in adjacency matrix\n",
    "\n",
    "        for i in range(connect):\n",
    "            x = new_rows[i]\n",
    "            y = new_cols [i]\n",
    "            if x>(excit-1) or y>(excit-1):   # Checking if either source or target neuron belongs to upper 20% of n \n",
    "                A_mat[x,y] = A_mat[x,y]*-1   # Inhibitory neuron defined, weight is made negative\n",
    "                                             # not necessary to repeat for symmetric part of the matrix as it won't be used\n",
    "\n",
    "        # Constructing array of unweighted connections\n",
    "        connect_A = [] # Initializaing empty connections array\n",
    "        for i in range(connect):\n",
    "            x = new_rows[i]\n",
    "            y = new_cols [i]\n",
    "            connect_A.append(A_mat[x,y])\n",
    "        connect_A = np.array(connect_A) # Converting data type list to numpy array\n",
    "        return connect_A,new_coord,new_rows,new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Spike_Stats:\n",
    "    '''\n",
    "    Description: Given spike times of each neuron, statistical parameters of ISI(Inter-Spike-Interval) can be calculated\n",
    "                 like mean, variance, co-efficent of variation. Spike trains can also be compared to produce correlation\n",
    "                 coefficients\n",
    "    \n",
    "    Parameters: \n",
    "    '''\n",
    "    \n",
    "    def __init__(self): # Not sure what to do here yet\n",
    "        pass\n",
    "    \n",
    "    def ISI_stats(self,spikemon):\n",
    "        neuron_spikes = spikemon.spike_trains() # Dictionary with dict keys as neuron indices and \n",
    "                                         # dict values as an array of spike times for that neuron\n",
    "        firing_n = list(set(sort(spikemon.i))) # To create a set or list of all unique neuron indices that have spiked\n",
    "                                                # in order to calculate statistical parameters for each unique neuron\n",
    "            \n",
    "        ISI = {} # Create an empty dictionary to contain dict keys as neuron indices and dict values as an array of ISIs\n",
    "        ISI_mean = {} # Dict for ISI mean of each neuron index\n",
    "        ISI_var = {} # Dict for ISI variance of each neuron index\n",
    "        ISI_cv = {} # Dict for ISI co-efficient of variation (CV) for each neuron index\n",
    "\n",
    "        # Calculate variance and mean of each ISI (Inter-Spike-Interval)\n",
    "        for i in firing_n:\n",
    "            # Calculate ISI array by subtracting spike times of each neuron to get an array of spike intervals\n",
    "            ISI[i] = np.diff(neuron_spikes[i])\n",
    "            # Calculate mean of ISI\n",
    "            ISI_mean[i] = np.mean(ISI[i])\n",
    "            # Calculate variance of ISI\n",
    "            ISI_var[i] = np.var(ISI[i])\n",
    "            # Calculate co-efficient of variation(CV) of ISI\n",
    "            ISI_cv[i] = np.sqrt(ISI_var[i])/ISI_mean[i]\n",
    "        return ISI,ISI_mean,ISI_var,ISI_cv\n",
    "    \n",
    "    def spike_bin(self,sp_time,bin_size):\n",
    "        '''\n",
    "        This function takes in an array of spike times and counts the number of spikes occuring within a time interval\n",
    "        defined by bin_size. \n",
    "        It outputs an array of 0's and 1's to indicate whether or not a spike occured within an interval\n",
    "        '''\n",
    "        sp_binary = {}\n",
    "        t_interval = range(0,run_time,bin_size)\n",
    "        t_size = len(t_interval)\n",
    "            \n",
    "        for k in range(0,len(sp_time)):\n",
    "            temp = np.array([0]*t_size) # Converting to an array so that simulatenous assignment \n",
    "                                        # to multiple indices is possible\n",
    "            bin_pos = (sp_time[k]/(bin_size*ms)).astype(int)\n",
    "            temp[bin_pos] = 1\n",
    "            sp_binary[k] = temp\n",
    "            \n",
    "        return sp_binary\n",
    "    \n",
    "    def spike_cc(self,set1,set2):\n",
    "        '''\n",
    "        This function calculates Pearson product-moment correlation co-efficients.\n",
    "        '''\n",
    "        #set1 = SN1_2_binary\n",
    "        #set2 = SN2_2_binary\n",
    "        final_CC = np.zeros((n,n))\n",
    "\n",
    "        for i in set1:\n",
    "            val1 = set1[i]\n",
    "            for j in set2:\n",
    "                val2 = set2[j]\n",
    "                corr = np.corrcoef(val1,val2)\n",
    "                final_CC[i][j] = corr[0,1]\n",
    "        return final_CC\n",
    "    \n",
    "    def spike_cc_phasingout(self,bin_vector):\n",
    "        var = [] # A empty list that will contain lists of binary spike trains\n",
    "        for k in bin_vector:\n",
    "            var.append(bin_vector[k]) # Required format to use with numpy's corrcoef function\n",
    "\n",
    "        CC_matrix = np.corrcoef(var) # This matrix is N-neurons by N-neurons and the main diagonal is all 1s \n",
    "                                     # test with CC_matrix.shape to confirm\n",
    "        return CC_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SynchronicityCalculation:\n",
    "    '''\n",
    "    To calculate different metrics of synchronicity\n",
    "    \n",
    "    For more information:\n",
    "        See Synch Metrics bookmarks folder\n",
    "        http://wwwold.fi.isc.cnr.it/users/thomas.kreuz/sourcecode.html\n",
    "        https://arxiv.org/pdf/1603.03293.pdf\n",
    "        http://mariomulansky.github.io/PySpike/pyspike.html#pyspike.SpikeTrain.SpikeTrain\n",
    "        http://mariomulansky.github.io/PySpike/index.html\n",
    "        http://www.scholarpedia.org/article/Measures_of_spike_train_synchrony#ISI-distance\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "\n",
    "    def Initialize(self,spikemon1,spikemon2,tstart,tend):\n",
    "        try:\n",
    "            st1 = spk.SpikeTrain(spikemon1.t/ms, edges=[tstart,tend])\n",
    "            st2 = spk.SpikeTrain(spikemon2.t/ms, edges=[tstart,tend])\n",
    "            \n",
    "        except AttributeError:\n",
    "        # In case parameters passed to function are a dictionary of spike times in 'ms' and not spike monitors \n",
    "        # The AttributeError 'dict' object has no attribute 't' results and is caught here\n",
    "            st1 = spk.SpikeTrain(spikemon1/ms, edges=[tstart,tend])\n",
    "            st2 = spk.SpikeTrain(spikemon2/ms, edges=[tstart,tend])\n",
    "\n",
    "        return st1,st2\n",
    "\n",
    "    def SPIKEsynch(self,st1,st2):\n",
    "        '''\n",
    "        SPIKE-synchronization measures similarity where 0 means absence of synchrony and bounded to 1\n",
    "        indicating absolute synchrony\n",
    "        '''\n",
    "        spike_sync = spk.spike_sync([st1,st2])\n",
    "        #print spike_sync\n",
    "\n",
    "        # Plotting SPIKE-synchronicity\n",
    "        spike_profile = spk.spike_sync_profile([st1,st2])\n",
    "        x,y = spike_profile.get_plottable_data()\n",
    "        plot(x,y,'-k')\n",
    "        ylabel('SPIKE-sync')\n",
    "\n",
    "    def ISIdistance(self,st1,st2):\n",
    "        '''\n",
    "        ISI-distance quantifies dissimilarity based on differences of interspike intervals from two\n",
    "        different spike trains. Becomes 0 for identical spike trains and approaches -1 and 1 when\n",
    "        first or second spike train is faster than the other, respectively.\n",
    "        '''\n",
    "        isi_prof = spk.isi_profile(st1,st2)\n",
    "        isi_dist = isi_prof.avrg()\n",
    "        #print isi_dist # Outputs nan if spike train has same time values\n",
    "\n",
    "        # Plotting ISI profile\n",
    "        x,y = isi_prof.get_plottable_data()\n",
    "        plot(x,y,'-k')\n",
    "        ylabel('ISI')\n",
    "\n",
    "    def SPIKEdistance(self,st1,st2):\n",
    "        '''\n",
    "        SPIKE-distance quantifies dissimilarity based on exact spike timings. In other words,\n",
    "        dissimilarity in terms of deviations from exact coincidences of spikes\n",
    "        Becomes 0 for identical spike trains, and bounded by 1 for highly dissimilar\n",
    "        '''\n",
    "        spike_dist = spk.spike_distance([st1,st2])\n",
    "        #print spike_dist\n",
    "\n",
    "        spike_profile = spk.spike_profile([st1,st2])\n",
    "        x,y = spike_profile.get_plottable_data()\n",
    "        plot(x,y,'-k')\n",
    "        xlabel('Time (ms)')\n",
    "        ylabel('SPIKE-dist')\n",
    "\n",
    "    def CrossCorrelation(self,spikemon1,spikemon2):\n",
    "        # Normalize spike times\n",
    "        norm1 = spikemon1.t / np.linalg.norm(spikemon1.t)\n",
    "        norm2 = spikemon2.t / np.linalg.norm(spikemon2.t)\n",
    "        test1 = norm1\n",
    "        test2 = norm2\n",
    "        y = np.correlate(test1,test2,\"full\") \n",
    "        z = np.correlate(test1,test1,\"full\") \n",
    "\n",
    "        # Plotting correlation\n",
    "        x_valy = range(len(y))\n",
    "        x_valz = range(len(z))\n",
    "        plot(x_valy-np.argmax(z/ms),y,'b')\n",
    "        plot(x_valz-np.argmax(z/ms),z,'g')\n",
    "        blue_patch = mpatches.Patch(color='blue', label='Test Correlation')\n",
    "        green_patch = mpatches.Patch(color='green', label='Autocorrelation')\n",
    "        suptitle('Comparing network 2 to network 1', fontsize=14, fontweight='bold')\n",
    "        plt.legend(handles=[blue_patch,green_patch])\n",
    "        \n",
    "    def sync_parameter(self,mean,sigma,N):\n",
    "        '''\n",
    "        Takes in the mean value of a parameter and generates another value from a Gaussian distribution within the range\n",
    "        specified by the standard deviation(sigma). The number of values generated corresponds to N. \n",
    "        '''\n",
    "        interval = np.random.normal(mean, sigma,N)\n",
    "        return interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initializing classes\n",
    "t_start = time.time()\n",
    "sync = SynchronicityCalculation()\n",
    "vis = Visualization() \n",
    "BrianVis = BrianVisualization()\n",
    "stats = Spike_Stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define network parameters\n",
    "\n",
    "'''\n",
    "Network Architecture Variables:\n",
    "    n - number of nodes/neurons\n",
    "    p1 - for Network 1, probability for an edge to be formed between two nodes\n",
    "    p2 - for Network 2, probability in a small-world network  \n",
    "    k - each node is connected to k nearest neightbors\n",
    "    rand_seed - method of generating a random number, in this case, one based on time\n",
    "    excit - number of excitatory neurons\n",
    "    inhib - number of inhibitory neurons\n",
    "'''\n",
    "n = 100\n",
    "p1 = 0.5\n",
    "p2 = 0.5 \n",
    "k = 2\n",
    "rand_seed = np.random.seed(int(time.time())) # To seed random number generator based on time\n",
    "excit = int(0.8*n) # 80% of total neurons\n",
    "inhib = int(0.2*n)\n",
    "\n",
    "'''\n",
    "Network Simulation Variables:\n",
    "    N: number of neurons\n",
    "    tau_m: time constant (ms)\n",
    "    v_r: reset membrane potential (mv)\n",
    "    v_th: threshold membrane potential (mv)\n",
    "    I_c: external depolarizing current that is constant\n",
    "    run_time: simulation time (ms)\n",
    "    p_couple: probability that neuron i in first net will couple with neuron i in second net\n",
    "    w_couple: synaptic weight in (V) for connections between sub-networks or between different network groups\n",
    "    PInput: Poisson Input - weight = 0 for off and 0.1 for on\n",
    "    integ_method: method of integration for solving differential equations of neuron dynamics\n",
    "    bin_size: time window to sample spike train data (ms) eg. counting spikes within a certain time interval\n",
    "'''\n",
    "N = n \n",
    "v_r = 0*volt\n",
    "v_th = 1*volt  \n",
    "run_time = 100 # units in ms\n",
    "p_couple = 0.5 #0.99\n",
    "w_couple = 0.5*volt #1 \n",
    "integ_method = 'euler' # or can use 'linear' if differential equation is linear\n",
    "bin_size = 1 # do NOT add units here. It will be added in Stats class under spike_bin function\n",
    "\n",
    "'''\n",
    "Individual Neuron dynamics:\n",
    "    E_l = leakage potential to account for the exchange of all other ions across cell membrane\n",
    "    dia = diameter of post-synaptic surface\n",
    "    length = length of post-synaptic surface\n",
    "    SA = surface area of post-synaptic neuron\n",
    "    gL = conductance of leakage channels\n",
    "    C_mem = membrane capacitance\n",
    "    E_ex = reversal potential of excitatory synaptic potential eg. AMPA\n",
    "    E_i = reversal potential of inhibitory synaptic potential eg. GABA \n",
    "    tau_ge = time constant for signal to go through excitatory synapse\n",
    "    tau_gi_c = time constant for signal to go through inhibitory synapse, same(constant) value applied to all neurons\n",
    "    tau_gi_var = time constant for signal to go through inhibitory synapse, different(variable) value applied to each neuron\n",
    "    v_c: starting voltage(constant) for all neurons in a neuron group before simulation\n",
    "    connect_type: 'ee', 'ii', 'ei','ie'\n",
    "    neuron_diffeqns: neural model for individual neurons, this is a string of differential equations\n",
    "'''\n",
    "\n",
    "E_l = -90*mV\n",
    "dia = 20*um\n",
    "length = 20*um\n",
    "SA = (2*pi*(dia/2)*length) # units are um2\n",
    "gL = 1*psiemens/um2 * SA # units are psiemens\n",
    "C_mem = 10e-6*farad/cm2 * SA # units are farad\n",
    "E_ex = 0*mV\n",
    "E_i = -80*mV \n",
    "v_c = 0*volt\n",
    "I_c = 100000 # same as I_ext, units pamp\n",
    "tau_ge = 2*ms\n",
    "tau_gi_c = 50 # units of ms\n",
    "connect_type = 'ee'\n",
    "\n",
    "# Defining variable parameters using functions in the SynchronicityCalculation class\n",
    "tau_gi_var = sync.sync_parameter(tau_gi_c,1,n)*ms\n",
    "I_var = sync.sync_parameter(I_c,1,n)*pamp\n",
    "\n",
    "model_2 = '''\n",
    "dv/dt = (1/C_mem)*(ge*(v - E_ex) + gi*(v - E_i) + gL*(v - E_l) + I) : volt (unless refractory)\n",
    "dge/dt = -ge/tau_ge : siemens\n",
    "dgi/dt = -gi/tau_gi : siemens\n",
    "I : ampere\n",
    "tau_gi : second\n",
    "'''\n",
    "\n",
    "# Specify which neural model to simulate with\n",
    "neuron_diffeqns = model_2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Individual Network Structure\n",
    "Two small-world networks are created using the following parameters:\n",
    "* n, number of neurons in the network \n",
    "* p, probablity of a synapse to form between two neurons\n",
    "* k, number of nearest neighbours each neuron is connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Creating two small-world networks and their corresponding adjacency matrices\n",
    "\n",
    "'''\n",
    "A1: Adjacency Matrix for a small world network (Network 1), n by n with 1's for a connection and 0's for none\n",
    "A2: Adjacency Matrix for a small world network (Network 2)\n",
    "Graph1: Network object specifying nodes and edges of network architecture for Network 1\n",
    "connect_A1: the unweighted version of connect_W, a 1-D array of excitatory(1) and inhibitory(-1) connections\n",
    "new_coord1: pairs of source and target neurons which are in order and no duplicate pairs\n",
    "new_rows1: 1-D array of all source neurons\n",
    "new_cols1: 1-D array of all target neurons\n",
    "'''\n",
    "\n",
    "Adj = AdjacencyMatrix(n) # Initiates an instance of AdjacencyMatrix class\n",
    "\n",
    "# Network 1: Small World\n",
    "[A1,Graph1] = Adj.small_world(n,k,p2) # Defines random topology using nodes, n and probability, p\n",
    "                        # NetworkX used to generate random graph topography\n",
    "                        # Creates adjacency matrix. For indexes, rows: source neurons, columns: target neurons. \n",
    "                        # 1s indicate nodes connected by an edge, 0s for the opposite\n",
    "\n",
    "# To produce an adjacency matrix with weights adjusted according to excitatory(+ve weight) or inhibitory synapse(-ve weight)\n",
    "[connect_A1,new_coord1,new_rows1,new_cols1] = Adj.adj_synapse_type(A1)\n",
    "\n",
    "# Network 2: Small World\n",
    "# Same process as for Network 1\n",
    "[A2,Graph2] = Adj.small_world(n,k,p2)\n",
    "[connect_A2, new_coord2,new_rows2,new_cols2] = Adj.adj_synapse_type(A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Using functions in the Visualization class\n",
    "\n",
    "cluster = vis.cluster_coeff(Graph1)\n",
    "print (\"For small-world network 1, the clustering co-efficient is\"), cluster\n",
    "\n",
    "# Clustering coefficient for Network 2\n",
    "cluster = vis.cluster_coeff(Graph2)\n",
    "print (\"For small-world network 2, the clustering co-efficient is\"), cluster\n",
    "\n",
    "vis.ex_in_connec(Graph1,connect_A1,new_coord1) # This function also uses new_coord returned from AdjacencyMatrix class, \n",
    "                                               # adj_synapse_type func\n",
    "suptitle('Source Small-world Network Connections', fontsize=14, fontweight='bold')\n",
    "    \n",
    "vis.ex_in_connec(Graph2,connect_A2,new_coord2)\n",
    "suptitle('Target Small-world Network Connections', fontsize=14, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating individual network simulation objects\n",
    "These objects are created using the following parameters:\n",
    "* N, number of neurons for each neuron group\n",
    "* new_rowsx and new_colsx, source and target neuron indexes where synapses need to be formed\n",
    "* connect_Wx, synaptic weights corresponding to unique connections (+ve and -ve values for excitatory and inhibitory connections respectively)\n",
    "* P_Input, <font color='red'> check if we need this when we're planning to supply I_ext as Gaussian white noise </font>\n",
    "* <font color='red'> Synaptic weight is 0.01 here, should it be something else?? </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For Network 1\n",
    "PInput = 0.1*volt\n",
    "connect_W1 = connect_A1*volt\n",
    "[G1,S1,P1] = BrianVis.network_indv(new_rows1,new_cols1,connect_W1,N,PInput)\n",
    "spikemon1 = SpikeMonitor(G1)\n",
    "\n",
    "# For Network 2\n",
    "PInput = 0.1*volt\n",
    "connect_W2 = connect_A2*volt\n",
    "[G2,S2,P2] = BrianVis.network_indv(new_rows2,new_cols2,connect_W2,N,PInput)\n",
    "spikemon2 = SpikeMonitor(G2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coupling the networks\n",
    "Individual networks created above are coupled/connected using the following parameters:\n",
    "* N, number of neurons in the individual network which will be used to determine % of coupling neurons\n",
    "* p_couple, probability of neurons in network that will take part in coupling <font color='red'> (not sure about the difference between manual and probabalistic coupling) </font>\n",
    "* w_couple, weight of (internetwork) synaptic connections <font color='red'> does this need to have +ve and -ve values like the weights for indv networks? </font>\n",
    "* G1 and G2, source and target neuron groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[statemon_G1,spikemon_G1,statemon_G1c2,spikemon_G1c2,G1c2_rows,G1c2_cols,G1c2_coup_mat,S1c2] = BrianVis.network_coupling(N,p_couple,w_couple,G1,G2,'Synapse_1c2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set parameters for Network 1\n",
    "G1.tau_gi = tau_gi_var+10*ms # making network 1 slower than network 2 for entrainment\n",
    "G1.I = I_var\n",
    "\n",
    "# Set parameters for Network 2\n",
    "G2.tau_gi = tau_gi_var\n",
    "G2.I = I_var*0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simulation (will convert this to a class after further testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Simulate a stand alone network 1\n",
    "#This will be used to compare to network 1 during the uncoupled - coupled - uncoupled run\n",
    "\n",
    "# Create a network group with network objects for only Network 1. \n",
    "net_NG1 = Network(G1,S1,P1,spikemon_G1)\n",
    "\n",
    "# Store initial network 1 state so that object G1 can be used in multiple runs\n",
    "net_NG1.store()\n",
    "\n",
    "# Simulate Network 1\n",
    "net_NG1.run(run_time*ms)\n",
    "\n",
    "# Assign Network 1 spikemonitor variables to a different name for the purpose of plotting.\n",
    "# Spikemon_G1 will be reset for subsequent runs\n",
    "SN0 = spikemon_G1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Simulate Network 1 coupled with Network 2\n",
    "\n",
    "net_NG1.restore() # Resetting Network 1 objects like G1, P1 and S1 so they can be simulated again\n",
    "net_NG1.add(G2,S2,P2,S1c2,spikemon_G1c2) # Network group now contains Network 1, Network 2 and coupled state objects\n",
    "\n",
    "t1 = run_time*0.2 # 20% of runtime will be in the uncoupled state at the beginning and end \n",
    "t2 = run_time*0.6 # 60% of runtime will be in the coupled state\n",
    "phase1 = t1\n",
    "phase2 = t1+t2\n",
    "phase3 = t2+2*t1\n",
    "\n",
    "# Change spikemonitor names for ease\n",
    "SN1 = spikemon_G1\n",
    "SN2 = spikemon_G1c2\n",
    "\n",
    "# 1. To begin simulation, set inter-network synaptic weights to 0. i.e. networks are not connected\n",
    "# 2. Run simulation for the first t1*ms\n",
    "S1c2.w = 0\n",
    "net_NG1.run(t1*ms)\n",
    "\n",
    "# 3. Re-establish synaptic connections\n",
    "# 4. Run simulation for the next t2*ms\n",
    "S1c2.w = w_couple\n",
    "net_NG1.run(t2*ms)\n",
    "\n",
    "# 5. Remove synaptic connections again\n",
    "# 6. Run simulation for the last t1*ms \n",
    "S1c2.w = 0\n",
    "net_NG1.run(t1*ms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Raster Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating multi-raster plot\n",
    "fig1 = plt.figure()\n",
    "\n",
    "# Setting up target network axes (red)\n",
    "## adjusting axes with the format: [left, bottom, width, height]\n",
    "h = 0.4\n",
    "ax1 = fig1.add_axes([0.1, 0.6, 1.5, h], ylim=(0, n), xlim = (0,run_time))\n",
    "ax1.set_title('Coupling of Two Small World Networks\\n')\n",
    "ax1.set_xticks([])\n",
    "\n",
    "plt.axvline(x = phase1)\n",
    "plt.axvline(x = phase2)\n",
    "plt.axvline(x = phase3)\n",
    "\n",
    "ylabel('Network 2')\n",
    "\n",
    "# Setting up source network axes (green)\n",
    "ax2 = fig1.add_axes([0.1, 0.2, 1.5, h], ylim=(0, n), xlim = (0,run_time))\n",
    "\n",
    "plt.axvline(x = phase1)\n",
    "plt.axvline(x = phase2)\n",
    "plt.axvline(x = phase3)\n",
    "\n",
    "ylabel('Network 1')\n",
    "xlabel('Time (ms)') \n",
    "\n",
    "# Plotting both raster plots\n",
    "ax1.plot(SN2.t/ms, SN2.i, '.r'); # target or slave network\n",
    "ax2.plot(SN1.t/ms, SN1.i, '.g'); # source or master network\n",
    "                   \n",
    "# Setting up source network axes (black)\n",
    "fig2 = plt.figure()\n",
    "ax3 = fig2.add_axes([0.1, 0.1, 1.5, h], ylim=(0, n), xlim = (0,run_time))\n",
    "\n",
    "plt.axvline(x = phase1)\n",
    "plt.axvline(x = phase2)\n",
    "plt.axvline(x = phase3)\n",
    "\n",
    "ylabel('Uncoupled Network 1')\n",
    "xlabel('Time (ms)') \n",
    "\n",
    "ax3.plot(SN0.t/ms, SN0.i, '.k');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation co-efficient Heat Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spk_extract(spikemon,tstart,tend):\n",
    "    SN_t = []\n",
    "    SN_mon = {}\n",
    "    for k in arange(n):\n",
    "        temp_time = [j for j in spikemon.spike_trains()[k] if j>tstart*ms and j<=tend*ms]\n",
    "        SN_t.extend(temp_time[:])\n",
    "        SN_mon[k] = temp_time\n",
    "    SN_t = sort(SN_t)\n",
    "    return SN_mon, SN_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Extract spike times and corresponding neuron indices for each phase\n",
    "# Get a dictionary of neuron indices and corresponding spike times for each phase(1,2 or 3)\n",
    "# Get an array of overall network spike times for each phase, this will be used as input for PySpike functions\n",
    "\n",
    "[SN1_1,SN1_1t] = spk_extract(SN1,0,phase1) \n",
    "[SN2_1,SN2_1t] = spk_extract(SN2,0,phase1) \n",
    "    \n",
    "[SN1_2,SN1_2t] = spk_extract(SN1,phase1,phase2) \n",
    "[SN2_2,SN2_2t] = spk_extract(SN2,phase1,phase2) \n",
    "    \n",
    "[SN1_3,SN1_3t] = spk_extract(SN1,phase2,phase3) \n",
    "[SN2_3,SN2_3t] = spk_extract(SN2,phase2,phase3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create binary spike trains, put into stats class\n",
    "\n",
    "# Stand-alone network 1\n",
    "SN0_binary = stats.spike_bin(SN0.spike_trains(),bin_size)\n",
    "SN0_CC = stats.spike_cc(SN0_binary,SN0_binary)\n",
    "\n",
    "# First phase of uncoupled networks\n",
    "SN1_1_binary = stats.spike_bin(SN1_1,bin_size)\n",
    "SN2_1_binary = stats.spike_bin(SN2_1,bin_size)\n",
    "SN_1_CC = stats.spike_cc(SN1_1_binary,SN2_1_binary)\n",
    "\n",
    "# Coupled networks\n",
    "SN1_2_binary = stats.spike_bin(SN1_2,bin_size)\n",
    "SN2_2_binary = stats.spike_bin(SN2_2,bin_size)\n",
    "SN_2_CC = stats.spike_cc(SN1_2_binary,SN2_2_binary)\n",
    "\n",
    "# Second phase of uncoupled networks\n",
    "SN1_3_binary = stats.spike_bin(SN1_3,bin_size)\n",
    "SN2_3_binary = stats.spike_bin(SN2_3,bin_size)\n",
    "SN_3_CC = stats.spike_cc(SN1_3_binary,SN2_3_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Generating a heat map\n",
    "fig3 = plt.figure()\n",
    "plt.subplots(figsize=(15,15)) # Increasing the figure size \n",
    "plt.subplots_adjust(hspace = 1) # Change width between subplots\n",
    "\n",
    "ax1 = plt.subplot(2,3,1)\n",
    "ax1.set_title(\"Networks before coupling\")\n",
    "map = plt.imshow(SN_1_CC,cmap = 'RdYlBu',vmin=-1,vmax=1) # Blue gives maximum correlation while red shows least correlation\n",
    "plt.colorbar(map) # To show the legend of colors with corresponding values form matrix            \n",
    "\n",
    "ax2 = plt.subplot(2,3,2)\n",
    "ax2.set_title(\"Networks during coupling\")\n",
    "map2 = plt.imshow(SN_2_CC,cmap = 'RdYlBu',vmin=-1,vmax=1) # Blue gives maximum correlation while red shows least correlation\n",
    "plt.colorbar(map2)\n",
    "\n",
    "ax3 = plt.subplot(2,3,3)\n",
    "ax3.set_title(\"Networks after coupling\")\n",
    "map3 = plt.imshow(SN_3_CC,cmap = 'RdYlBu',vmin=-1,vmax=1) # Blue gives maximum correlation while red shows least correlation\n",
    "plt.colorbar(map3)\n",
    "\n",
    "ax3 = plt.subplot(2,3,5)\n",
    "ax3.set_title(\"Stand-alone Target Network\")\n",
    "map3 = plt.imshow(SN0_CC,cmap = 'RdYlBu',vmin=-1,vmax=1) # Blue gives maximum correlation while red shows least correlation\n",
    "plt.colorbar(map3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_end = time.time()\n",
    "t_end - t_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing PySpike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how PySpike functions are used\n",
    "\n",
    "# Initialize parameters for graphing\n",
    "# [st1,st2] = sync.Initialize(SN1_1t,SN2_1t,0,phase1)\n",
    "# [st3,st4] = sync.Initialize(SN1_2t,SN2_2t,phase1,phase2)\n",
    "# [st4,st5] = sync.Initialize(SN1_3t,SN2_3t,phase2,phase3)\n",
    "\n",
    "# Plot ISI_distance where 0 is for identical spike trains and approaches -1 and 1 when\n",
    "# first or second spike train is faster than the other, respectively.\n",
    "# sync.ISIdistance(st1,st2)\n",
    "\n",
    "# Plot spike distance which looks at exact spike timings: \n",
    "# 0 for identical spike trains, and bounded by 1 for highly dissimilar spikes\n",
    "# sync.SPIKEdistance(st1,st2)\n",
    "\n",
    "# Plot spike synchronization measure where 0 means absence of synchrony and bounded to 1 indicating absolute synchrony\n",
    "# sync.SPIKEsynch(st1,st2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
