{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program Specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Two networks of 100 neurons (80 excitatory/20 inhibitory)\n",
    "- Network topology: random and small world\n",
    "- Network model: simplified integrate-and-fire model (Model 1) and more complex integrate-and-fire (Model 2)\n",
    "- Total run time of 1,000 ms\n",
    "- Display the network model with the functions of the Visualization class\n",
    "- Plot the raster plot of the simulation using the functions of the BrianVisualization class\n",
    "- Plot PSTH (peristimulus time histogram)\n",
    "- Compare the raster plot of the simulation with and without the Poisson inputs to the neurons. \n",
    "\n",
    "Contents: \n",
    "Line 1 to 7: Python package imports\n",
    "Line 1 to 95: Visualization class\n",
    "Line 1 to 183: Brain Visualization class\n",
    "Line 1 to 51: Adjacency Matrix class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Please make sure kernel is Python 2 and not Python 3. \n",
    "# Currently Brian 2 does not work correctly on Python3 even if the package is installed\n",
    "# Refer to README file on GitHub for how to change the Jupyter notebook environment to Python2\n",
    "\n",
    "import networkx as nx\n",
    "from brian2 import *\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Classes\n",
    "\n",
    "### Types: \n",
    "* Visualization\n",
    "* Brian Visualization\n",
    "* Adjacency Matrix\n",
    "* Spike Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Visualization:\n",
    "    '''\n",
    "    Function 2: Visualize neural network\n",
    "    Inputs graph G \n",
    "    Returns cluster coefficient & characteristic path length\n",
    "        & plot of connections between neurons (color-coded)\n",
    "    For more info: see collective dynamics paper\n",
    "    \n",
    "    Description:\n",
    "    From network model, determines cluster coefficient and characteristic path length for each\n",
    "        node. For each network, will take average of those values, respectively and yield \n",
    "        single integer value.\n",
    "    From network model, will output plot of connections, color-coded for excitatory and\n",
    "        inhibitory.\n",
    "    \n",
    "    Returns:\n",
    "        cc_avg: Cluster coefficient averaged over all nodes\n",
    "        ex_in_plot: Plot of colored excitatory/inhibitory connections\n",
    "        cpl_avg: Number of edges at shortest path over all nodes \n",
    "        \n",
    "    Parameters:\n",
    "        G: NetworkX Graph from Function 1\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        #plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "\n",
    "    def cluster_coeff(self,G):        \n",
    "        cc = nx.clustering(G) # calculate clustering co-eff according to different rules eg. no of triangles going through node\n",
    "        # outputs co-eff for all or specified nodes in dict form\n",
    "        cc_y=[]\n",
    "        for idx in cc:\n",
    "            cc_y=np.append(cc_y,cc[idx]) # access and append dict values (co-effs in this case) to array\n",
    "        \n",
    "        cc_avg = np.ndarray.mean(cc_y, dtype=np.float64)\n",
    "        return cc_avg\n",
    "    \n",
    "    def ex_in_connec(self,G,connect_W):\n",
    "        plt.figure()\n",
    "        red_patch = mpatches.Patch(color='red', label='Excitatory')\n",
    "        blue_patch = mpatches.Patch(color='blue', label='Inhibitory')\n",
    "        plt.legend(handles=[red_patch,blue_patch])\n",
    "        suptitle('Structural Connections', fontsize=14, fontweight='bold')\n",
    "\n",
    "        edges = G.edges() # list of tuple pairs\n",
    "        nodes = G.nodes() # array of nodes\n",
    "\n",
    "        custom_color={}\n",
    "        for idx in range(len(connect_W)):\n",
    "            if connect_W[idx] < 0:\n",
    "                inhib_edge = new_coord[idx]\n",
    "                G.add_edge(*inhib_edge)\n",
    "                custom_color[inhib_edge]='b'\n",
    "            else:\n",
    "                excit_edge = new_coord[idx]\n",
    "                G.add_edge(*excit_edge)\n",
    "                custom_color[excit_edge]='r'\n",
    "        if 0:\n",
    "            for idx,idy in enumerate(edges):\n",
    "                x1,y1 = edges[idx]\n",
    "                if connect_W < 0:\n",
    "                    inhib_edge = (x1,y1)\n",
    "                    G.add_edge(x1,y1)\n",
    "                    custom_color[x1,y1]='b' # Stores color of edges in dict\n",
    "                else:\n",
    "                    excit_edge = (x1,y1)\n",
    "                    G.add_edge(x1,y1)\n",
    "                    custom_color[x1,y1]='r'\n",
    "        \n",
    "        ex_in_plot=nx.draw_networkx(G,node_color='w',\n",
    "                         with_labels=True,\n",
    "                         node_list=nodes,\n",
    "                         #node_size=50,\n",
    "                         node_size=200,\n",
    "                         edge_list=custom_color.keys(),\n",
    "                         edge_color=custom_color.values(),\n",
    "                         label='Blue=Inhibitory, Red=Excitatory')\n",
    "        #plt.savefig(\"Structural Connections.png\")\n",
    "        \n",
    "    def char_path_len(self,G):\n",
    "        cpl = nx.all_pairs_shortest_path_length(G) # shortest path lengths. Gen. returns tuple with source and target dict\n",
    "        my_array = []\n",
    "        my_key = []\n",
    "        cpl_count = []\n",
    "        for idx in cpl: # looping through each source node and looking at no of targets and length to target nodes\n",
    "            myarray = cpl[idx[1]] # cpl is a generator object. idx is a tuple (source, target dict). Should be idx[1].\n",
    "            min_val = min(ii for ii in myarray if ii > 0) # Find min length\n",
    "            for key,length in myarray.iteritems():\n",
    "                if length == min_val:\n",
    "                    my_key = np.append(my_key,key) # array of target nodes with min length for specific source node\n",
    "            my_count = len(my_key) # Find number of edges of that length\n",
    "            cpl_count = np.append(cpl_count,my_count)\n",
    "            my_key = []\n",
    "            cpl_avg = np.mean(cpl_count) # Find average of those edges\n",
    "        return cpl_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class BrianVisualization:\n",
    "    '''\n",
    "    Function 4: Visualization of Brian \n",
    "    Define LIF neural population in Brian\n",
    "    Call to save spike times\n",
    "    Call to plot voltage monitor\n",
    "    Call to plot raster plot\n",
    "    Call to plot histogram\n",
    "    \n",
    "    Description:\n",
    "    Will plot the voltage monitor, raster plot, and histogram of neural network\n",
    "    \n",
    "    Returns:\n",
    "        G: NeuronGroup\n",
    "        spike_times: Spike times for neuron 0\n",
    "        all_spikes: Spike times for all neurons\n",
    "        \n",
    "    \n",
    "    Parameters:\n",
    "        statemon: StateMonitor\n",
    "        spikemon: SpikeMonitor\n",
    "        run_time: Simulation run time\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "        \n",
    "        start_scope()\n",
    "    \n",
    "    def network1(self,rows,cols,connect_W,N,PInput):\n",
    "        # rows and cols 1-D arrays of source and target neurons that are connected as defined in graph from networkx\n",
    "        # connect_W: 1-D array of strength of connections corresponding to source and target neuron pairs \n",
    "        '''\n",
    "        For full synch: G1.v = fixed\n",
    "                        PI = off\n",
    "        '''\n",
    "        eqs = neuron_diffeqns # Defined in the input parameter block \n",
    "                \n",
    "        G1 = NeuronGroup(N, eqs, threshold='v>v_th', reset='v=v_r', refractory=10*ms, method=integ_method) #integ_method defined in input parameter block\n",
    "        #G1.v = 'rand()' #random so changes dynamics for each neuron --> causes difference in raster\n",
    "        #G1.v = '0.967188882214'\n",
    "        G1.v = v_c\n",
    "        '''\n",
    "        Injection current is constant but with slight perturbations from PoissonInput, if that function is active\n",
    "        To get rid of highly synchronized, G1.v='rand()' and turn on P1\n",
    "        '''\n",
    "        G1.I = I_c # Constant current define in input block \n",
    "        G1.tau = tau_m1 * ms\n",
    "        \n",
    "        # PoissonInput injection current -- changes each neuron's firing rate\n",
    "        # Each neuron has different input current depending on Poisson distribution\n",
    "        PI_num = 0.8*N \n",
    "        #subG1 = G1[int(PI_num):] # Top 20% of total neurons stimulated\n",
    "        subG1 = G1[:] # All neurons stimulated via Poisson \n",
    "        '''\n",
    "        PoissonInput(target,target_var,N,rate,weight)\n",
    "        target: which neurons to send PoissonInput\n",
    "        target_var: which variable that is being changed from input\n",
    "        N: number of inputs (more input = higher firing rate)\n",
    "        rate: rate of input (100Hz = 10ms per spike)\n",
    "        weight: amount added to voltage\n",
    "        '''\n",
    "        #P1 = PoissonInput(subG1, 'v', 5, 100*Hz, weight=0.1) # PoissonInput on\n",
    "        P1 = PoissonInput(subG1, 'v', 5, 100*Hz, weight=PInput) # PoissonInput off if PInput = 0\n",
    "\n",
    "        \n",
    "        S1 = Synapses(G1, G1, 'w : volt', on_pre='v_post += w') # w is the synapse weight added to the signal\n",
    "        S1.connect(i=rows, j=cols) # Adjacency matrix from Adj.weighted, this uses network structure defined on networkx\n",
    "        S1.w = connect_W/float(100) # Weighted matrix defined from networkx graph \n",
    "               \n",
    "        return G1,S1,P1\n",
    "    \n",
    "    def network2(self,rows,cols,connect_W,N,PInput):\n",
    "        '''\n",
    "        Start off w/ identical network parameters as network 1, but need to eventually change connect_W (its interconnections)\n",
    "        If P2 turned on, may need to increase S3.w so network 1 influence is higher than PoissonInput\n",
    "        '''\n",
    "        eqs = neuron_diffeqns # Defined in the input parameter block\n",
    "\n",
    "        G2 = NeuronGroup(N, eqs, threshold='v>v_th', reset='v=v_r', refractory=10*ms, method=integ_method)\n",
    "        #G2.v = '0.967188882214' # For debugging of coupling so that all nodes in G2 will fire at same rate\n",
    "        #G2.v = 'rand()'\n",
    "        G1.v = v_c\n",
    "        G2.I = I_c\n",
    "        G2.tau = tau_m2 * ms\n",
    "        \n",
    "        subG2 = G2[:]\n",
    "        P2 = PoissonInput(subG2, 'v', 5, 100*Hz, weight=PInput) #PoissonInput on if PInput = 0.1\n",
    "        \n",
    "        S2 = Synapses(G2, G2, 'w: volt', on_pre='v_post += w')\n",
    "        S2.connect(i=rows, j=cols) # Network 2 has same inter-network connections as Network 1\n",
    "        S2.w = connect_W/float(100)\n",
    "        \n",
    "        return G2,S2,P2\n",
    "\n",
    "    def network_coupling(self,N,p_couple,w_couple,G1,G2):\n",
    "        '''\n",
    "        Should see how coupling between different subpopulation has global effects (raster plot)\n",
    "            - Could see difference if neurons have same firing rate (non-PoissonInput) vs. different firing rate (all-PoissonInput)\n",
    "            - May only want to record (Statemon, Spikemon) from this last coupling (G2) to save resources\n",
    "                - See Monitoring Synaptic Variables from http://brian2.readthedocs.io/en/2.0.1/user/synapses.html\n",
    "            = Can introduce multiple output synapses (multisynaptic_index from http://brian2.readthedocs.io/en/2.0.1/user/synapses.html)\n",
    "                - Or more simply \"S.connect(i=numpy.arange(10), j=1)\"\n",
    "        '''\n",
    "        S3 = Synapses(G1,G2, 'w:1', on_pre='v_post += w')#, delay=5*ms) # G1 drives G2\n",
    "        \n",
    "        ### Manually defining coupling ###\n",
    "        p_couple2 = p_couple*N\n",
    "        i_couple = 0.8*N\n",
    "        \n",
    "        # If want 1:1 for only first p_couple% neurons (excitatory --> excitatory)\n",
    "        c_rows = list(arange(0,p_couple2,dtype=int)) # Source neurons\n",
    "        c_cols = list(arange(0,p_couple2,dtype=int)) # Target neurons\n",
    "        \n",
    "        # If want 1:1 for only last p_couple% neurons \n",
    "        #c_rows = list(arange(N-p_couple2,N,dtype=int))\n",
    "        #c_cols = list(arange(N-p_couple2,N,dtype=int))\n",
    "        \n",
    "        # If want 1:1 for inhibitory onto inhibitory neurons\n",
    "        #c_rows = list(arange(N-i_couple,N,dtype=int))\n",
    "        #c_cols = list(arange(N-i_couple,N,dtype=int))        \n",
    "        \n",
    "        # If want 1:1 for projection of excitatory onto inhibitory neurons\n",
    "        #c_rows = list(arange(0,p_couple2,dtype=int))\n",
    "        #c_cols = list(arange(N-i_couple,N,dtype=int))\n",
    "        \n",
    "        # If want 1:! for projection of inhibitory onto excitatory neurons\n",
    "        #c_rows = list(arange(N-p_couple2,N,dtype=int))\n",
    "        #c_cols = list(arange(0,p_couple2,dtype=int))\n",
    "        \n",
    "        S3.connect(i=c_rows, j=c_cols) # Manually defined coupling\n",
    "        S3.w = w_couple\n",
    "        ###################################\n",
    "        \n",
    "        ##### Probabilistic coupling #####\n",
    "        #S3.connect(p=0.05) # Probabilistic connection - Chance that G2 will connect with and spike from G1\n",
    "        #S3.w = 0.02\n",
    "        #S3.connect(p=p_couple)\n",
    "        ###################################\n",
    "                \n",
    "        # Coupling matrix\n",
    "        coup_mat = [[0 for x in range(N)] for y in range(N)]\n",
    "\n",
    "        for ii in range(len(c_rows)):\n",
    "            for jj in range(len(c_cols)):\n",
    "                coup_mat[ii][ii] = 1      # Matrix has 1s for connections and 0s for none\n",
    "\n",
    "        statemon1 = StateMonitor(G1, 'v', record=0) # Records just neuron 0 to save resources\n",
    "        spikemon1 = SpikeMonitor(G1, variables='v')\n",
    "        statemon2 = StateMonitor(G2, 'v', record=0) # Records just neuron 0 to save resources\n",
    "        spikemon2 = SpikeMonitor(G2, variables='v')\n",
    "                \n",
    "        run(run_time*ms, 'text')\n",
    "\n",
    "        return statemon1,spikemon1,statemon2,spikemon2,c_rows,c_cols,coup_mat\n",
    "        \n",
    "    def spike_time(self,spikemon):\n",
    "        all_values = spikemon.all_values()\n",
    "        spike_times = all_values['t'][0] # Spike times for just neuron 0\n",
    "        all_spikes = spikemon.t/ms # Spike times for all neurons\n",
    "        \n",
    "        return spike_times,all_spikes\n",
    "        \n",
    "    def voltage_monitor(self,statemon):\n",
    "        plot(statemon.t/ms, statemon.v[0])\n",
    "        #plot(statemon.t/ms, statemon.v[1])  # Plots second neuron      \n",
    "        ylabel('Voltage (V)')\n",
    "        xlabel('Time (ms)')\n",
    "        \n",
    "    def raster_plot(self,spikemon,spikemon_other):\n",
    "        #ion()\n",
    "        plot(spikemon.t/ms, spikemon.i, '.r')\n",
    "        plot(spikemon_other.t/ms, spikemon_other.i, '.k') # Plots overlay of each network\n",
    "        xlabel('Time (ms)')\n",
    "        ylabel('Neuron index');\n",
    "        #plt.show(block=True)\n",
    "        \n",
    "    def spike_hist(self,run_time,all_spikes):\n",
    "        my_bins = arange(0,run_time+2,2)\n",
    "        plt.hist(all_spikes, bins=my_bins)\n",
    "        xlabel('Time (ms)')\n",
    "        ylabel('Total number of spikes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class AdjacencyMatrix:  \n",
    "    '''\n",
    "    Function 1: Weighted adjacency matrix\n",
    "    Call to initiate adjacency matrix\n",
    "    Call to choose which neural network topology with given parameters\n",
    "    \n",
    "    Description:\n",
    "    Given parameters, constructs network with adjacency matrix and applies random weights.\n",
    "    \n",
    "    Returns:\n",
    "        G: NetworkX Graph\n",
    "        A: Adjacency matrix. Sparse matrix\n",
    "        rows: Presynaptic neurons\n",
    "        cols: Postsynaptic neurons\n",
    "        connect_W: Weights for each E/I connection (in order of rows,cols)\n",
    "    \n",
    "    Parameters:\n",
    "        n: nodes\n",
    "        m: edges\n",
    "        k: neighbor connections\n",
    "        p: probability \n",
    "        d: degrees\n",
    "    '''\n",
    "    def __init__(self,n): \n",
    "        plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "        \n",
    "    def random(self,n,p): \n",
    "        # Interchangeable based on UI for different types of topography\n",
    "        #G = nx.dense_gnm_random_graph(n,m) # Uses NetX to generate random topography, need to add input param m\n",
    "        G = nx.gnp_random_graph(n,p)\n",
    "        #nx.draw(G, with_labels=True) # Draws connectivity figure\n",
    "        #plt.savefig(\"Random.png\") # Saves connectivity figure as Random.png\n",
    "\n",
    "        # Extracts ADJACENCY MATRIX from topography and rearranges to manageable array of (n*n) elements\n",
    "        A = nx.adjacency_matrix(G) # Assigns A as adjacency matrix (which nodes are connected)\n",
    "        return A, G \n",
    "    \n",
    "    def small_world(self,n,k,p): \n",
    "        G = nx.newman_watts_strogatz_graph(n,k,p) \n",
    "        #nx.draw(G, with_labels=True)\n",
    "        #plt.savefig(\"Small-world.png\")\n",
    "        A = nx.adjacency_matrix(G)\n",
    "        return A, G\n",
    "    \n",
    "    def unidir_coord(self,rows, cols):\n",
    "        # function to remove duplicate connections like (0,3) and (3,0) so that all connections are uni- and not bi-directional\n",
    "        new_coord = zip(rows,cols) # To get an array of coordinate pair tuples, to define node pairs or edges \n",
    "        #print new_coord\n",
    "        new_rows = set(tuple(sorted(l)) for l in new_coord) # set removes duplicate tuples that are now ordered pairs\n",
    "        # set(array of tuples)\n",
    "        g = np.array(list(new_rows)) #array of 1 by 2 neuron pair vectors that are connected to each other\n",
    "        # In each 1 by 2 vector: column 0 is source neuron and column 1 is target neuron\n",
    "        new_rows = g[:,0] #1-D array of all source neurons i\n",
    "        new_cols = g[:,1] #1-D array of all target neurons j\n",
    "        new_coord = zip(rows,cols) # list of tuples, source and target ordered pairs with no duplicates\n",
    "        return new_coord, new_rows, new_cols\n",
    "    \n",
    "    def adj_synapse_type(self,A):\n",
    "        ### Define connections as inhibitory or excitatory in the adjacency matrix\n",
    "        A_mat = A.todense() # Converts adjacency matrix from 'scipy.sparse.csr.csr_matrix' to numpy matrix                              \n",
    "        rows, cols = np.nonzero(A_mat) # Two arrays of index positions for connections\n",
    "        [new_coord, new_rows, new_cols] = self.unidir_coord(rows,cols) # Removes duplicate connections\n",
    "        connect = len(new_rows) # number of connections or 1s in adjacency matrix\n",
    "\n",
    "        for i in range(connect):\n",
    "            x = new_rows[i]\n",
    "            y = new_cols [i]\n",
    "            if x>(excit-1) or y>(excit-1):   # Checking if either source or target neuron belongs to upper 20% of n \n",
    "                A_mat[x,y] = A_mat[x,y]*-1   # Inhibitory neuron defined, weight is made negative\n",
    "\n",
    "        # Constructing array of unweighted connections\n",
    "        connect_A = [] # Initializaing empty connections array\n",
    "        for i in range(connect):\n",
    "            x = new_rows[i]\n",
    "            y = new_cols [i]\n",
    "            connect_A.append(A_mat[x,y])\n",
    "        connect_A = np.array(connect_A) # Converting data type list to numpy array\n",
    "        return connect_A,new_coord,new_rows,new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Spike_Stats:\n",
    "    '''\n",
    "    Description: Given spike times of each neuron, statistical parameters of ISI(Inter-Spike-Interval) can be calculated\n",
    "                 like mean, variance, co-efficent of variation. Spike trains can also be compared to produce correlation\n",
    "                 coefficients\n",
    "    \n",
    "    Parameters: \n",
    "    '''\n",
    "    \n",
    "    def __init__(self): # Not sure what to do here yet\n",
    "        pass\n",
    "    \n",
    "    def ISI_stats(self,spikemon):\n",
    "        neuron_spikes = spikemon.spike_trains() # Dictionary with dict keys as neuron indices and \n",
    "                                         # dict values as an array of spike times for that neuron\n",
    "        firing_n = list(set(sort(spikemon.i))) # To create a set or list of all unique neuron indices that have spiked\n",
    "                                                # in order to calculate statistical parameters for each unique neuron\n",
    "            \n",
    "        ISI = {} # Create an empty dictionary to contain dict keys as neuron indices and dict values as an array of ISIs\n",
    "        ISI_mean = {} # Dict for ISI mean of each neuron index\n",
    "        ISI_var = {} # Dict for ISI variance of each neuron index\n",
    "        ISI_cv = {} # Dict for ISI co-efficient of variation (CV) for each neuron index\n",
    "\n",
    "        # Calculate variance and mean of each ISI (Inter-Spike-Interval)\n",
    "        for i in firing_n:\n",
    "            # Calculate ISI array by subtracting spike times of each neuron to get an array of spike intervals\n",
    "            ISI[i] = np.diff(neuron_spikes[i])\n",
    "            # Calculate mean of ISI\n",
    "            ISI_mean[i] = np.mean(ISI[i])\n",
    "            # Calculate variance of ISI\n",
    "            ISI_var[i] = np.var(ISI[i])\n",
    "            # Calculate co-efficient of variation(CV) of ISI\n",
    "            ISI_cv[i] = np.sqrt(ISI_var[i])/ISI_mean[i]\n",
    "        return ISI,ISI_mean,ISI_var,ISI_cv\n",
    "    \n",
    "    def spike_bin(self,ISI,bin_size):\n",
    "        sp_binary = {}\n",
    "        t_interval = range(0,run_time,bin_size)\n",
    "        t_size = len(t_interval)\n",
    "\n",
    "        for k in ISI:\n",
    "            temp = [0]*t_size\n",
    "            count= 0\n",
    "            for t in t_interval: # for loop to search for spikes in the current time interval\n",
    "                #print(count)\n",
    "                for r in ISI[k]: # looks through all spike times to see if any are within the current time interval\n",
    "                    if r>t*ms and r<=(t+bin_size)*ms:\n",
    "                        temp[count] = 1\n",
    "                        break    # breaks out of for loop when at least one spike has been found for the time interval \n",
    "                                 # and moves on to the next time interval\n",
    "                    else:\n",
    "                        temp[count] = 0\n",
    "                count = count + 1\n",
    "            sp_binary[k] = temp\n",
    "        return sp_binary\n",
    "\n",
    "    def spike_cc(self,bin_vector):\n",
    "        var = [] # A empty list that will contain lists of binary spike trains\n",
    "        for k in bin_vector:\n",
    "            var.append(bin_vector[k]) # Required format to use with numpy's corrcoef function\n",
    "\n",
    "        CC_matrix = np.corrcoef(var) # This matrix is N-neurons by N-neurons and the main diagonal is all 1s \n",
    "                                     # test with try CC_matrix.shape to confirm\n",
    "        return CC_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define network parameters\n",
    "\n",
    "'''\n",
    "Network Architecture Variables:\n",
    "    n - number of nodes/neurons\n",
    "    p - probability for an edge to be formed between two nodes\n",
    "    p_sm - probability in a small-world network \n",
    "    k - each node is connected to k nearest neightbors\n",
    "    rand_seed - method of generating a random number, in this case, one based on time\n",
    "    excit - number of excitatory neurons\n",
    "    inhib - number of inhibitory neurons\n",
    "    connect_A - the unweighted version of connect_W, a 1-D array of excitatory(1) and inhibitory(-1) connections\n",
    "'''\n",
    "n = 100\n",
    "p = 0.2\n",
    "p_sm = 1 \n",
    "k = 2\n",
    "rand_seed = np.random.seed(int(time.time())) # To seed random number generator based on time\n",
    "excit = int(0.8*n) # 80% of total neurons\n",
    "inhib = int(0.2*n)\n",
    "\n",
    "'''\n",
    "Network Simulation Variables:\n",
    "    N: number of neurons\n",
    "    tau_m: time constant (ms)\n",
    "    v_r = reset membrane potential (mv)\n",
    "    v_th = threshold membrane potential (mv)\n",
    "    I_c = external depolarizing current that is constant\n",
    "    run_time = simulation time (ms)\n",
    "    p_couple = probability that neuron i in first net will couple with neuron i in second net\n",
    "    PInput = Poisson Input: weight = 0 for off and 0.1 for on\n",
    "'''\n",
    "N = n \n",
    "v_r = 0*volt\n",
    "v_th = 1*volt  \n",
    "run_time = 1000\n",
    "#p_couple = 0.1 #0.99\n",
    "integ_method = 'euler' # or can use 'linear' if differential equation is linear\n",
    "bin_size = 1 # Units are ms, do NOT add them here. It will be added in Stats class under spike_bin function\n",
    "\n",
    "'''\n",
    "Individual Neuron dynamics\n",
    "    E_K = reverse potential for Potassium across lipid bilayer\n",
    "    E_Na = reverse potential for Sodium across lipid bilayer\n",
    "    E_L = leakage potential to account for the exchange of all other ions across cell membrane\n",
    "    dia = diameter of post-synaptic surface\n",
    "    length = length of post-synaptic surface\n",
    "    SA = surface area of post-synaptic neuron\n",
    "    gL = conductance of leakage channels\n",
    "    C_mem = membrane capacitance\n",
    "    E_ex = reversal potential of excitatory synaptic potential eg. AMPA\n",
    "    E_i = reversal potential of inhibitory synaptic potential eg. GABA \n",
    "'''\n",
    "#E_K = -80*mV\n",
    "#E_Na = 20*mV\n",
    "E_l = -90*mV\n",
    "dia = 20*um\n",
    "length = 20*um\n",
    "SA = (2*pi*(dia/2)*length) # units are um2\n",
    "gL = 1*psiemens/um2 * SA # units are psiemens\n",
    "C_mem = 10e-6*farad/cm2 * SA # units are farad\n",
    "E_ex = 0*mV\n",
    "E_i = -80*mV \n",
    "v_c = 0*volt\n",
    "I_c = 10*pamp # same as I_ext\n",
    "tau_m1 = 0\n",
    "tau_m2 = 0\n",
    "tau_ge = 5*ms\n",
    "tau_gi = 2*ms\n",
    "\n",
    "model_2 = '''\n",
    "dv/dt = (1/C_mem)*(ge*(v - E_ex) + gi*(v - E_i) + gL*(v - E_l) + I) : volt (unless refractory)\n",
    "dge/dt = -ge/tau_ge : siemens\n",
    "dgi/dt = -gi/tau_gi : siemens\n",
    "I : ampere\n",
    "tau : second\n",
    "'''\n",
    "\n",
    "# Leaky integrate and fire neuron (from previous code) \n",
    "# NOTE:Need to include cell resistance so that (RI - v) dimensions match\n",
    "#R = 1*ohm # Assumption for cell resistance\n",
    "#I_c = 2*amp\n",
    "#tau_m1 = 20.4 #37\n",
    "#tau_m2 = 32.4 #43\n",
    "\n",
    "model_1 = '''                \n",
    "dv/dt = (R*I-v)/tau : volt (unless refractory)\n",
    "I : ampere\n",
    "tau : second\n",
    "'''   \n",
    "\n",
    "neuron_diffeqns = model_2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named scipy",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8fd72ee225b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Network 1: Random\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Defines random topology using nodes, n and probability, p\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                         \u001b[1;31m# NetworkX used to generate random graph topography\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                         \u001b[1;31m# Creates adjacency matrix. For indexes, rows: source neurons, columns: target neurons.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-a2ba0ceabe4f>\u001b[0m in \u001b[0;36mrandom\u001b[1;34m(self, n, p)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# Extracts ADJACENCY MATRIX from topography and rearranges to manageable array of (n*n) elements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madjacency_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Assigns A as adjacency matrix (which nodes are connected)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pkhor\\Anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\networkx\\linalg\\graphmatrix.pyc\u001b[0m in \u001b[0;36madjacency_matrix\u001b[1;34m(G, nodelist, weight)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[0mto_dict_of_dicts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \"\"\"\n\u001b[1;32m--> 162\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_scipy_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodelist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnodelist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pkhor\\Anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\networkx\\convert_matrix.pyc\u001b[0m in \u001b[0;36mto_scipy_sparse_matrix\u001b[1;34m(G, nodelist, dtype, weight, format)\u001b[0m\n\u001b[0;32m    758\u001b[0m        \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morg\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mreference\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \"\"\"\n\u001b[1;32m--> 760\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnodelist\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m         \u001b[0mnodelist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named scipy"
     ]
    }
   ],
   "source": [
    "### Creating a network of 100 neurons and its corresponding adjacency matrix\n",
    "\n",
    "Adj = AdjacencyMatrix(n) # Initiates an instance of AdjacencyMatrix class\n",
    "\n",
    "# Network 1: Random\n",
    "[A,G] = Adj.random(n,p) # Defines random topology using nodes, n and probability, p\n",
    "                        # NetworkX used to generate random graph topography\n",
    "                        # Creates adjacency matrix. For indexes, rows: source neurons, columns: target neurons. \n",
    "                        # 1s indicate nodes connected by an edge, 0s for the opposite\n",
    "\n",
    "# To produce an adjacency matrix with weights adjusted according to excitatory(+ve weight) or inhibitory synapse(-ve weight)\n",
    "[connect_A,new_coord,new_rows,new_cols] = Adj.adj_synapse_type(A)\n",
    "\n",
    "# Network 2: Small World\n",
    "# Same process as for Network 1\n",
    "Adj = AdjacencyMatrix(n) # Initiates an instance of AdjacencyMatrix class\n",
    "[A_sm,G_sm] = Adj.small_world(n,k,p_sm)\n",
    "[connect_A_sm, new_coord_sm,new_rows_sm,new_cols_sm] = Adj.adj_synapse_type(A_sm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Using functions in the Visualization class\n",
    "\n",
    "vis = Visualization() # Initializing the class\n",
    "\n",
    "cluster = vis.cluster_coeff(G)\n",
    "print (\"For random network 1, the clustering co-efficient is\"), cluster\n",
    "\n",
    "## Same process for small-world, Network 2\n",
    "cluster = vis.cluster_coeff(G_sm)\n",
    "print (\"For small-world network 2, the clustering co-efficient is\"), cluster\n",
    "\n",
    "print (\"\\nConnection Types in the Random Network\")\n",
    "vis.ex_in_connec(G,connect_A) # This function also uses new_coord returned from AdjacencyMatrix class, adj_synapse_type func\n",
    "\n",
    "#char_pl = vis.char_path_len(G)\n",
    "#print \"Characteristic path length is\", char_pl\n",
    "\n",
    "#print \"\\nConnection Types in the Small-world Network\"\n",
    "#vis.ex_in_connec(G_small,connect_A_small) \n",
    "# This function also uses new_coord returned from AdjacencyMatrix class, adj_synapse_type func\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Simulating the network\n",
    "connect_W = connect_A*volt\n",
    "\n",
    "# Initializing BrianVis class\n",
    "BrianVis = BrianVisualization()\n",
    "\n",
    "# Run LIF model for first network with Poisson input\n",
    "PInput = 0.1*volt\n",
    "[G1,S1,P1] = BrianVis.network1(new_rows,new_cols,connect_W,N,PInput) # Modified Brian network 1 and 2 class def for PInput\n",
    "spikemon1 = SpikeMonitor(G1)\n",
    "\n",
    "# Run LIF model for second network with Poisson input\n",
    "PInput = 0.1*volt\n",
    "connect_W_sm = connect_A_sm*volt\n",
    "[G2,S2,P2] = BrianVis.network2(new_rows_sm,new_cols_sm,connect_W_sm,N,PInput) # Modified Brian class def for PInput\n",
    "spikemon2 = SpikeMonitor(G2)\n",
    "\n",
    "run(run_time*ms) # This simulates both network1 and network2 defined above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Plotting raster plot\n",
    "fig1 = plt.figure() \n",
    "fig1.suptitle(\"Raster plots for Random Networks\")\n",
    "plt.subplots(figsize=(10,5)) # Increasing the figure size \n",
    "plt.subplots_adjust(wspace = 1) # Change width between subplots\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "ax.set_title(\"Network 1: Random With Poisson Input\")\n",
    "BrianVis.raster_plot(spikemon1,spikemon1)\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "ax.set_title(\"Network 2: Small World With Poisson Input\")\n",
    "BrianVis.raster_plot(spikemon2,spikemon2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Plotting PSTH plot\n",
    "\n",
    "# Gather data for network 1\n",
    "[spike_times1,all_spikes1] = BrianVis.spike_time(spikemon1)\n",
    "\n",
    "# Gather data for network 1\n",
    "[spike_times2,all_spikes2] = BrianVis.spike_time(spikemon2)\n",
    "\n",
    "fig2 = plt.figure()\n",
    "fig2.suptitle(\"PSTH plots for Random Networks\")\n",
    "plt.subplots(figsize=(10,5)) # Increasing the figure size \n",
    "plt.subplots_adjust(wspace = 1) # Change width between subplots\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "ax.set_title(\"Random with Poisson Input\")\n",
    "BrianVis.spike_hist(run_time,all_spikes1)\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "ax.set_title(\"Small World with Poisson Input\")\n",
    "BrianVis.spike_hist(run_time,all_spikes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Statistical Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def spike_stat(spikemon):\n",
    "    # provide a pairs showing index and spike times of neurons\n",
    "    list_of_pairs = zip(*spikemon.it)\n",
    "    # represent neuron index in an array\n",
    "    neuron_index_list = list(spikemon.i)\n",
    "    # represent neuron spike times in a separate array\n",
    "    spike_time_list = list(spikemon.t)\n",
    "    index_array, time_array = spikemon.i, spikemon.t\n",
    "\n",
    "    # make a dictionary where each index represents the \n",
    "    # neuron index and the corresponding array represents all spike times of the neuron\n",
    "    from collections import defaultdict\n",
    "    neuron_spikes = defaultdict(list)\n",
    "    for index,value in enumerate(index_array):\n",
    "        neuron_spikes[value] += [time_array[index]]\n",
    "    for l in neuron_spikes:\n",
    "        neuron_spikes[l] = sorted(neuron_spikes[l])\n",
    "    # find the difference between the spike times \n",
    "    for g in neuron_spikes:\n",
    "        lis = neuron_spikes[g]\n",
    "        l = list()\n",
    "        for index,f in enumerate(lis):\n",
    "            if(index+1 >= len(neuron_spikes[g])):\n",
    "                continue\n",
    "            else:\n",
    "                l += [(lis[index+1]/ms)-(f/ms)]\n",
    "        neuron_spikes[g] = l\n",
    "    # make a function to calculate average\n",
    "    def avg(numbers):\n",
    "        return float(sum(numbers)) / max(len(numbers), 1)\n",
    "    mean = []\n",
    "    std = []\n",
    "    # find the standard deviation\n",
    "    for liss in neuron_spikes:\n",
    "        lists = neuron_spikes[liss]\n",
    "        std.append(numpy.std(lists))\n",
    "        mean.append(avg(lists))\n",
    "     # find the coefficient of variance by dividing mean by std\n",
    "    cv = []\n",
    "    for s in range(100): \n",
    "        cv.append(std[s]/mean[s])   \n",
    "\n",
    "    return numpy.round(mean,2),numpy.round(std,2),numpy.round(cv,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate ISI mean, variance and co-efficient of variation from spike times\n",
    "stats = Spike_Stats() # Initialize Spike Stats class\n",
    "[ISI,ISI_mean,ISI_var,ISI_cv] = stats.ISI_stats(spikemon1)\n",
    "[ISI2,ISI2_mean,ISI2_var,ISI2_cv] = stats.ISI_stats(spikemon2)\n",
    "\n",
    "# Create binary spike trains, put into stats class\n",
    "sp_binary = stats.spike_bin(ISI,bin_size)\n",
    "sp2_binary = stats.spike_bin(ISI2,bin_size)\n",
    "\n",
    "# Calculating correlation co-efficient\n",
    "CC_matrix = stats.spike_cc(sp_binary)\n",
    "CC2_matrix = stats.spike_cc(sp2_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation co-efficient Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generating a heat map\n",
    "fig3 = plt.figure()\n",
    "plt.subplots(figsize=(10,5)) # Increasing the figure size \n",
    "#plt.subplots_adjust(wspace = 1) # Change width between subplots\n",
    "\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "ax1.set_title(\"Random with Poisson Input\")\n",
    "map = plt.imshow(CC_matrix,cmap = 'RdBu') # Blue gives maximum correlation while red shows least correlation\n",
    "plt.colorbar(map) # To show the legend of colors with corresponding values form matrix            \n",
    "\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.set_title(\"Small World with Poisson Input\")\n",
    "map2 = plt.imshow(CC2_matrix,cmap = 'RdBu') # Blue gives maximum correlation while red shows least correlation\n",
    "plt.colorbar(map2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
