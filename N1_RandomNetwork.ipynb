{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program Specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Two networks of 100 neurons (80 excitatory/20 inhibitory)\n",
    "- Network topology: random and small world\n",
    "- Network model: simplified integrate-and-fire model (Model 1) and more complex integrate-and-fire (Model 2)\n",
    "- Total run time of 1,000 ms\n",
    "- Display the network model with the functions of the Visualization class\n",
    "- Plot the raster plot of the simulation using the functions of the BrianVisualization class\n",
    "- Plot PSTH (peristimulus time histogram)\n",
    "- Compare the raster plot of the simulation with and without the Poisson inputs to the neurons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Please make sure kernel is Python 2 and not Python 3. \n",
    "# Currently Brian 2 does not work correctly on Python3 even if the package is installed\n",
    "# Refer to README file on GitHub for how to change the Jupyter notebook environment to Python2\n",
    "# Refer to README file on GitHub for how to setup PySpike\n",
    "\n",
    "import networkx as nx\n",
    "from brian2 import *\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pyspike as spk\n",
    "%matplotlib inline\n",
    "\n",
    "# for testing purposes in BrianVis class\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Classes\n",
    "\n",
    "### Types: \n",
    "* Visualization\n",
    "* Brian Visualization\n",
    "* Adjacency Matrix\n",
    "* Spike Stats\n",
    "* Synchronicity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Visualization:\n",
    "    '''\n",
    "    Function 2: Visualize neural network\n",
    "    Inputs graph G \n",
    "    Returns cluster coefficient & characteristic path length\n",
    "        & plot of connections between neurons (color-coded)\n",
    "    For more info: see collective dynamics paper\n",
    "    \n",
    "    Description:\n",
    "    From network model, determines cluster coefficient and characteristic path length for each\n",
    "        node. For each network, will take average of those values, respectively and yield \n",
    "        single integer value.\n",
    "    From network model, will output plot of connections, color-coded for excitatory and\n",
    "        inhibitory.\n",
    "    \n",
    "    Returns:\n",
    "        cc_avg: Cluster coefficient averaged over all nodes\n",
    "        ex_in_plot: Plot of colored excitatory/inhibitory connections\n",
    "        cpl_avg: Number of edges at shortest path over all nodes \n",
    "        \n",
    "    Parameters:\n",
    "        G: NetworkX Graph from Function 1\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        #plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "\n",
    "    def cluster_coeff(self,G):        \n",
    "        cc = nx.clustering(G) # calculate clustering co-eff according to different rules eg. no of triangles going through node\n",
    "        # outputs co-eff for all or specified nodes in dict form\n",
    "        cc_y=[]\n",
    "        for idx in cc:\n",
    "            cc_y=np.append(cc_y,cc[idx]) # access and append dict values (co-effs in this case) to array\n",
    "        \n",
    "        cc_avg = np.ndarray.mean(cc_y, dtype=np.float64)\n",
    "        return cc_avg\n",
    "    \n",
    "    def ex_in_connec(self,G,connect_W,new_coord):\n",
    "        plt.figure()\n",
    "        red_patch = mpatches.Patch(color='red', label='Excitatory')\n",
    "        blue_patch = mpatches.Patch(color='blue', label='Inhibitory')\n",
    "        plt.legend(handles=[red_patch,blue_patch])\n",
    "        suptitle('Structural Connections', fontsize=14, fontweight='bold')\n",
    "\n",
    "        edges = G.edges() # list of tuple pairs\n",
    "        nodes = G.nodes() # array of nodes\n",
    "\n",
    "        custom_color={}\n",
    "        for idx in range(len(connect_W)):\n",
    "            if connect_W[idx] < 0:\n",
    "                inhib_edge = new_coord[idx]\n",
    "                G.add_edge(*inhib_edge)     # adds an inhibitory edge connection to graph if it's not already there\n",
    "                custom_color[inhib_edge]='b'\n",
    "            else:\n",
    "                excit_edge = new_coord[idx]\n",
    "                G.add_edge(*excit_edge)\n",
    "                custom_color[excit_edge]='r'\n",
    "        if 0:\n",
    "            for idx,idy in enumerate(edges):\n",
    "                x1,y1 = edges[idx]\n",
    "                if connect_W < 0:\n",
    "                    inhib_edge = (x1,y1)\n",
    "                    G.add_edge(x1,y1)\n",
    "                    custom_color[x1,y1]='b' # Stores color of edges in dict\n",
    "                else:\n",
    "                    excit_edge = (x1,y1)\n",
    "                    G.add_edge(x1,y1)\n",
    "                    custom_color[x1,y1]='r'\n",
    "        \n",
    "        ex_in_plot=nx.draw_networkx(G,node_color='w',\n",
    "                         with_labels=True,\n",
    "                         node_list=nodes,\n",
    "                         #node_size=50,\n",
    "                         node_size=200,\n",
    "                         edge_list=custom_color.keys(),\n",
    "                         edge_color=custom_color.values(),\n",
    "                         label='Blue=Inhibitory, Red=Excitatory')\n",
    "        #plt.savefig(\"Structural Connections.png\")\n",
    "        \n",
    "    def char_path_len(self,G):\n",
    "        cpl = nx.all_pairs_shortest_path_length(G) # shortest path lengths. Gen. returns tuple with source and target dict\n",
    "        my_array = []\n",
    "        my_key = []\n",
    "        cpl_count = []\n",
    "        for idx in cpl: # looping through each source node and looking at no of targets and length to target nodes\n",
    "            myarray = cpl[idx[1]] # cpl is a generator object. idx is a tuple (source, target dict). Should be idx[1].\n",
    "            min_val = min(ii for ii in myarray if ii > 0) # Find min length\n",
    "            for key,length in myarray.iteritems():\n",
    "                if length == min_val:\n",
    "                    my_key = np.append(my_key,key) # array of target nodes with min length for specific source node\n",
    "            my_count = len(my_key) # Find number of edges of that length\n",
    "            cpl_count = np.append(cpl_count,my_count)\n",
    "            my_key = []\n",
    "            cpl_avg = np.mean(cpl_count) # Find average of those edges\n",
    "        return cpl_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class BrianVisualization:\n",
    "    '''\n",
    "    Function 4: Visualization of Brian \n",
    "    Define LIF neural population in Brian\n",
    "    Call to save spike times\n",
    "    Call to plot voltage monitor\n",
    "    Call to plot raster plot\n",
    "    Call to plot histogram\n",
    "    \n",
    "    Description:\n",
    "    Will plot the voltage monitor, raster plot, and histogram of neural network\n",
    "    \n",
    "    Returns:\n",
    "        G: NeuronGroup\n",
    "        spike_times: Spike times for neuron 0\n",
    "        all_spikes: Spike times for all neurons\n",
    "        \n",
    "    \n",
    "    Parameters:\n",
    "        statemon: StateMonitor\n",
    "        spikemon: SpikeMonitor\n",
    "        run_time: Simulation run time\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "        \n",
    "        start_scope()\n",
    "    \n",
    "    def network1(self,rows,cols,connect_W,N,PInput):\n",
    "        # rows and cols 1-D arrays of source and target neurons that are connected as defined in graph from networkx\n",
    "        # connect_W: 1-D array of strength of connections corresponding to source and target neuron pairs \n",
    "        '''\n",
    "        For full synch: G1.v = fixed\n",
    "                        PI = off\n",
    "        '''\n",
    "        eqs = neuron_diffeqns # Defined in the input parameter block \n",
    "                \n",
    "        G1 = NeuronGroup(N, eqs, threshold='v>v_th', reset='v=v_r', refractory=10*ms, method=integ_method,name='Neuron_Group1') #integ_method defined in input parameter block\n",
    "        #G1.v = 'rand()' #random so changes dynamics for each neuron --> causes difference in raster\n",
    "        #G1.v = '0.967188882214'\n",
    "        G1.v = v_c\n",
    "        '''\n",
    "        Injection current is constant but with slight perturbations from PoissonInput, if that function is active\n",
    "        To get rid of highly synchronized, G1.v='rand()' and turn on P1\n",
    "        '''\n",
    "        G1.I = I_c # Constant current define in input block \n",
    "        G1.tau = tau_m1 * ms\n",
    "        \n",
    "        # PoissonInput injection current -- changes each neuron's firing rate\n",
    "        # Each neuron has different input current depending on Poisson distribution\n",
    "        PI_num = 0.8*N \n",
    "        #subG1 = G1[int(PI_num):] # Top 20% of total neurons stimulated\n",
    "        subG1 = G1[:] # All neurons stimulated via Poisson \n",
    "        '''\n",
    "        PoissonInput(target,target_var,N,rate,weight)\n",
    "        target: which neurons to send PoissonInput\n",
    "        target_var: which variable that is being changed from input\n",
    "        N: number of inputs (more input = higher firing rate)\n",
    "        rate: rate of input (100Hz = 10ms per spike)\n",
    "        weight: amount added to voltage\n",
    "        '''\n",
    "        #P1 = PoissonInput(subG1, 'v', 5, 100*Hz, weight=0.1) # PoissonInput on\n",
    "        P1 = PoissonInput(subG1, 'v', 5, 100*Hz, weight=PInput) # PoissonInput off if PInput = 0\n",
    "\n",
    "        \n",
    "        S1 = Synapses(G1, G1, 'w : volt', on_pre='v_post += w') # w is the synapse weight added to the signal\n",
    "        S1.connect(i=rows, j=cols) # Adjacency matrix from Adj.weighted, this uses network structure defined on networkx\n",
    "        S1.w = connect_W/float(100) # Weighted matrix defined from networkx graph \n",
    "               \n",
    "        return G1,S1,P1\n",
    "    \n",
    "    def network2(self,rows,cols,connect_W,N,PInput,NG_name,SG_name):\n",
    "        '''\n",
    "        Start off w/ identical network parameters as network 1, but need to eventually change connect_W (its interconnections)\n",
    "        If P2 turned on, may need to increase S3.w so network 1 influence is higher than PoissonInput\n",
    "        '''\n",
    "        eqs = neuron_diffeqns # Defined in the input parameter block\n",
    "\n",
    "        G2 = NeuronGroup(N, eqs, threshold='v>v_th', reset='v=v_r', refractory=10*ms, method=integ_method,name=NG_name)\n",
    "        #G2.v = '0.967188882214' # For debugging of coupling so that all nodes in G2 will fire at same rate\n",
    "        #G2.v = 'rand()'\n",
    "        G2.v = v_c\n",
    "        G2.I = I_c\n",
    "        G2.tau = tau_m2 * ms\n",
    "        \n",
    "        subG2 = G2[:]\n",
    "        P2 = PoissonInput(subG2, 'v', 5, 100*Hz, weight=PInput) #PoissonInput on if PInput = 0.1\n",
    "        \n",
    "        S2 = Synapses(G2, G2, 'w: volt', on_pre='v_post += w',name=SG_name)\n",
    "        S2.connect(i=rows, j=cols) # Network 2 has same inter-network connections as Network 1\n",
    "        S2.w = connect_W/float(100)\n",
    "        \n",
    "        return G2,S2,P2\n",
    "\n",
    "    def network_coupling(self,N,p_couple,w_couple,G1,G2,SG_name):\n",
    "        '''\n",
    "        Should see how coupling between different subpopulation has global effects (raster plot)\n",
    "            - Could see difference if neurons have same firing rate (non-PoissonInput) vs. different firing rate (all-PoissonInput)\n",
    "            - May only want to record (Statemon, Spikemon) from this last coupling (G2) to save resources\n",
    "                - See Monitoring Synaptic Variables from http://brian2.readthedocs.io/en/2.0.1/user/synapses.html\n",
    "            = Can introduce multiple output synapses (multisynaptic_index from http://brian2.readthedocs.io/en/2.0.1/user/synapses.html)\n",
    "                - Or more simply \"S.connect(i=numpy.arange(10), j=1)\"\n",
    "        '''\n",
    "        S3 = Synapses(G1,G2, 'w: volt', on_pre='v_post += w',name=SG_name)#, delay=5*ms) # G1 drives G2\n",
    "        \n",
    "        ### Manually defining coupling ###\n",
    "        p_couple2 = p_couple*N\n",
    "        i_couple = 0.2*N\n",
    "        \n",
    "        if connect_type == 'ee':\n",
    "            c_rows = list(arange(0,p_couple2,dtype=int)) \n",
    "            c_cols = list(arange(0,p_couple2,dtype=int))\n",
    "        elif connect_type == 'ii':\n",
    "            c_rows = list(arange(N-i_couple,N,dtype=int))\n",
    "            c_cols = list(arange(N-i_couple,N,dtype=int))\n",
    "        elif connect_type == 'ie':\n",
    "            c_rows = list(arange(N-p_couple2,N,dtype=int))\n",
    "            c_cols = list(arange(0,p_couple2,dtype=int))\n",
    "        elif connect_type == 'ei':\n",
    "            c_rows = list(arange(0,p_couple2,dtype=int))\n",
    "            c_cols = list(arange(N-i_couple,N,dtype=int))\n",
    "        \n",
    "        S3.connect(i=c_rows, j=c_cols) # Manually defined coupling\n",
    "        S3.w = w_couple\n",
    "        ###################################\n",
    "        \n",
    "        ##### Probabilistic coupling #####\n",
    "        #S3.connect(p=0.05) # Probabilistic connection - Chance that G2 will connect with and spike from G1\n",
    "        #S3.w = 0.02\n",
    "        #S3.connect(p=p_couple)\n",
    "        ###################################\n",
    "                \n",
    "        # Coupling matrix\n",
    "        coup_mat = [[0 for x in range(N)] for y in range(N)]\n",
    "\n",
    "        for ii in range(len(c_rows)):\n",
    "            for jj in range(len(c_cols)):\n",
    "                coup_mat[ii][ii] = 1      # Matrix has 1s for connections and 0s for none\n",
    "\n",
    "        rand_name = str(random.randint(1,10))\n",
    "        \n",
    "        statemon1 = StateMonitor(G1, 'v', record=0,name='statemon1_'+ G1.name + rand_name) # Records just neuron 0 to save resources\n",
    "        spikemon1 = SpikeMonitor(G1, variables='v',)\n",
    "        statemon2 = StateMonitor(G2, 'v', record=0,name='statemon2_'+ G2.name + rand_name) # Records just neuron 0 to save resources\n",
    "        spikemon2 = SpikeMonitor(G2, variables='v')\n",
    "           \n",
    "        #run(run_time*ms, 'text')\n",
    "\n",
    "        return statemon1,spikemon1,statemon2,spikemon2,c_rows,c_cols,coup_mat,S3\n",
    "        \n",
    "    def spike_time(self,spikemon):\n",
    "        all_values = spikemon.all_values()\n",
    "        spike_times = all_values['t'][0] # Spike times for just neuron 0\n",
    "        all_spikes = spikemon.t/ms # Spike times for all neurons\n",
    "        \n",
    "        return spike_times,all_spikes\n",
    "        \n",
    "    def voltage_monitor(self,statemon):\n",
    "        plot(statemon.t/ms, statemon.v[0])\n",
    "        #plot(statemon.t/ms, statemon.v[1])  # Plots second neuron      \n",
    "        ylabel('Voltage (V)')\n",
    "        xlabel('Time (ms)')\n",
    "        \n",
    "    def raster_plot(self,spikemon,spikemon_other):\n",
    "        #ion()\n",
    "        plot(spikemon.t/ms, spikemon.i, '.r')\n",
    "        plot(spikemon_other.t/ms, spikemon_other.i, '.k') # Plots overlay of each network\n",
    "        xlabel('Time (ms)')\n",
    "        ylabel('Neuron index');\n",
    "        #plt.show(block=True)\n",
    "        \n",
    "    def spike_hist(self,run_time,all_spikes):\n",
    "        my_bins = arange(0,run_time+2,2)\n",
    "        plt.hist(all_spikes, bins=my_bins)\n",
    "        plt.yticks(np.arange(0, 30, step=2))\n",
    "        xlabel('Time (ms)')\n",
    "        ylabel('Total number of spikes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class AdjacencyMatrix:  \n",
    "    '''\n",
    "    Function 1: Weighted adjacency matrix\n",
    "    Call to initiate adjacency matrix\n",
    "    Call to choose which neural network topology with given parameters\n",
    "    \n",
    "    Description:\n",
    "    Given parameters, constructs network with adjacency matrix and applies random weights.\n",
    "    \n",
    "    Returns:\n",
    "        Graph: NetworkX Graph\n",
    "        A: Adjacency matrix. Sparse matrix\n",
    "        rows: Presynaptic neurons\n",
    "        cols: Postsynaptic neurons\n",
    "        connect_W: Weights for each E/I connection (in order of rows,cols)\n",
    "    \n",
    "    Parameters:\n",
    "        n: nodes\n",
    "        m: edges\n",
    "        k: neighbor connections\n",
    "        p: probability \n",
    "        d: degrees\n",
    "    '''\n",
    "    def __init__(self,n): \n",
    "        plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "        \n",
    "    def random(self,n,p): \n",
    "        # Interchangeable based on UI for different types of topography\n",
    "        #G = nx.dense_gnm_random_graph(n,m) # Uses NetX to generate random topography, need to add input param m\n",
    "        Graph = nx.gnp_random_graph(n,p)\n",
    "        #nx.draw(G, with_labels=True) # Draws connectivity figure\n",
    "        #plt.savefig(\"Random.png\") # Saves connectivity figure as Random.png\n",
    "\n",
    "        # Extracts ADJACENCY MATRIX from topography and rearranges to manageable array of (n*n) elements\n",
    "        A = nx.adjacency_matrix(Graph) # Assigns A as adjacency matrix (which nodes are connected)\n",
    "        return A, Graph \n",
    "    \n",
    "    def small_world(self,n,k,p): \n",
    "        Graph = nx.newman_watts_strogatz_graph(n,k,p) \n",
    "        #nx.draw(G, with_labels=True)\n",
    "        #plt.savefig(\"Small-world.png\")\n",
    "        A = nx.adjacency_matrix(Graph)\n",
    "        return A, Graph\n",
    "    \n",
    "    def unidir_coord(self,rows, cols):\n",
    "        # function to remove duplicate connections like (0,3) and (3,0) so that all connections are uni- and not bi-directional\n",
    "        new_coord = zip(rows,cols) # To get an array of coordinate pair tuples, to define node pairs or edges \n",
    "        #print new_coord\n",
    "        new_rows = set(tuple(sorted(l)) for l in new_coord) # set removes duplicate tuples that are now ordered pairs\n",
    "        # set(array of tuples)\n",
    "        g = np.array(list(new_rows)) #array of 1 by 2 neuron pair vectors that are connected to each other\n",
    "        # In each 1 by 2 vector: column 0 is source neuron and column 1 is target neuron\n",
    "        new_rows = g[:,0] #1-D array of all source neurons i\n",
    "        new_cols = g[:,1] #1-D array of all target neurons j\n",
    "        new_coord = zip(rows,cols) # list of tuples, source and target ordered pairs with no duplicates\n",
    "        return new_coord, new_rows, new_cols\n",
    "    \n",
    "    def adj_synapse_type(self,A):\n",
    "        ### Define connections as inhibitory or excitatory in the adjacency matrix\n",
    "        A_mat = A.todense() # Converts adjacency matrix from 'scipy.sparse.csr.csr_matrix' to numpy matrix                              \n",
    "        rows, cols = np.nonzero(A_mat) # Two arrays of index positions for connections\n",
    "        [new_coord, new_rows, new_cols] = self.unidir_coord(rows,cols) # Removes duplicate connections\n",
    "        connect = len(new_rows) # number of connections or 1s in adjacency matrix\n",
    "\n",
    "        for i in range(connect):\n",
    "            x = new_rows[i]\n",
    "            y = new_cols [i]\n",
    "            if x>(excit-1) or y>(excit-1):   # Checking if either source or target neuron belongs to upper 20% of n \n",
    "                A_mat[x,y] = A_mat[x,y]*-1   # Inhibitory neuron defined, weight is made negative\n",
    "\n",
    "        # Constructing array of unweighted connections\n",
    "        connect_A = [] # Initializaing empty connections array\n",
    "        for i in range(connect):\n",
    "            x = new_rows[i]\n",
    "            y = new_cols [i]\n",
    "            connect_A.append(A_mat[x,y])\n",
    "        connect_A = np.array(connect_A) # Converting data type list to numpy array\n",
    "        return connect_A,new_coord,new_rows,new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Spike_Stats:\n",
    "    '''\n",
    "    Description: Given spike times of each neuron, statistical parameters of ISI(Inter-Spike-Interval) can be calculated\n",
    "                 like mean, variance, co-efficent of variation. Spike trains can also be compared to produce correlation\n",
    "                 coefficients\n",
    "    \n",
    "    Parameters: \n",
    "    '''\n",
    "    \n",
    "    def __init__(self): # Not sure what to do here yet\n",
    "        pass\n",
    "    \n",
    "    def ISI_stats(self,spikemon):\n",
    "        neuron_spikes = spikemon.spike_trains() # Dictionary with dict keys as neuron indices and \n",
    "                                         # dict values as an array of spike times for that neuron\n",
    "        firing_n = list(set(sort(spikemon.i))) # To create a set or list of all unique neuron indices that have spiked\n",
    "                                                # in order to calculate statistical parameters for each unique neuron\n",
    "            \n",
    "        ISI = {} # Create an empty dictionary to contain dict keys as neuron indices and dict values as an array of ISIs\n",
    "        ISI_mean = {} # Dict for ISI mean of each neuron index\n",
    "        ISI_var = {} # Dict for ISI variance of each neuron index\n",
    "        ISI_cv = {} # Dict for ISI co-efficient of variation (CV) for each neuron index\n",
    "\n",
    "        # Calculate variance and mean of each ISI (Inter-Spike-Interval)\n",
    "        for i in firing_n:\n",
    "            # Calculate ISI array by subtracting spike times of each neuron to get an array of spike intervals\n",
    "            ISI[i] = np.diff(neuron_spikes[i])\n",
    "            # Calculate mean of ISI\n",
    "            ISI_mean[i] = np.mean(ISI[i])\n",
    "            # Calculate variance of ISI\n",
    "            ISI_var[i] = np.var(ISI[i])\n",
    "            # Calculate co-efficient of variation(CV) of ISI\n",
    "            ISI_cv[i] = np.sqrt(ISI_var[i])/ISI_mean[i]\n",
    "        return ISI,ISI_mean,ISI_var,ISI_cv\n",
    "    \n",
    "    def spike_bin(self,ISI,bin_size):\n",
    "        sp_binary = {}\n",
    "        t_interval = range(0,run_time,bin_size)\n",
    "        t_size = len(t_interval)\n",
    "            \n",
    "        for k in range(0,len(ISI)):\n",
    "            temp = np.array([0]*t_size) # Converting to an array so that simulatenous assignment \n",
    "                                        # to multiple indices is possible\n",
    "            bin_pos = (ISI[k]/(bin_size*ms)).astype(int)\n",
    "            temp[bin_pos] = 1\n",
    "            sp_binary[k] = temp\n",
    "            \n",
    "        return sp_binary\n",
    "        '''\n",
    "                for k in ISI:\n",
    "                    temp = [0]*t_size\n",
    "                    count= 0\n",
    "                    for t in t_interval: # for loop to search for spikes in the current time interval\n",
    "                        #print(count)\n",
    "                        for r in ISI[k]: # looks through all spike times to see if any are within the current time interval\n",
    "                            if r>t*ms and r<=(t+bin_size)*ms:\n",
    "                                temp[count] = 1\n",
    "                                break    # breaks out of for loop when at least one spike has been found for the time interval \n",
    "                                         # and moves on to the next time interval\n",
    "                            else:\n",
    "                                temp[count] = 0\n",
    "                        count = count + 1\n",
    "                    sp_binary[k] = temp\n",
    "        '''       \n",
    "    \n",
    "\n",
    "    def spike_cc(self,bin_vector):\n",
    "        var = [] # A empty list that will contain lists of binary spike trains\n",
    "        for k in bin_vector:\n",
    "            var.append(bin_vector[k]) # Required format to use with numpy's corrcoef function\n",
    "\n",
    "        CC_matrix = np.corrcoef(var) # This matrix is N-neurons by N-neurons and the main diagonal is all 1s \n",
    "                                     # test with CC_matrix.shape to confirm\n",
    "        return CC_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class SynchronicityCalculation:\n",
    "    '''\n",
    "    To calculate different metrics of synchronicity\n",
    "    \n",
    "    For more information:\n",
    "        See Synch Metrics bookmarks folder\n",
    "        http://wwwold.fi.isc.cnr.it/users/thomas.kreuz/sourcecode.html\n",
    "        https://arxiv.org/pdf/1603.03293.pdf\n",
    "        http://mariomulansky.github.io/PySpike/pyspike.html#pyspike.SpikeTrain.SpikeTrain\n",
    "        http://mariomulansky.github.io/PySpike/index.html\n",
    "        http://www.scholarpedia.org/article/Measures_of_spike_train_synchrony#ISI-distance\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        plt.clf() # Clears any previous figures\n",
    "        plt.close() # Clears any figure windows\n",
    "\n",
    "    def Initialize(self,spikemon1,spikemon2):\n",
    "        st1 = spk.SpikeTrain(list(spikemon1.t/ms), edges=[0,run_time])\n",
    "        st2 = spk.SpikeTrain(list(spikemon2.t/ms), edges=[0,run_time])\n",
    "\n",
    "        return st1,st2\n",
    "\n",
    "    def SPIKEsynch(self,spikemon1,spikemon2):\n",
    "        '''\n",
    "        SPIKE-synchronization measures similarity where 0 means absence of synchrony and bounded to 1\n",
    "        indicating absolute synchrony\n",
    "        '''\n",
    "        spike_sync = spk.spike_sync([st1,st2])\n",
    "        #print spike_sync\n",
    "\n",
    "        # Plotting SPIKE-synchronicity\n",
    "        spike_profile = spk.spike_sync_profile([st1,st2])\n",
    "        x,y = spike_profile.get_plottable_data()\n",
    "        plot(x,y,'-k')\n",
    "        ylabel('SPIKE-sync')\n",
    "\n",
    "    def ISIdistance(self,spikemon1,spikemon2):\n",
    "        '''\n",
    "        ISI-distance quantifies dissimilarity based on differences of interspike intervals from two\n",
    "        different spike trains. Becomes 0 for identical spike trains and approaches -1 and 1 when\n",
    "        first or second spike train is faster than the other, respectively.\n",
    "        '''\n",
    "        isi_prof = spk.isi_profile(st1,st2)\n",
    "        isi_dist = isi_prof.avrg()\n",
    "        #print isi_dist # Outputs nan if spike train has same time values\n",
    "\n",
    "        # Plotting ISI profile\n",
    "        x,y = isi_prof.get_plottable_data()\n",
    "        plot(x,y,'-k')\n",
    "        ylabel('ISI')\n",
    "\n",
    "    def SPIKEdistance(self,spikemon1,spikemon2):\n",
    "        '''\n",
    "        SPIKE-distance quantifies dissimilarity based on exact spike timings. In other words,\n",
    "        dissimilarity in terms of deviations from exact coincidences of spikes\n",
    "        Becomes 0 for identical spike trains, and bounded by 1 for highly dissimilar\n",
    "        '''\n",
    "        spike_dist = spk.spike_distance([st1,st2])\n",
    "        #print spike_dist\n",
    "\n",
    "        spike_profile = spk.spike_profile([st1,st2])\n",
    "        x,y = spike_profile.get_plottable_data()\n",
    "        plot(x,y,'-k')\n",
    "        xlabel('Time (ms)')\n",
    "        ylabel('SPIKE-dist')\n",
    "\n",
    "    def CrossCorrelation(self,spikemon1,spikemon2):\n",
    "        # Normalize spike times\n",
    "        norm1 = spikemon1.t / np.linalg.norm(spikemon1.t)\n",
    "        norm2 = spikemon2.t / np.linalg.norm(spikemon2.t)\n",
    "        test1 = norm1\n",
    "        test2 = norm2\n",
    "        y = np.correlate(test1,test2,\"full\") \n",
    "        z = np.correlate(test1,test1,\"full\") \n",
    "\n",
    "        # Plotting correlation\n",
    "        x_valy = range(len(y))\n",
    "        x_valz = range(len(z))\n",
    "        plot(x_valy-np.argmax(z/ms),y,'b')\n",
    "        plot(x_valz-np.argmax(z/ms),z,'g')\n",
    "        blue_patch = mpatches.Patch(color='blue', label='Test Correlation')\n",
    "        green_patch = mpatches.Patch(color='green', label='Autocorrelation')\n",
    "        suptitle('Comparing network 2 to network 1', fontsize=14, fontweight='bold')\n",
    "        plt.legend(handles=[blue_patch,green_patch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define network parameters\n",
    "\n",
    "'''\n",
    "Network Architecture Variables:\n",
    "    n - number of nodes/neurons\n",
    "    p1 - for Network 1, probability for an edge to be formed between two nodes\n",
    "    p2 - for Network 2, probability in a small-world network \n",
    "    p3 - for Network 2, probability in a small-world network \n",
    "    k - each node is connected to k nearest neightbors\n",
    "    rand_seed - method of generating a random number, in this case, one based on time\n",
    "    excit - number of excitatory neurons\n",
    "    inhib - number of inhibitory neurons\n",
    "'''\n",
    "n = 100\n",
    "p1 = 0.2\n",
    "p2 = 1 \n",
    "p3 = 1\n",
    "k = 2\n",
    "rand_seed = np.random.seed(int(time.time())) # To seed random number generator based on time\n",
    "excit = int(0.8*n) # 80% of total neurons\n",
    "inhib = int(0.2*n)\n",
    "\n",
    "'''\n",
    "Network Simulation Variables:\n",
    "    N: number of neurons\n",
    "    tau_m: time constant (ms)\n",
    "    v_r: reset membrane potential (mv)\n",
    "    v_th: threshold membrane potential (mv)\n",
    "    I_c: external depolarizing current that is constant\n",
    "    run_time: simulation time (ms)\n",
    "    p_couple: probability that neuron i in first net will couple with neuron i in second net\n",
    "    w_couple: synaptic weight in (V) for connections between sub-networks or between different network groups\n",
    "    PInput: Poisson Input - weight = 0 for off and 0.1 for on\n",
    "    integ_method: method of integration for solving differential equations of neuron dynamics\n",
    "    bin_size: time window to sample spike train data (ms) eg. counting spikes within a certain time interval\n",
    "'''\n",
    "N = n \n",
    "v_r = 0*volt\n",
    "v_th = 1*volt  \n",
    "run_time = 100\n",
    "p_couple = 0.8 #0.99\n",
    "w_couple = 0.5*volt #1 \n",
    "integ_method = 'euler' # or can use 'linear' if differential equation is linear\n",
    "bin_size = 1 # do NOT add units here. It will be added in Stats class under spike_bin function\n",
    "\n",
    "'''\n",
    "Individual Neuron dynamics\n",
    "    E_K = reverse potential for Potassium across lipid bilayer\n",
    "    E_Na = reverse potential for Sodium across lipid bilayer\n",
    "    E_l = leakage potential to account for the exchange of all other ions across cell membrane\n",
    "    dia = diameter of post-synaptic surface\n",
    "    length = length of post-synaptic surface\n",
    "    SA = surface area of post-synaptic neuron\n",
    "    gL = conductance of leakage channels\n",
    "    C_mem = membrane capacitance\n",
    "    E_ex = reversal potential of excitatory synaptic potential eg. AMPA\n",
    "    E_i = reversal potential of inhibitory synaptic potential eg. GABA \n",
    "    tau_ge = time constant for signal to go through excitatory synapse\n",
    "    tau_gi = time constant for signal to go through inhibitory synapse\n",
    "    v_c: starting voltage(constant) for all neurons in a neuron group before simulation\n",
    "    connect_type: 'ee', 'ii', 'ei','ie'\n",
    "    neuron_diffeqns: neural model for individual neurons, this is a string of differential equations\n",
    "'''\n",
    "#E_K = -80*mV\n",
    "#E_Na = 20*mV\n",
    "E_l = -90*mV\n",
    "dia = 20*um\n",
    "length = 20*um\n",
    "SA = (2*pi*(dia/2)*length) # units are um2\n",
    "gL = 1*psiemens/um2 * SA # units are psiemens\n",
    "C_mem = 10e-6*farad/cm2 * SA # units are farad\n",
    "E_ex = 0*mV\n",
    "E_i = -80*mV \n",
    "v_c = 0*volt\n",
    "I_c = 10*pamp # same as I_ext\n",
    "tau_m1 = 0\n",
    "tau_m2 = 0\n",
    "tau_ge = 5*ms\n",
    "tau_gi = 2*ms\n",
    "connect_type = 'ee'\n",
    "#tau_ge = 2*ms\n",
    "#tau_gi = 6.8*ms\n",
    "\n",
    "model_2 = '''\n",
    "dv/dt = (1/C_mem)*(ge*(v - E_ex) + gi*(v - E_i) + gL*(v - E_l) + I) : volt (unless refractory)\n",
    "dge/dt = -ge/tau_ge : siemens\n",
    "dgi/dt = -gi/tau_gi : siemens\n",
    "I : ampere\n",
    "tau : second\n",
    "'''\n",
    "\n",
    "# Leaky integrate and fire neuron (from previous code) \n",
    "# NOTE:Need to include cell resistance so that (RI - v) dimensions match\n",
    "#R = 1*ohm # Assumption for cell resistance\n",
    "#I_c = 2*amp\n",
    "#tau_m1 = 20.4 #37\n",
    "#tau_m2 = 32.4 #43\n",
    "\n",
    "model_1 = '''                \n",
    "dv/dt = (R*I-v)/tau : volt (unless refractory)\n",
    "I : ampere\n",
    "tau : second\n",
    "'''   \n",
    "\n",
    "# Specify which neural model to simulate with\n",
    "neuron_diffeqns = model_2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Individual Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Creating a network of 100 neurons and its corresponding adjacency matrix\n",
    "\n",
    "'''\n",
    "A1: Adjacency Matrix for a random network (Network 1)\n",
    "A2: Adjacency Matrix for a small world network (Network 2)\n",
    "A3: Adjacency Matrix for a different small world network (Network 3)\n",
    "Graph1: Network object specifying nodes and edges of network architecture for Network 1\n",
    "connect_A1: the unweighted version of connect_W, a 1-D array of excitatory(1) and inhibitory(-1) connections\n",
    "newcoord1: pairs of source and target neurons which are in order and no duplicate pairs\n",
    "new_rows1: 1-D array of all source neurons\n",
    "new_cols1: 1-D array of all target neurons\n",
    "'''\n",
    "\n",
    "Adj = AdjacencyMatrix(n) # Initiates an instance of AdjacencyMatrix class\n",
    "\n",
    "# Network 1: Random\n",
    "[A1,Graph1] = Adj.random(n,p1) # Defines random topology using nodes, n and probability, p\n",
    "                        # NetworkX used to generate random graph topography\n",
    "                        # Creates adjacency matrix. For indexes, rows: source neurons, columns: target neurons. \n",
    "                        # 1s indicate nodes connected by an edge, 0s for the opposite\n",
    "\n",
    "# To produce an adjacency matrix with weights adjusted according to excitatory(+ve weight) or inhibitory synapse(-ve weight)\n",
    "[connect_A1,new_coord1,new_rows1,new_cols1] = Adj.adj_synapse_type(A1)\n",
    "\n",
    "# Network 2: Small World\n",
    "# Same process as for Network 1\n",
    "[A2,Graph2] = Adj.small_world(n,k,p2)\n",
    "[connect_A2, new_coord2,new_rows2,new_cols2] = Adj.adj_synapse_type(A2)\n",
    "\n",
    "# Network 3: Small World\n",
    "[A3,Graph3] = Adj.small_world(n,k,p3)\n",
    "[connect_A3, new_coord3,new_rows3,new_cols3] = Adj.adj_synapse_type(A3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Using functions in the Visualization class\n",
    "\n",
    "vis = Visualization() # Initializing the class\n",
    "\n",
    "cluster = vis.cluster_coeff(Graph1)\n",
    "print (\"For random network 1, the clustering co-efficient is\"), cluster\n",
    "\n",
    "# Clustering coefficient for Network 2\n",
    "cluster = vis.cluster_coeff(Graph2)\n",
    "print (\"For small-world network 2, the clustering co-efficient is\"), cluster\n",
    "\n",
    "# Clustering coefficient for Network 3\n",
    "cluster = vis.cluster_coeff(Graph3)\n",
    "print (\"For small-world network 2, the clustering co-efficient is\"), cluster\n",
    "\n",
    "vis.ex_in_connec(Graph1,connect_A1,new_coord1) # This function also uses new_coord returned from AdjacencyMatrix class, \n",
    "                                               # adj_synapse_type func\n",
    "suptitle('Random Network Connections', fontsize=14, fontweight='bold')\n",
    "    \n",
    "vis.ex_in_connec(Graph2,connect_A2,new_coord2)\n",
    "suptitle('Small-world Network Connections (Network 2)', fontsize=14, fontweight='bold')\n",
    "\n",
    "vis.ex_in_connec(Graph3,connect_A3,new_coord3)\n",
    "suptitle('Small-world Network Connections (Network 3)', fontsize=14, fontweight='bold')\n",
    "\n",
    "#char_pl = vis.char_path_len(Graph1)\n",
    "#print \"Characteristic path length is\", char_pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating Individual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Creating and simulating neuron groups (sub-networks)\n",
    "'''\n",
    "connect_W: Weights for each E/I connection (in order of rows,cols)\n",
    "G1: Brian neuron group\n",
    "S1: Brian synapse group\n",
    "P1: Brian Poisson input group\n",
    "'''\n",
    "\n",
    "### Simulating the network\n",
    "connect_W1 = connect_A1*volt\n",
    "\n",
    "# Initializing BrianVis class\n",
    "BrianVis = BrianVisualization()\n",
    "\n",
    "# Run LIF model for first network with Poisson input\n",
    "PInput = 0.1*volt\n",
    "[G1,S1,P1] = BrianVis.network1(new_rows1,new_cols1,connect_W1,N,PInput) # Modified Brian network 1 and 2 class def for PInput\n",
    "spikemon1 = SpikeMonitor(G1) # Records spike times of each neuron in Network 1\n",
    "\n",
    "\n",
    "# Run LIF model for second network with Poisson input\n",
    "PInput = 0.1*volt\n",
    "connect_W2 = connect_A2*volt\n",
    "[G2,S2,P2] = BrianVis.network2(new_rows2,new_cols2,connect_W2,N,PInput,'Neuron_Group2','Synapse_Group2') # Modified Brian class def for PInput\n",
    "spikemon2 = SpikeMonitor(G2)\n",
    "\n",
    "# Run LIF model for third network with Poisson input\n",
    "PInput = 0.1*volt\n",
    "connect_W2 = connect_A2*volt\n",
    "[G3,S3,P3] = BrianVis.network2(new_rows2,new_cols2,connect_W2,N,PInput,'Neuron_Group3','Synapse_Group3') # Modified Brian class def for PInput\n",
    "spikemon3 = SpikeMonitor(G3)\n",
    "\n",
    "net0 = Network(G1,S1,P1,spikemon1) # To store all the network object variables of the random network\n",
    "net1 = Network(G2,S2,P2,spikemon2,G3,S3,P3,spikemon3) # To store all the network object variables of the two small world networks\n",
    "net1.store() # Store the initial state of the small world networks before simulating the neurons\n",
    "net0.run(run_time*ms) # Simulate the random network\n",
    "net1.run(run_time*ms) # Simulate the small world networks\n",
    "\n",
    "#run(run_time*ms) # This simulates both network1 and network2 defined above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Individual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Plotting raster plot\n",
    "fig1 = plt.figure() \n",
    "fig1.suptitle(\"Raster plots for Random Networks\")\n",
    "plt.subplots(figsize=(20,10)) # Increasing the figure size \n",
    "plt.subplots_adjust(wspace = 0.5, hspace = 0.5) # Change width between subplots\n",
    "\n",
    "ax = plt.subplot(2,2,1)\n",
    "ax.set_title(\"Network 2: Small World With Poisson Input\")\n",
    "BrianVis.raster_plot(spikemon2,spikemon2)\n",
    "\n",
    "# Spiking activity of small-world network 3 as a result of being connected to small-world network 2\n",
    "ax = plt.subplot(2,2,2)\n",
    "ax.set_title(\"Network 3: Small World With Poisson Input\")\n",
    "BrianVis.raster_plot(spikemon3,spikemon3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plotting Individual PSTH plot\n",
    "\n",
    "[spike_times2,all_spikes2] = BrianVis.spike_time(spikemon2) # Gather data for network 2\n",
    "[spike_times3,all_spikes3] = BrianVis.spike_time(spikemon3) # Gather data for network 3\n",
    "\n",
    "\n",
    "fig2 = plt.figure()\n",
    "fig2.suptitle(\"PSTH plots for Random Networks\")\n",
    "plt.subplots(figsize=(20,10)) # Increasing the figure size \n",
    "plt.subplots_adjust(wspace = 0.5, hspace = 0.5) # Change width between subplots\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "ax.set_title(\"Small World Network 2 with Poisson Input\")\n",
    "BrianVis.spike_hist(run_time,all_spikes2)\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "ax.set_title(\"Small World Network 3 with Poisson Input\")\n",
    "BrianVis.spike_hist(run_time,all_spikes3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating and Plotting Inter-connected Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Connecting two small-world networks (Network 2 and 3)\n",
    "\n",
    "net1.restore()\n",
    "\n",
    "[statemon_G2,spikemon_G2,statemon_G2c3,spikemon_G2c3,G2c3_rows,G2c3_cols,G2c3_coup_mat,S2c3] = BrianVis.network_coupling(N,p_couple,w_couple,G2,G3,'Synapse_2c3')\n",
    "\n",
    "net1.add(spikemon_G2,spikemon_G2c3,S2c3)\n",
    "net1.run(run_time*ms)\n",
    "\n",
    "# Plotting interconnected networks 2 and 3\n",
    "\n",
    "fig1 = plt.figure() \n",
    "fig1.suptitle(\"Raster plots for Random Networks\")\n",
    "plt.subplots(figsize=(20,10)) # Increasing the figure size \n",
    "plt.subplots_adjust(wspace = 0.5, hspace = 0.5) # Change width between subplots\n",
    "\n",
    "ax = plt.subplot(2,2,1)\n",
    "ax.set_title(\"Network 2 (Source): Small World With Poisson Input after coupling\")\n",
    "BrianVis.raster_plot(spikemon_G2,spikemon_G2)\n",
    "\n",
    "# Spiking activity of small-world network 3 as a result of being connected to small-world network 2\n",
    "ax = plt.subplot(2,2,2)\n",
    "ax.set_title(\"Network 3 (Target): Small World With Poisson Input after coupling\")\n",
    "BrianVis.raster_plot(spikemon_G2c3,spikemon_G2c3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting PSTH plot of coupled networks\n",
    "\n",
    "[spike_times_G2,all_spikes_G2] = BrianVis.spike_time(spikemon_G2) # Gather data for network 2 when coupled with 3\n",
    "[spike_times2c3,all_spikes2c3] = BrianVis.spike_time(spikemon_G2c3) # Gather data for network 3 when coupled with 3\n",
    "\n",
    "fig2 = plt.figure()\n",
    "fig2.suptitle(\"PSTH plots for Random Networks\")\n",
    "plt.subplots(figsize=(20,10)) # Increasing the figure size \n",
    "plt.subplots_adjust(wspace = 0.5, hspace = 0.5) # Change width between subplots\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "ax.set_title(\"Small World Network 2 with Poisson Input after coupling\")\n",
    "BrianVis.spike_hist(run_time,all_spikes_G2)\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "ax.set_title(\"Small World Network 3 with Poisson Input after coupling\")\n",
    "BrianVis.spike_hist(run_time,all_spikes2c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing code below (may need to take out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Initializing BrianVis class\n",
    "BrianVis = BrianVisualization()\n",
    "Sync = SynchronicityCalculation()\n",
    "\n",
    "### Simulating the network\n",
    "\n",
    "# Run LIF model for second network with Poisson input\n",
    "PInput = 0.1*volt\n",
    "connect_W2 = connect_A2*volt\n",
    "[G2,S2,P2] = BrianVis.network2(new_rows2,new_cols2,connect_W2,N,PInput,'Neuron_Group2','Synapse_Group2') # Modified Brian class def for PInput\n",
    "spikemon2 = SpikeMonitor(G2)\n",
    "\n",
    "# Run LIF model for Network 3 with Poisson input (with tau value same as Network 2, no fast or slow network)\n",
    "PInput = 0.1*volt\n",
    "connect_W3 = connect_A3*volt\n",
    "[G4,S4,P4] = BrianVis.network2(new_rows3,new_cols3,connect_W3,N,PInput,'Neuron_Group4','Synapse_Group4')\n",
    "spikemon4 = SpikeMonitor(G4)\n",
    "\n",
    "store(G2.name,G4.name) # To record initial state so that simulation can be repeated with the synapse\n",
    "\n",
    "run(run_time*ms, 'text')\n",
    "\n",
    "# Run LIF model for Network 3 with Poisson input (with different tau, to create 'fast' network)\n",
    "PInput = 0.1*volt\n",
    "tau_gi = 3.5*ms\n",
    "connect_W3 = connect_A3*volt\n",
    "[G3,S3,P3] = BrianVis.network2(new_rows3,new_cols3,connect_W3,N,PInput,'Neuron_Group3') # Modified Brian network 1 and 2 class def for PInput\n",
    "\n",
    "# Connecting two small-world networks with the same tau value (no fast/slow networks)\n",
    "\n",
    "restore(G2.name,G4.name) # G2 and G4 neuron groups will run again starting from original state\n",
    "\n",
    "[statemon_G2,spikemon_G2,statemon_G2c4,spikemon_G2c4,G2c4_rows,G2c4_cols,G2c4_coup_mat,S2c4] = BrianVis.network_coupling(N,p_couple,w_couple,G2,G4,'Synapse_Group2c4')\n",
    "\n",
    "run(run_time*ms, 'text')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Results (may need to remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "### Plotting raster plot\n",
    "fig1 = plt.figure() \n",
    "fig1.suptitle(\"Raster plots for Random Networks\")\n",
    "plt.subplots(figsize=(20,10)) # Increasing the figure size \n",
    "plt.subplots_adjust(wspace = 0.5, hspace = 0.5) # Change width between subplots\n",
    "\n",
    "ax = plt.subplot(2,2,1)\n",
    "ax.set_title(\"Network 1: Random With Poisson Input\")\n",
    "BrianVis.raster_plot(spikemon1,spikemon1)\n",
    "\n",
    "ax = plt.subplot(2,2,2)\n",
    "ax.set_title(\"Network 2: Small World With Poisson Input\")\n",
    "BrianVis.raster_plot(spikemon2,spikemon2)\n",
    "\n",
    "# Spiking activity of small-world network 3 as a result of being connected to small-world network 2\n",
    "ax = plt.subplot(2,2,3)\n",
    "ax.set_title(\"Network 3 (fast): Small World With Poisson Input and input from Network 2 (slow)\")\n",
    "BrianVis.raster_plot(spikemon_c3,spikemon_c3)\n",
    "\n",
    "# Spiking activity of small-world network 3 as a result of being connected to small-world network 2\n",
    "ax = plt.subplot(2,2,4)\n",
    "ax.set_title(\"Network 3: Small World With Poisson Input and input from Network 2 (same tau)\")\n",
    "BrianVis.raster_plot(spikemon_c2,spikemon_c2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# May need to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "### Plotting raster plot\n",
    "fig1 = plt.figure() \n",
    "fig1.suptitle(\"Raster plots for Random Networks\")\n",
    "plt.subplots(figsize=(20,10)) # Increasing the figure size \n",
    "plt.subplots_adjust(wspace = 0.5, hspace = 0.5) # Change width between subplots\n",
    "\n",
    "ax = plt.subplot(2,2,1)\n",
    "ax.set_title(\"Network 2: Small World With Poisson Input\")\n",
    "BrianVis.raster_plot(spikemon2,spikemon2)\n",
    "\n",
    "ax = plt.subplot(2,2,3)\n",
    "ax.set_title(\"Network 4: Small World With Poisson Input\")\n",
    "BrianVis.raster_plot(spikemon4,spikemon4)\n",
    "\n",
    "# Spiking activity of small-world network 3 as a result of being connected to small-world network 2\n",
    "ax = plt.subplot(2,2,2)\n",
    "ax.set_title(\"Coupled Network 2 (source)\")\n",
    "BrianVis.raster_plot(spikemon_G2,spikemon_G2)\n",
    "\n",
    "# Spiking activity of small-world network 3 as a result of being connected to small-world network 2\n",
    "ax = plt.subplot(2,2,4)\n",
    "ax.set_title(\"Coupled Network 4 (target)\")\n",
    "BrianVis.raster_plot(spikemon_G2c4,spikemon_G2c4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# May need to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "### Plotting PSTH plot\n",
    "\n",
    "[spike_times1,all_spikes1] = BrianVis.spike_time(spikemon1) # Gather data for network 1\n",
    "[spike_times2,all_spikes2] = BrianVis.spike_time(spikemon2) # Gather data for network 2\n",
    "[spike_times2,all_spikes3] = BrianVis.spike_time(spikemon_G2c3) # Gather data for network 3\n",
    "\n",
    "fig2 = plt.figure()\n",
    "fig2.suptitle(\"PSTH plots for Random Networks\")\n",
    "plt.subplots(figsize=(20,10)) # Increasing the figure size \n",
    "plt.subplots_adjust(wspace = 0.5, hspace = 0.5) # Change width between subplots\n",
    "\n",
    "ax = plt.subplot(2,2,1)\n",
    "ax.set_title(\"Random with Poisson Input\")\n",
    "BrianVis.spike_hist(run_time,all_spikes1)\n",
    "\n",
    "ax = plt.subplot(2,2,3)\n",
    "ax.set_title(\"Small World Network 2 with Poisson Input\")\n",
    "BrianVis.spike_hist(run_time,all_spikes2)\n",
    "\n",
    "ax = plt.subplot(2,2,4)\n",
    "ax.set_title(\"Small World Network 3 with Poisson Input and input from Network 2\")\n",
    "BrianVis.spike_hist(run_time,all_spikes3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Statistical Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def spike_stat(spikemon):\n",
    "    # provide a pairs showing index and spike times of neurons\n",
    "    list_of_pairs = zip(*spikemon.it)\n",
    "    # represent neuron index in an array\n",
    "    neuron_index_list = list(spikemon.i)\n",
    "    # represent neuron spike times in a separate array\n",
    "    spike_time_list = list(spikemon.t)\n",
    "    index_array, time_array = spikemon.i, spikemon.t\n",
    "\n",
    "    # make a dictionary where each index represents the \n",
    "    # neuron index and the corresponding array represents all spike times of the neuron\n",
    "    from collections import defaultdict\n",
    "    neuron_spikes = defaultdict(list)\n",
    "    for index,value in enumerate(index_array):\n",
    "        neuron_spikes[value] += [time_array[index]]\n",
    "    for l in neuron_spikes:\n",
    "        neuron_spikes[l] = sorted(neuron_spikes[l])\n",
    "    # find the difference between the spike times \n",
    "    for g in neuron_spikes:\n",
    "        lis = neuron_spikes[g]\n",
    "        l = list()\n",
    "        for index,f in enumerate(lis):\n",
    "            if(index+1 >= len(neuron_spikes[g])):\n",
    "                continue\n",
    "            else:\n",
    "                l += [(lis[index+1]/ms)-(f/ms)]\n",
    "        neuron_spikes[g] = l\n",
    "    # make a function to calculate average\n",
    "    def avg(numbers):\n",
    "        return float(sum(numbers)) / max(len(numbers), 1)\n",
    "    mean = []\n",
    "    std = []\n",
    "    # find the standard deviation\n",
    "    for liss in neuron_spikes:\n",
    "        lists = neuron_spikes[liss]\n",
    "        std.append(numpy.std(lists))\n",
    "        mean.append(avg(lists))\n",
    "     # find the coefficient of variance by dividing mean by std\n",
    "    cv = []\n",
    "    for s in range(100): \n",
    "        cv.append(std[s]/mean[s])   \n",
    "\n",
    "    return numpy.round(mean,2),numpy.round(std,2),numpy.round(cv,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions may be from Synchronicity Calculation class (CHECK!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate ISI mean, variance and co-efficient of variation from spike times\n",
    "stats = Spike_Stats() # Initialize Spike Stats class\n",
    "[ISI,ISI_mean,ISI_var,ISI_cv] = stats.ISI_stats(spikemon1)\n",
    "[ISI2,ISI2_mean,ISI2_var,ISI2_cv] = stats.ISI_stats(spikemon2)\n",
    "[ISI3,ISI3_mean,ISI3_var,ISI3_cv] = stats.ISI_stats(spikemon_G2c3)\n",
    "\n",
    "# Create binary spike trains, put into stats class\n",
    "sp_binary = stats.spike_bin(ISI,bin_size)\n",
    "sp2_binary = stats.spike_bin(ISI2,bin_size)\n",
    "sp3_binary = stats.spike_bin(ISI3,bin_size)\n",
    "\n",
    "# Calculating correlation co-efficient\n",
    "CC_matrix = stats.spike_cc(sp_binary)\n",
    "CC2_matrix = stats.spike_cc(sp2_binary)\n",
    "CC3_matrix = stats.spike_cc(sp3_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation co-efficient Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generating a heat map\n",
    "fig3 = plt.figure()\n",
    "plt.subplots(figsize=(10,5)) # Increasing the figure size \n",
    "plt.subplots_adjust(hspace = 1) # Change width between subplots\n",
    "\n",
    "ax1 = plt.subplot(2,2,1)\n",
    "ax1.set_title(\"Random with Poisson Input\")\n",
    "map = plt.imshow(CC_matrix,cmap = 'RdBu') # Blue gives maximum correlation while red shows least correlation\n",
    "plt.colorbar(map) # To show the legend of colors with corresponding values form matrix            \n",
    "\n",
    "ax2 = plt.subplot(2,2,2)\n",
    "ax2.set_title(\"Small World with Poisson Input\")\n",
    "map2 = plt.imshow(CC2_matrix,cmap = 'RdBu') # Blue gives maximum correlation while red shows least correlation\n",
    "plt.colorbar(map2)\n",
    "\n",
    "ax3 = plt.subplot(2,2,3)\n",
    "ax3.set_title(\"Small-world Network 2 to Network 3\")\n",
    "map3 = plt.imshow(CC3_matrix,cmap = 'RdBu') # Blue gives maximum correlation while red shows least correlation\n",
    "plt.colorbar(map3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
